---
layout: post
title: MySQL 高级
categories: [RDBMS]
description: 
keywords: 
---

* content
{:toc}


## 说下 mysql 的索引有哪些吧, 聚簇和非聚簇索引又是什么

索引按照数据结构来说主要包含B+树和Hash索引. 

假设我们有张表, 结构如下:

```sql
create table user(
  id int(11) not null,
  age int(11) not null,
  primary key(id),
  key(age)
);
```

B+树是左小右大的顺序存储结构, 节点只包含id索引列, 而叶子节点包含索引列和数据, 这种数据和索引在一起存储的索引方式叫做聚簇索引, 一张表只能有一个聚簇索引. 假设没有定义主键, InnoDB会选择一个唯一的非空索引代替, 如果没有的话则会隐式定义一个主键作为聚簇索引. 

一般来说索引就是如B-树这类可以来存储键值方便快速查找的数据结构.聚簇索引是物理索引, 数据表就是按顺序存储的, 物理上是连续的.一旦创建了聚簇索引, 表中的所有列都根据构造聚簇索引的关键列来存储.(我的理解, 所有的记录行都根据聚簇索引顺序存储, 如按照主键Id递增方式依次物理顺序存储)因为聚簇索引是按该列的排序存储的, 因此一个表只能有一个聚簇索引.

每个InnoDB表都需要一个聚簇索引.该聚簇索引可以帮助表优化增删改查操作.

如果你为表定义了一个主键, MySQL将使用主键作为聚簇索引.

如果你不为表指定一个主键, MySQL讲索第一个组成列都not null的唯一索引作为聚簇索引.

如果InnoBD表没有主键且没有适合的唯一索引(没有构成该唯一索引的所有列都NOT NULL), MySQL将自动创建一个隐藏的名字为“`GEN_CLUST_INDEX` ”的聚簇索引.

因此每个InnoDB表都有且仅有一个聚簇索引.

 

**所有不是聚簇索引的索引都叫非聚簇索引或者辅助索引.**

在InnDB存储引擎中, 每个辅助索引的每条记录都包含主键, 也包含非聚簇索引指定的列.

MySQL使用这个主键值来检索聚簇索引.

因此应该尽可能将主键缩短, 否则辅助索引占用空间会更大.

**一般来说用自增的整数型列作为主键列.**



聚簇索引和非聚簇索引

![http://www.milky.show/images/database/mysql/lianhuan_1.png](http://www.milky.show/images/database/mysql/lianhuan_1.png)





**下面举例聚簇索引和非聚簇索引的区别.**

注意: 这里的主键是非自增的.普通索引K表示普通的索引非唯一索引.

![http://www.milky.show/images/database/mysql/lianhuan_2.png](http://www.milky.show/images/database/mysql/lianhuan_2.png)

主键是采用B+Tree的数据结构(请看左图), 根据上文可以知主键为**聚簇索引**, 物理存储是根据ID的增加排序递增连续存储的.

普通索引K也是B+Tree的数据结构(请看右图), 但是它不是聚簇索引, 因此为**非聚簇索引或者辅助索引**(聚簇索引只可能是主键, 或者所有组成唯一键的所有列都为NOT NULL的第一个唯一索引, 或者隐式创建的聚簇索引这三种情况).

他的叶子节点存储的是索引列的值, 它的数据域是聚簇索引即ID.

 

假如普通索引k为非唯一索引, 要查询k=3的数据.

需要在k索引查找k=3得到id=30.

然后在左侧的ID索引树查找ID=30对应的记录R3.

然后K索引树继续向右查找, 发现下一个是k=5不满足(非唯一索引后面有可能有相等的值, 因此向右查找到第一个不等于3的地方), 停止.

整个过程从K索引树到主键索引树的过程叫做“回表”.



这是主键聚簇索引存储的结构, 那么非聚簇索引的结构是什么样子呢? 非聚簇索引(二级索引)保存的是主键id值, 这一点和myisam保存的是数据地址是不同的. 

最终, 我们一张图看看InnoDB和Myisam聚簇和非聚簇索引的区别

![http://www.milky.show/images/database/mysql/lianhuan_3.png](http://www.milky.show/images/database/mysql/lianhuan_3.png)



## 什么是覆盖索引和回表吗

覆盖索引指的是在一次查询中, 如果一个索引包含或者说覆盖所有需要查询的字段的值, 我们就称之为覆盖索引, 而不再需要回表查询. 

而要确定一个查询是否是覆盖索引, 我们只需要explain sql语句看Extra的结果是否是“Using index”即可. 

以上面的user表来举例, 我们再增加一个name字段, 然后做一些查询试试. 

```mysql
explain select * from user where age=1; # 查询的 name 无法从索引数据获取, 需要回表
explain select id,age from user where age=1; # 可以直接从索引获取
```

## 锁的类型有哪些呢

**mysql中锁的概念有很多, 乐观锁、悲观锁、共享锁、排他锁、表锁、行锁等, 他们之间有什么关系呢**

**乐观锁**

乐观锁大多是基于数据版本记录机制实现, 一般是给数据库表增加一个"version"字段. 读取数据时, 将此版本号一同读出, 之后更新时, 对此版本号加一. 此时将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对, 如果提交的数据版本号大于数据库表当前版本号, 则予以更新, 否则认为是过期数据. 

**悲观锁**

悲观锁依靠数据库提供的锁机制实现. MySQL中的共享锁和排它锁都是悲观锁. 数据库的增删改操作默认都会加排他锁, 而查询不会加任何锁. 

**共享锁(读锁)**

共享锁指的就是对于多个不同的事务, 对于一个资源共享同一个锁. 对某一资源加共享锁, 自身可可读该资源, 其他人也可以读该资源(也可以再加共享锁, 即共享锁共享多个内存), 但无法修改. 要想修改就必须等所有共享锁都释放完之后. 语法: `select * from table lock in share mode;`

**排它锁(写锁)**

排它锁指的就是对于多个不同的事务, 对同一个资源只能有一把锁. 对某一资源加排它锁, 自身可以进行增删改查, 其他人无法进行加锁操作, 更无法进行增删改操作. 语法: `select * from table for update`. 

**行锁**

行锁就是给一行数据进行加锁, 操作对象是数据表中的一行(共享锁和排他锁可能是行锁也可能是表锁, 取决于对数据加锁的范围, 是一行还是整个表). 是MVCC技术用的比较多的, 但在MYISAM用不了, 行级锁用mysql的储存引擎实现而不是mysql服务器. 但行级锁对系统开销较大, 处理高并发较好. 

**表锁**

表锁就是对一张表进行加锁, 操作对象是数据表. Mysql大多数锁策略都支持(常见mysql innodb), 是系统开销最低但并发性最低的一个锁策略. 事务t对整个表加读锁, 则其他事务可读不可写, 若加写锁, 则其他事务增删改都不行. 比如alter修改表结构的时候会锁表. 

**意向锁**

意向锁是InnoDB自动加的, 不需要用户干预. 

对于insert、update、delete, InnoDB会自动给涉及的数据加排他锁(X); 对于一般的Select语句, InnoDB不会加任何锁, 事务可以通过以下语句给显示加共享锁或排他锁. 

共享锁:   SELECT ... LOCK IN SHARE MODE;

排他锁:   SELECT ... FOR UPDATE;



## 你能说下事务的基本特性和隔离级别吗

事务基本特性ACID分别是:

**原子性**指的是一个事务中的操作要么全部成功, 要么全部失败. 

**一致性**指的是数据库总是从一个一致性的状态转换到另外一个一致性的状态. 比如A转账给B100块钱, 假设中间sql执行过程中系统崩溃A也不会损失100块, 因为事务没有提交, 修改也就不会保存到数据库. 

**隔离性**指的是一个事务的修改在最终提交前, 对其他事务是不可见的. 

**持久性**指的是一旦事务提交, 所做的修改就会永久保存到数据库中. 

而隔离性有4个隔离级别, 分别是:

**read uncommit** 读未提交, 可能会读到其他事务未提交的数据, 也叫做脏读. 

用户本来应该读取到id=1的用户age应该是10, 结果读取到了其他事务还没有提交的事务, 结果读取结果age=20, 这就是脏读. 

![http://www.milky.show/images/database/mysql/lianhuan_4.png](http://www.milky.show/images/database/mysql/lianhuan_4.png)

**read commit** 读已提交, 两次读取结果不一致, 叫做不可重复读. 

不可重复读解决了脏读的问题, 他只会读取已经提交的事务. 

用户开启事务读取id=1用户, 查询到age=10, 再次读取发现结果=20, 在同一个事务里同一个查询读取到不同的结果叫做不可重复读. 

![http://www.milky.show/images/database/mysql/lianhuan_5.png](http://www.milky.show/images/database/mysql/lianhuan_5.png)

**repeatable read** 可重复复读, 这是mysql的默认级别, 就是每次读取结果都一样, 但是有可能产生幻读. 

**serializable** 串行, 一般是不会使用的, 他会给每一行读取的数据加锁, 会导致大量超时和锁竞争的问题. 



## 事务ACID的实现

事务需要满足ACID特性, 那在数据库中, 它是如何实现的? 我们接下来的内容将一一介绍.

### 原子性

原子性由undo log日志保证, 它记录了需要回滚的日志信息, 事务回滚时撤销已经执行成功的sql, 在InnoDB存储引擎中, 重做日志都是以512字节进行存储的, 称为重做日志块.若一个页中产生的重做日志数量大于512字节, 那么需要分割为多个重做日志块进行存储.由于重做日志块的大小与磁盘扇区大小一样, 都是512字节, 因此重做日志的写入可以保证事务的原子性.重做日志块大小为512字节, 但其中包含的有效存储为492字节, 重做日志文件头占12字节, 日志尾占8字节.

### 一致性

一致性一般由代码层面来保证

通过数据库的 undo log 撤销日志, 来保证事务的一致性.
为了完成事务的回滚操作, 在对数据库进行修改时, InnoDB存储引擎不但会产生redo log,还会产生一定量的undo logo.undo log是逻辑日志, 只是将数据库逻辑地恢复到原来的样子, 保证了事务的一致性(从一个状态转换为下一个一致性状态).

### 隔离性

其实我们在[《MySQL InnoDB引擎 MVCC并发控制》](http://blog.csdn.net/tb3039450/article/details/66472579)中谈到了事务的隔离级别, 但没有谈到怎样实现隔离性.我们提到了要消除幻读, 一般的数据库系统需要保证串行化的事务隔离级别, 而MySQL InnoDB在可重复读的事务隔离级别下消除了幻读, 功劳应该归于Next-key Lock锁.这个具体详述在[《MySQL InnoDB中的行锁 Next-Key Lock消除幻读》](http://blog.csdn.net/tb3039450/article/details/66475638).那说了半天事务隔离级别, 隔离性到底是如何实现的? 其实在上面我们已经谈到了, 是锁机制+MVCC.我们**通过 MVCC 使得事务隔离级别达到了可重复读, 使用锁机制消除了幻读, 实现了事务隔离**.需要注意的是, 在使用分布式事务时, InnoDB存储引擎的事务隔离级别必须设置为串行化.

#### 锁实现的 Isolation

**未提交读**: 一个update事务A只有在对数据修改时才加write lock, 一旦写完马上释放write lock, 即使事务A还没有提交. 因此事务B在读取同一行时, 才能读到事务A修改过的数据. 

**提交读**: 一个update事务A只有在对数据修改时才加write lock, 但直到事务A commit时才释放写锁. 因此, 同时进行的事务B希望读取同一行数据时, 会被事务A的write lock堵塞, 所以解决了脏读的问题. 

**可重复读**: 这个隔离等级的条件下, 除了执行提交读的写锁方式, 还会在读取一行数据后, 为这行数据添加read lock直至事务commit. 例如, 事务A读取ID=1这一行数据, 然后为ID=1添加read lock. 事务B同时希望update ID=1, 此时获取写锁失败, 因此在事务A执行完之前, 没有其他任何事务可以对ID=1这一行做修改, 因此解决了重复读的问题

**虽然读写锁解决了Isolation问题, 但锁会导致大量的堵塞, 性能下降. 某些时候会造成死锁, 为了解决死锁, 还要添加死锁探测机制, 性能进一步下降, 因此需要更高效的方式实现Isolation.**

#### MVCC 实现的 Isolation

MVCC, 多版本并发控制, 的思路是: 对每一行数据用log记录多个版本, 每个版本的数据可能都不相同, 然后根据事务的ID去寻找到适合他的那个版本数据, 以此达到不同事务之间的隔离性. 

<img src="http://www.milky.show/images/database/mysql/mysql_4.png" alt="http://www.milky.show/images/database/mysql/mysql_4.png" style="zoom: 50%;" />

如图所示, InnoDB每行数据除了用户定义的数据外, 还包括TRX_ID(当前数据属于哪个事务ID)、ROLL_PTR(指向这一行数据undo log的指针)、delete bit(删除标记). 

<img src="http://www.milky.show/images/database/mysql/mysql_5.png" alt="http://www.milky.show/images/database/mysql/mysql_5.png" style="zoom: 50%;" />

如图, MVCC的前提下, 事务A读取ID=1的行, 数据库会检测事务A的事务ID, 并在ROLL_PTR指向的undo log链中寻找合适的数据版本, 并提取数据. 通过MVCC, 数据库可以使得事务的读取不需要很多读锁, 提升了数据库的性能. 当一个事务完成时, 数据库会删除关于这条事务所有的undo log, 若未完成事务数据库崩溃则根据undo log回滚, 实现Atomicity. 

**新的问题来了: 数据库是如何知道哪个版本是事务A可见的呢? **
在实现上,  InnoDB 为每个事务构造了一个数组, 用来保存这个事务启动瞬间, 所有活跃的事务ID. 

1.  如果 undo log 指向的是绿色部分的trx_id, 说明该事务在事务A启动前已commit, 那么其修改一定是事务A可见的数据

2.  如果 undo log 指向的是红色部分的trx_id, 说明该事务在事务A启动前还未开启, 那么其修改一定是事务A不可见的. 

3.  如果 undo log 指向的是黄色部分的trx_id且这个trx_id在事务A启动时创建的活跃事务中, 那么这个版本是事务A不可见的

<img src="http://www.milky.show/images/database/mysql/mysql_6.png" alt="http://www.milky.show/images/database/mysql/mysql_6.png" style="zoom: 50%;" />

通过以上的步骤可以取得适合事务A的版本数据(undo log), 取出数据并返回, 此时实现了事务的Isolation. 

**提交读**: 事务A执行每一条语句时, 生成一份活跃事务表, 根据这份表去获取数据, 因此不会获取到脏数据(未提交事务引起的), 但会有重复读问题(因为可以读取到commit的事务数据)

**可重复读**: 事务A只有在事务开始时才生成一份活跃事务表, 因此不会读取到事务A执行中commit的其它事务引起的数据变更, 也就不存在重复读问题. 

### 持久性

数据库的最终数据是要落盘的, 试想如果我想修改 100 张表里的 10000 条数据, 如果每次修改都直接以落盘的形式处理, 那么必定有大量的随机IO, 如果使用机械磁盘那么一定存在大量的disk seek时间, 数据库性能极低(我的另一篇文章: [从磁盘到文件系统](https://www.jianshu.com/p/a5d783643fc2) 很清晰的描述了为什么随机IO性能低). 为了能提高性能, 我们希望能将这些改动缓存下来, 统一处理, 但问题是: 如果这期间数据库崩溃了, 那么这部分修改就丢失了, Durability就无法得到满足. 

针对于此问题, InnoDB存储引擎引入了 WAL 技术(write-ahead logging)和redo log. 

1. 每次commit事务之前, 先将要修改的数据信息存入redo log buffer, 然后根据**innodb_flush_log_at_trx_commit** 的设置将redo log刷新至磁盘, 写redo log至磁盘属于磁盘顺序写(因为只需append log到下一位置), 因此redo log的落盘速度是非常快的. 

2. MySQL在内存中执行此次update操作, 即修改数据. 

3. MySQL会周期或不周期性的刷新内存值到磁盘. 

**可以看到, 一次update事务并不会立刻修改磁盘中的数据, 而是记录修改信息, 后期刷新至磁盘. 所以步骤一以后, 即使数据库崩溃, 还可以根据落盘的redo log恢复已执行的事务, 使得我们能获得Durability. **

<img src="http://www.milky.show/images/database/mysql/mysql_3.png" alt="http://www.milky.show/images/database/mysql/mysql_3.png" style="zoom: 50%;" />





### redo 和 undo 的区别

redo 恢复提交事务修改的页操作, undo 回滚行记录到某个特定版本.

redo 通常是物理日志, 记录的是页的物理修改操作.undo是逻辑日志, 根据每行记录进行记录.

### undo误解

通常对undo的误解是undo用于将数据库物理地恢复到执行语句或事务之前的样子.事实上, NO!!!

举个栗子: 一个事务在修改当前一个页中某几条记录, 同时还有别的事务在对同一个页中另几条记录进行修改.因此, 不能将一个页回滚到事务开始的样子, 因为这样会影响其他事务正在进行的工作.所以, 在上面我们说道undo log是逻辑日志.

### undo作用

除了回滚操作, undo的另一个作用是MVCC, 在InnoDB存储引擎中MVCC的实现是通过undo来完成.当用户读取一行记录时, 若该记录已经被其他事务占用, 当前事务可以通过undo读取之前的行版本信息, 以此实现非锁定读.
undo log会产生redo log, undo操作需要持久性保护.



## 事物隔离级别的实现

隔离性分为四个级别: 

1.  读未提交: (Read Uncommitted)
2.  读已提交(Read Committed) 大多数数据库默认的隔离级别
3.  可重复读(Repeatable-Read) mysql数据库所默认的级别
4.  序列化(serializable)

首先程序是可以并发执行的, 同样, 在MySQL中, 一个表可以由两个或多个进程同时来读写数据, 这是没有问题的.

 

比如, 此时有两个进程来读数据, 这也没什么问题, 允许.但是如果一个进程在读某一行的数据的过程中, 另一个在进程又往这一行里面写数据(改、删), 那结果会是如何? 同样, 如果两个进程都同时对某一行数据进行更改, 以谁的更改为准? 那结果又会怎样, 不敢想象, 是不是数据就被破坏掉了.所以此时是冲突的.

既然会冲突就要想办法解决, 靠谁来解决, 这时候就是靠锁机制来维护了.怎么使用锁来使他们不冲突? 

在事务开始的时候可以给要准备写操作的这一行数据加一个排它锁, 如果是读操作, 就给该行数据一个读锁.这样之后, 在修改该行数据的时候, 不让其他进程对该行数据有任何操作.而读该行数据的时候, 其他进程不能更改, 但可以读.读或写完成时, 释放锁, 最后commit提交.这时候读写就分离开了, 写和写也就分离开了.
注意: 此时加锁和释放锁的过程由mysql数据库自身来维护, 不需要我们人为干涉.mysql开发者给这个解决冲突的方案起了一个名字叫做: 读未提交: (Read Uncommitted).这也就是事务的第一个隔离性.

 

但是这个程度的隔离性仅仅是不够的.看下面的测试结果: 

1.  A 修改事务级别为: 未提交读.并开始事务, 对 user 表做一次查询

    ![http://www.milky.show/images/database/mysql/lianhuan_9.png](http://www.milky.show/images/database/mysql/lianhuan_9.png)

2.  B 事务更新一条记录

    ![http://www.milky.show/images/database/mysql/lianhuan_10.png](http://www.milky.show/images/database/mysql/lianhuan_10.png)

3.  此时 B 事务还未提交, A在事务内做一次查询, 发现查询结果已经改变

    ![http://www.milky.show/images/database/mysql/lianhuan_11.png](http://www.milky.show/images/database/mysql/lianhuan_11.png)

4.  B 进行事务回滚

    ![http://www.milky.show/images/database/mysql/lianhuan_12.png](http://www.milky.show/images/database/mysql/lianhuan_12.png)

5.  A 再做一次查询, 查询结果又变回去了

    ![http://www.milky.show/images/database/mysql/lianhuan_13.png](http://www.milky.show/images/database/mysql/lianhuan_13.png)

由试验得知: 在一个进程的事务当中, 我更改了其中的一行数据, 但是我修改完之后就释放了锁, 这时候另一个进程读取了该数据, 此时先前的事务是还未提交的, 直到我回滚了数据, 另一个进程读的数据就变成了无用的或者是错误的数据.我们通常把这种数据叫做脏数据, 这种情况读出来的数据叫做賍读.

 

怎么办? 依然是靠锁机制.无非是锁的位置不同而已, 之前是只要操作完该数据就立马释放掉锁, 现在是把释放锁的位置调整到事务提交之后, 此时在事务提交前, 其他进程是无法对该行数据进行读取的, 包括任何操作.那么数据库为此种状态的数据库操作规则又给了一个名字叫做: 读已提交(Read Committed), 或者也可以叫不可重复读.这也就是事务的第二个隔离性.

 

在某些情况下, 不可重复读并不是问题, 比如我们多次查询某个数据当然以最后查询得到的结果为主.但在另一些情况下就有可能发生问题, 例如对于同一个数据A和B依次查询就可能不同, A和B就可能打起来了……

继续看下面的测试结果: 

1.  把隔离性调为READ-COMMITTED(读取提交内容)设置A的事务隔离级别, 并进入事务做一次查询

    ![http://www.milky.show/images/database/mysql/lianhuan_14.png](http://www.milky.show/images/database/mysql/lianhuan_14.png)

2.  B开始事务, 并对记录进行修改

    ![http://www.milky.show/images/database/mysql/lianhuan_15.png](http://www.milky.show/images/database/mysql/lianhuan_15.png)

3.  A再对user表进行查询, 发现记录没有受到影响

    ![http://www.milky.show/images/database/mysql/lianhuan_16.png](http://www.milky.show/images/database/mysql/lianhuan_16.png)

4.  B提交事务

    ![http://www.milky.show/images/database/mysql/lianhuan_17.png](http://www.milky.show/images/database/mysql/lianhuan_17.png)

5.  A再对user表查询, 发现记录被修改

    ![http://www.milky.show/images/database/mysql/lianhuan_18.png](http://www.milky.show/images/database/mysql/lianhuan_18.png)

试验进行到这里, 你会发现, 在同一个事务中如果两次读取相同的数据时, 最后的结果却不一致.这里我们把这种现象称为: 不可重复读.因为在第一个事务读取了数据之后, 此时另一个事务把该数据给修改了, 这时候事务提交, 那么另一个事务在第二次读取的时候, 结果就不一样, 一个修改前的, 一个是修改后的.

但是细心的你会发现, 既然你说此种隔离性是在事务提交后才释放锁, 那么在试验过程中, 在该数据未提交前, 另一个事务为什么也是仍然可以读取的呀.是我说错了吗? 不是的, 在这里mysql使用了一个并发版本控制机制, 他们把它叫做MVCC, 通俗的也就是说: mysql为了提高系统的并发量, 在事务未提交前, 虽然事务内操作的数据是锁定状态, 但是另一个事务仍然可以读取, 大多数数据库默认的就是这个级别的隔离性.但mysql不是.

而且不只是在更新数据时出现这个问题, 在插入数据时仍然会造成类似的这样一种现象: mysql虽然锁住了正在操作的数据行, 但它仍然不会阻止另一个事务往表插入新行新的数据.比如: 一个事务读取或更新了表里的所有行, 接者又有另一个事务往该表里插入一个新行, 在事务提交后.原来读取或更改过数据的事务又第二次读取了相同的数据, 这时候这个事务中两次读取的结果集行数就不一样.原来更新了所有行, 而现在读出来发现竟然还有一行没有更新.这就是所谓的幻读.

为了防止同事务中两次读取数据不一致, (包括不可重读和幻读), 接下来该如何继续做呢? ！

mysql依然采取的是MVCC并发版本控制来解决这个问题.具体是: 如果事务中存在多次读取同样的数据, MySQL第一次读的时候仍然会保持选择读最新提交事务的数据, 当第一次之后, 之后再读时, mysql会取第一次读取的数据作为结果.这样就保证了同一个事务多次读取数据时数据的一致性.这时候, mysql把这种解决方案叫做: 可重复度(Repeatable-Read), 也就是上述所写的第三个隔离性, 也是mysql默认的隔离级别.

注意: 幻读和不可重复读(Read Committed)都是读取了另一条已经提交的事务(这点就脏读不同), 所不同的是不可重复读查询的都是同一个数据项, 而幻读针对的是一批数据整体(比如数据的个数).

说到这里, 真的就完事了吗? 到这里其实mysql并未完全解决数据的一致性问题.只是在读取上做了手脚, 解决了传统意义上的幻读和不可重复读.
例子: 

1.  A事务开启, B事务开启.
2.  B事务往表里面插入了一条数据, 但还并未提交.
3.  A事务开始查询了, 并没有发现B事务这次插入的数据.然后此时B事务提交了数据.
4.  于是乎, A事务就以为没有这条数据, 就开始添加这条数据, 但是却发现, 发生了数据 重复冲突.

最后这个时候, 该我们的最后一种隔离级别也是最高的隔离级: 别序列化(serializable)登场了.
该隔离级别会自动在锁住你要操作的整个表的数据, 如果另一个进程事务想要操作表里的任何数据就需要等待获得锁的进程操作完成释放锁.可避免脏读、不可重复读、幻读的发生.当然性能会下降很多, 会导致很多的进程相互排队竞争锁.

后记: 以上所说的四种隔离性的锁机制应用是数据库自动完成的, 不需要人为干预.隔离级别的设置只对当前链接有效.对于使用MySQL命令窗口而言, 一个窗口就相当于一个链接, 当前窗口设置的隔离级别只对当前窗口中的事务有效



## 什么是幻读, 什么是 MVCC

MVCC 全称 Mutli Version Concurreny Control, 多版本并发控制, 也可称之为非锁定一致性读; 它通过行的多版本控制方式来读取当前执行时间数据库中的行数据. 实质上使用的是快照数据.

消除锁的开销: 这个较好理解, 如果要保证数据的一致性, 最简单的方式就是对操作数据进行加锁, 但是加锁不可避免的会有锁开销.所以, 如果有能避免进行加锁的方式当然是最好的.

在 InnoDB 事务隔离级别**“读已提交”**与**“可重复读”**下 ,InnoDB存储引擎使用MVCC机制(非锁定一致性读).在**“读已提交”**事务隔离级别下, 对于快照数据, MVCC读总是**读取被锁定行的最新的快照数据**.而**“可重复读”**读到的总是读取**事务开始时的行数据版本**.

我们每行数实际上隐藏了两列, 创建时间版本号, 过期(删除)时间版本号, 每开始一个新的事务, 版本号都会自动递增. 

还是拿上面的user表举例子, 假设我们插入两条数据, 他们实际上应该长这样. 

| id   | name | create_version | delete_version |
| ---- | ---- | -------------- | -------------- |
| 1    | 张三 | 1              |                |
| 2    | 李四 | 2              |                |

这时候假设小明去执行查询, 此时current_version=3

```mysql
select * from user where id<=3;
```

同时, 小红在这时候开启事务去修改id=1的记录, current_version=4

```mysql
update user set name='张三三' where id=1;
```

执行成功后的结果是这样的

| id   | name   | create_version | delete_version |
| ---- | ------ | -------------- | -------------- |
| 1    | 张三   | 1              |                |
| 2    | 李四   | 2              |                |
| 1    | 张三三 | 4              |                |

如果这时候还有小黑在删除id=2的数据, current_version=5, 执行后结果是这样的. 

| id   | name   | create_version | delete_version |
| ---- | ------ | -------------- | -------------- |
| 1    | 张三   | 1              |                |
| 2    | 李四   | 2              | 5              |
| 1    | 张三三 | 4              |                |

由于MVCC的原理是查找创建版本小于或等于当前事务版本, 删除版本为空或者大于当前事务版本, 小明的真实的查询应该是这样

```mysql
select * from user where id<=3 and create_version<=3 and (delete_version>3 or delete_version is null);
```

所以小明最后查询到的id=1的名字还是'张三', 并且id=2的记录也能查询到. 这样做是**为了保证事务读取的数据是在事务开始前就已经存在的, 要么是事务自己插入或者修改的**. 

明白MVCC原理, 我们来说什么是幻读就简单多了. 举一个常见的场景, 用户注册时, 我们先查询用户名是否存在, 不存在就插入, 假定用户名是唯一索引. 

1.  小明开启事务current_version=6查询名字为'王五'的记录, 发现不存在. 
2.  小红开启事务current_version=7插入一条数据, 结果是这样:

| id   | Name | create_version | delete_version |
| ---- | ---- | -------------- | -------------- |
| 1    | 张三 | 1              |                |
| 2    | 李四 | 2              |                |
| 3    | 王五 | 7              |                |

1.  小明执行插入名字'王五'的记录, 发现唯一索引冲突, 无法插入, 这就是幻读. 



## 什么是间隙锁

InnoDB中有三种行锁技术: 

1.  Record Lock:**单条索引记录上加锁, record lock锁住的永远是索引**, 而非记录本身, 即使该表上没有任何索引, 那么innodb会在后台创建一个隐藏的聚集主键索引, 那么锁住的就是这个隐藏的聚集主键索引. 所以说当一条sql没有走任何索引时, 那么将会在每一条聚集索引后面加X锁, 这个类似于表锁, 但原理上和表锁应该是完全不同的. 
2.  Gap Lock: 在索引记录之间的间隙中加锁, 或者是在某一条索引记录之前或者之后加锁, 并不包括该索引记录本身. gap lock的机制主要是解决可重复读模式下的幻读问题. 
3.  Next-Key Lock: Record Lock+Gap Lock, 锁定一个范围, 并且锁定记录本身

### Next-Key Lock

Next-Key Lock是结合Record Lock与Gap Lock的一种锁定方法, 它锁定了包括记录本身的一个范围. 

| id   | name |
| ---- | ---- |
| 10   | a    |
| 20   | b    |
| 50   | c    |

如果索引为 10, 20, 50, 那么: 
Record Lock: select * from tab where id = 10 for update; //对id=10单行进行加锁
Gap Lock锁范围: (- ∞\infty∞, 10)(10, 20)(20, 50)(50, +∞\infty∞)
Next-Key Lock锁范围: (- ∞\infty∞, 10] (10, 20] (20, 50] (50, +∞\infty∞)

| 事务A                                                        | 事务B                                                        |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| set autocommit=0;                                            |                                                              |
| select * from tab where id>10 for update; //查询结果为20,50  |                                                              |
|                                                              | select * from tab where id=10 for update;//执行等待,Next-Key Lock锁机制暴露 |
| commit;                                                      |                                                              |
|                                                              | 继续执行, 查询结果为10                                       |
| select * from tab where id=10 for update; //查询结果为10     |                                                              |
|                                                              | select * from tab where id=10 for update; //等待执行         |
| commit;                                                      |                                                              |
|                                                              | 继续执行, 查询结果为10                                       |
| select * from tab where id=10 for update; //查询结果为10, 锁降级为Record Lock |                                                              |
|                                                              | select * from tab where id>20 for update; //立即执行, 查询结果为50 |

应该从上面的例子中看出了一些问题. 

1.  Next-Key Lock的加锁方式
2.  **当查询的索引含有唯一属性时, InnoDB会对Next-Key Lock进行优化, 将其降级为Record Lock, 即仅锁住索引本身, 而不是范围. **上表中的第三个事例中可看出.

### 为什么会存在Next-Key Lock

**InnoDB能在可重复读的事务隔离级别下消除幻读**

一般的数据库避免幻读需要在串行化的事务隔离级别下, 而InnoDB在可重复读的事务隔离级别下消除幻读; 这样能够有效提高数据库的并发度. 

### 幻读

幻读是指在同一事务下, 连续执行两次同样的SQL语句可能导致不同的结果, 第二次的SQL语句可能会返回之前不存在的行. 

|                                                              |                                              |
| ------------------------------------------------------------ | -------------------------------------------- |
| 事务A                                                        | 事务B                                        |
| SET SESSION tx_isolation=‘READ-COMMITTED’;                   |                                              |
| begin; select * from tab where id>10 for update; //查询结果为20,50 |                                              |
|                                                              | begin; insert into tab values(30,c); commit; |
| select * from tab where id>10 for update; //查询结果为20,30,50;出现幻读 |                                              |



## 数据量级多大? 分库分表怎么做的?

首先分库分表分为垂直和水平两个方式, 一般来说我们拆分的顺序是先垂直后水平. 

**垂直分库**

基于现在微服务拆分来说, 都是已经做到了垂直分库了

![http://www.milky.show/images/database/mysql/lianhuan_6.png](http://www.milky.show/images/database/mysql/lianhuan_6.png)

**垂直分表**

如果表字段比较多, 将不常用的、数据较大的等等做拆分

![http://www.milky.show/images/database/mysql/lianhuan_7.png](http://www.milky.show/images/database/mysql/lianhuan_7.png)

**水平分表**

首先根据业务场景来决定使用什么字段作为分表字段(sharding_key), 比如我们现在日订单 1000 万, 我们大部分的场景来源于 C 端, 我们可以用 user_id 作为sharding_key, 数据查询支持到最近 3 个月的订单, 超过 3 个月的做归档处理, 那么 3 个月的数据量就是9亿, 可以分 1024 张表, 那么每张表的数据大概就在 100 万左右. 

比如用户 id 为 100, 那我们都经过hash(100), 然后对 1024 取模, 就可以落到对应的表上了. 



## 分表后的 ID 怎么保证唯一性的呢? 

因为我们主键默认都是自增的, 那么分表之后的主键在不同表就肯定会有冲突了. 有几个办法考虑:

1.  设定步长, 比如 1-1024 张表我们分别设定 1-1024 的基础步长, 这样主键落到不同的表就不会冲突了. 
2.  分布式 ID, 自己实现一套分布式 ID 生成算法或者使用开源的比如雪花算法这种
3.  分表后不使用主键作为查询依据, 而是每张表单独新增一个字段作为唯一主键使用, 比如订单表订单号是唯一的, 不管最终落在哪张表都基于订单号作为查询依据, 更新也一样. 

## 分表后非 sharding_key 的查询怎么处理

1.  可以做一个mapping表, 比如这时候商家要查询订单列表怎么办呢? 不带user_id查询的话你总不能扫全表吧? 所以我们可以做一个映射关系表, 保存商家和用户的关系, 查询的时候先通过商家查询到用户列表, 再通过user_id去查询. 
2.  打宽表, 一般而言, 商户端对数据实时性要求并不是很高, 比如查询订单列表, 可以把订单表同步到离线(实时)数仓, 再基于数仓去做成一张宽表, 再基于其他如es提供查询服务. 
3.  数据量不是很大的话, 比如后台的一些查询之类的, 也可以通过多线程扫表, 然后再聚合结果的方式来做. 或者异步的形式也是可以的. 

```java
List<Callable<List<User>>> taskList = Lists.newArrayList();
for (int shardingIndex = 0; shardingIndex < 1024; shardingIndex++) {
    taskList.add(() -> (userMapper.getProcessingAccountList(shardingIndex)));
}
List<ThirdAccountInfo> list = null;
try {
    list = taskExecutor.executeTask(taskList);
} catch (Exception e) {
    //do something
}

public class TaskExecutor {
    public <T> List<T> executeTask(Collection<? extends Callable<T>> tasks) throws Exception {
        List<T> result = Lists.newArrayList();
        List<Future<T>> futures = ExecutorUtil.invokeAll(tasks);
        for (Future<T> future : futures) {
            result.add(future.get());
        }
        return result;
    }
}
```

## mysql 主从同步怎么做的

首先先了解 mysql 主从同步的原理

1.  master 提交完事务后, 写入 binlog
2.  slave 连接到 master, 获取 binlog
3.  master 创建 dump 线程, 推送 binglog 到 slave
4.  slave 启动一个IO线程读取同步过来的 master 的 binlog, 记录到 relay log 中继日志中
5.  slave 再开启一个 sql 线程读取 relay log 事件并在 slave 执行, 完成同步
6.  slave 记录自己的 binglog

<img src="http://www.milky.show/images/database/mysql/lianhuan_8.png" alt="http://www.milky.show/images/database/mysql/lianhuan_8.png" style="zoom:67%;" />

由于 mysql 默认的复制方式是异步的, 主库把日志发送给从库后不关心从库是否已经处理, 这样会产生一个问题就是假设主库挂了, 从库处理失败了, 这时候从库升为主库后, 日志就丢失了. 由此产生两个概念. 

**全同步复制**

主库写入 binlog 后强制同步日志到从库, 所有的从库都执行完成后才返回给客户端, 但是很显然这个方式的话性能会受到严重影响. 

**半同步复制**

和全同步不同的是, 半同步复制的逻辑是这样, 从库写入日志成功后返回 ACK 确认给主库, 主库收到至少一个从库的确认就认为写操作完成. 

## 主从的延迟怎么解决呢

这个问题貌似真的是个无解的问题, 只能是说自己来判断了, 需要走主库的强制走主库查询. 



## redo/undo log、binlog 的详解及其区别

### redo log 和 undo log

redo log 是重做日志, 提供 **前滚** 操作; undo log 是回退日志, 提供 **回滚** 操作. 

只用 undo log 实现原子性和持久性的缺陷: 

-   事务提交前需要将 Undo Log 写磁盘(提供可回滚功能, 保证原子性), 这会造成多次磁盘 IO(不考虑各种优化例如 SQL 解析优化等), 这些 IO 算是顺序 IO; 
-   事务提交后需要将数据立即更新到数据库中, 这又会造成至少一次磁盘 IO, 这是一次随机 IO. 

如何优化? 事务提交后如果能够将数据缓存一段时间, 而不是立即更新到数据库, 就能将一次次的随机 IO 打包变成一次 IO, 可以提高性能. 但是这样就会丧失事务的持久性. 因此引入了另外一种机制来实现持久化, 即 redo log. redo 解决的问题之一就是事务执行过程中的强制刷脏. 
 在事务提交前, 只要将 Redo Log 持久化即可, 不需要将数据持久化. 当系统崩溃时, 虽然数据没有持久化, 但是 Redo Log 已经持久化. 系统可以根据 Redo Log 的内容, 将所有数据恢复到最新的状态. 

>   InnoDB 有 buffer pool(简称bp). bp 是 **物理页** 的缓存, 对 InnoDB 的任何修改操作都会首先在 bp 的 page 上进行, 然后这样的页面将被标记为 dirty 并被放到专门的flush list 上, 后续将由专门的刷脏线程阶段性的将这些页面写入磁盘. 这样的好处是避免每次写操作都操作磁盘导致大量的随机 IO, 阶段性的刷脏可以将多次对页面的修改 merge 成一次IO 操作, 同时异步写入也降低了访问的时延. 
>
>   然而, 如果在 dirty page 还未刷入磁盘时, server非正常关闭, 这些修改操作将会丢失, 如果写入操作正在进行, 甚至会由于损坏数据文件导致数据库不可用. 为了避免上述问题的发生, Innodb 将所有对页面的修改操作写入一个专门的文件, 并在数据库启动时从此文件进行恢复操作, 这个文件就是 redo log file. 这样的技术推迟了 bp 页面的刷新, 从而提升了数据库的吞吐, 有效的降低了访问时延. 带来的问题是额外的写 redo log 操作的开销(顺序 IO, 比随机 IO 快很多), 以及数据库启动时恢复操作所需的时间. 

**划重点**

1.  redo log 通常是 **物理** 日志, 记录的是 **数据页** 的物理修改, 而不是某一行或某几行修改成怎样怎样, 它用来恢复提交后的物理数据页(恢复数据页, 且只能恢复到最后一次提交的位置). 
2.  undo log 用来回滚行记录到某个版本. undo log 一般是逻辑日志, 根据每行记录进行记录. 

将二者结合, 提高效率. 

>   要从两个角度来优化, 一个就是尽可能减少写入硬盘(即多个事务合并成一次落盘), 另一个就是尽量顺序写入(HDD 的随机写入性能远差于顺序写入). 

Undo 记录某 **数据** 被修改 **前** 的值, 可以用来在事务失败时进行 rollback; 
 Redo 记录某 **数据块** 被修改 **后** 的值, 可以用来恢复未写入 data file 的已成功事务更新的数据. 
 即, 

-   Redo Log 保证事务的持久性
-   Undo Log 保证事务的原子性(在 InnoDB 引擎中, 还用 Undo Log 来实现 MVCC)

比如某一时刻数据库 DOWN 机了, 有两个事务, 一个事务已经提交, 另一个事务正在处理. 数据库重启的时候就要根据日志进行前滚及回滚, 把已提交事务的更改写到数据文件, 未提交事务的更改恢复到事务开始前的状态. 即, 当数据 crash-recovery 时, 通过 redo log 将所有已经在存储引擎内部提交的事务应用 redo log 恢复, 所有已经 prepared 但是没有 commit 的 transactions 将会应用 undo log 做 roll back. 

### 小细节总结: 为什么只用 redo-log 或者只用 undo-log 不可以

假设只有 undo-log: 那么就必须保证提交前刷脏完成, 否则宕机时有些修改就在内存中丢失了, 破坏了持久性. (这样带来了一个问题, 那就是前面提到的性能差)

假设只有 redo-log: 那么就不能随心所欲地在事务提交前刷脏, 即无法支持大事务. (假如、某张表有 100 亿的 8 字节整数数据, 就算不考虑其他东西带来的损耗, 光 update 整张表至少要消耗 80G 的内存. 如前所述, 有了 undo-log, 就可以随便刷脏. )



### redo/undo log 和 binlog

两者区别还是挺多的, 大致如下, 

-   层次不同. redo/undo 是 innodb 引擎层维护的, 而 binlog 是 mysql server 层维护的, 跟采用何种引擎没有关系, 记录的是所有引擎的更新操作的日志记录. 
-   记录内容不同. redo/undo 记录的是 每个页/每个数据 的修改情况, 属于物理日志+逻辑日志结合的方式(redo log 是物理日志, undo log 是逻辑日志). binlog 记录的都是事务操作内容, binlog 有三种模式: Statement(基于 SQL 语句的复制)、Row(基于行的复制) 以及 Mixed(混合模式). 不管采用的是什么模式, 当然格式是二进制的, 
-   记录时机不同. redo/undo 在 **事务执行过程中** 会不断的写入, 而 binlog 是在 **事务最终提交前** 写入的. binlog 什么时候刷新到磁盘跟参数 `sync_binlog` 相关. 

### binlog 三种模式对比

上面提到 binlog 有三种格式, 各有优缺点: 

-   statement: 基于SQL语句的模式, 某些语句中含有一些函数, 例如 `UUID` `NOW` 等在复制过程可能导致数据不一致甚至出错. 
-   row: 基于行的模式, 记录的是行的变化, 很安全. 但是 binlog 的磁盘占用会比其他两种模式大很多, 在一些大表中清除大量数据时在 binlog 中会生成很多条语句, 可能导致从库延迟变大. 
-   mixed: 混合模式, 根据语句来选用是 statement 还是 row 模式. 

### 扩展

解决上面提到的大事务的 bad case 并不只有使用 undo 日志这一个方案, 其他方案比如, 

-   用虚拟内存, 开足够大
-   文档里直接写明不支持
-   加内存, 加到够用为止
-   内存不够用就转储到硬盘的临时文件上

但这些方案要么性能太差, 要么委屈客户, 要么成本太高, 因此 Mysql 和 Oracle 都选择了使用 undo 日志(虽然实现上各有不同). 
 但是需要注意的是, OceanBase 由于采用了 LSM-Tree 的方案通过减小写放大和加内存的方式抬高了大事务的上限. 这也算是一种解决思路. 



## mysql 磁盘满了会发生什么

使用命令发现磁盘使用率为100%了, 还剩几十兆. 

### 一系列神操作

备份数据库, 删除实例, 删除数据库表, 重启mysql服务, 结果磁盘空间均没有释放. 



### 怎么办

网上查了很多资源, 说要进行磁盘碎片化整理. 原因是 datafree 占据的空间太多啦. 具体可以通过这个 sql 查看. 

```sql
SELECT CONCAT(TRUNCATE(SUM(data_length)/1024/1024,2),'MB') AS data_size,
CONCAT(TRUNCATE(SUM(max_data_length)/1024/1024,2),'MB') AS max_data_size,
CONCAT(TRUNCATE(SUM(data_free)/1024/1024,2),'MB') AS data_free,
CONCAT(TRUNCATE(SUM(index_length)/1024/1024,2),'MB') AS index_size
FROM information_schema.tables WHERE TABLE_NAME = 'datainfo';
```

这个是后来的图了, 之前的图没有留, 当时显示一张表里的 data_free 都达到了 20 个 G. 

<img src="http://www.milky.show/images/mysql/datafull/f_1.png" alt="http://www.milky.show/images/mysql/datafull/f_1.png" style="zoom:50%;" />

网上推荐的做法如下所示, 对表格进行碎片化整理. 

```sql
ALTER TABLE datainfo ENGINE=InnoDB;
ANALYZE TABLE datainfo;

optimize table datainfo;
```

### 僵局

查看数据库版本为 5.562 不支持 inodb, 要么选择升级数据库. 正在这时, 有个不好的消息发生了, 那张表格给删掉了, 但是磁盘空间还是没有释放啊. 所以对表进行碎片化整理的路也走不通了, 因为表没了. . . 



### 后来的神操作

使用命令查看 mysql 安装的位置和配置文件所在的地方

```bash
mysql 1118 945 0 14:28 ? 00:00:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mysqld.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/lib/mysql/mysql.sock
```

关闭 mysql

```bash
service mysql stop
```

删除 datadir 目录下的 ibdata1, ib_logfile0 ib_logfile1这些文件

![http://www.milky.show/images/mysql/datafull/f_2.png](http://www.milky.show/images/mysql/datafull/f_2.png)

移动mysql的启动参数

```bash
mv /etc/my.cnf ./abc
```

重新启动 mysql 发现磁盘空间释放了 service mysql start



### 磁盘空间终于释放了

采用 navicate 备份工具, 进行数据库备份

<img src="http://www.milky.show/images/mysql/datafull/f_3.png" alt="http://www.milky.show/images/mysql/datafull/f_3.png" style="zoom:50%;" />

备份成功后生成了, 生成psc文件. 200409141055.psc



新建一个数据库实例, 设置数据库名和字符集

<img src="http://www.milky.show/images/mysql/datafull/f_4.png" alt="http://www.milky.show/images/mysql/datafull/f_4.png" style="zoom:50%;" />



然后对备份数据库进行还原, 点击还原

<img src="http://www.milky.show/images/mysql/datafull/f_5.png" alt="http://www.milky.show/images/mysql/datafull/f_5.png" style="zoom:67%;" />



### 问题解决

表的存储会出现碎片化, 每当删除了一行内容, 该段空间就会变为被留空, 而在一段时间内的大量删除操作, 会使这种留空的空间变得比存储列表内容所使用的空间更大

当执行插入操作时, MySQL会尝试使用空白空间, 但如果某个空白空间一直没有被大小合适的数据占用, 仍然无法将其彻底占用, 就形成了碎片

当MySQL对数据进行扫描时, 它扫描的对象实际是列表的容量需求上限, 也就是数据被写入的区域中处于峰值位置的部分



### 清除碎片的优点

降低访问表时的 IO,提高 mysql 性能,释放表空间降低磁盘空间使用率

**注意** 

MySQL 官方建议不要经常(每小时或每天)进行碎片整理, 一般根据实际情况, 只需要每周或者每月整理一次即可(我们现在是每月凌晨4点清理mysql所有实例下的表碎片). 

在 OPTIMIZE TABLE 运行过程中, MySQL 会锁定表. 因此, 这个操作一定要在网站访问量较少的时间段进行. 

清理 student 的 105 万条数据, OPTIMIZE TABLE 库.student;本地测试需要37秒. 



### 自测

大家可以用这条语句看看自己的系统的 datafree 大不大 show table status from 表名;





## mysql 引起 cpu 过高如何优化

### 谁在消耗cpu?

用户+系统+IO等待+软硬中断+空闲

<img src="http://www.milky.show/images/mysql/cpu/cpu_1.png" alt="http://www.milky.show/images/mysql/cpu/cpu_1.png" style="zoom:50%;" />

<img src="http://www.milky.show/images/mysql/cpu/cpu_2.png" alt="http://www.milky.show/images/mysql/cpu/cpu_2.png" style="zoom:50%;" />

### 祸首是谁?

#### 用户

用户空间 CPU 消耗, 各种逻辑运算

正在进行大量 tps

函数/排序/类型转化/逻辑 IO 访问…

用户空间消耗大量 cpu, 产生的系统调用是什么? 那些函数使用了 cpu 周期? 

#### IO 等待

等待 IO 请求的完成

此时 CPU 实际上空闲

如 vmstat 中的 wa 很高. 但 IO 等待增加, wa 也不一定会上升(请求 I/O 后等待响应, 但进程从核上移开了)

<img src="http://www.milky.show/images/mysql/cpu/cpu_3.png" alt="http://www.milky.show/images/mysql/cpu/cpu_3.png" style="zoom:50%;" />

<img src="http://www.milky.show/images/mysql/cpu/cpu_4.png" alt="http://www.milky.show/images/mysql/cpu/cpu_4.png" style="zoom:50%;" />

### 产生影响

用户和 IO 等待消耗了大部分 cpu

-   吞吐量下降(tps)
-   查询响应时间增加
-   慢查询数增加
-   对 mysql 的并发陡增, 也会产生上诉影响

<img src="http://www.milky.show/images/mysql/cpu/cpu_5.png" alt="http://www.milky.show/images/mysql/cpu/cpu_5.png" style="zoom:50%;" />

### 如何减少 CPU 消耗?

减少等待

减少 IO 量

SQL/index, 使用合适的索引减少扫描的行数(需平衡索引的正收益和维护开销, 空间换时间)

提升 IO 处理能力

加 cache/加磁盘/SSD

<img src="http://www.milky.show/images/mysql/cpu/cpu_6.png" alt="http://www.milky.show/images/mysql/cpu/cpu_6.png" style="zoom: 50%;" />

#### **减少计算**

**减少逻辑运算量**

-   避免使用函数, 将运算转移至易扩展的应用服务器中 如 substr 等字符运算, dateadd/datesub 等日期运算, abs 等数学函数
-   减少排序, 利用索引取得有序数据或避免不必要排序 如 union all 代替 union, order by 索引字段等
-   禁止类型转换, 使用合适类型并保证传入参数类型与数据库字段类型绝对一致 如数字用 tiny/int/bigint 等, 必需转换的在传入数据库之前在应用中转好
-   简单类型, 尽量避免复杂类型, 降低由于复杂类型带来的附加运算. 更小的数据类型占用更少的磁盘、内存、cpu 缓存和 cpu 周期

<img src="http://www.milky.show/images/mysql/cpu/cpu_7.png" alt="http://www.milky.show/images/mysql/cpu/cpu_7.png" style="zoom: 50%;" />

**减少逻辑 IO 量**

-   index, 优化索引, 减少不必要的表扫描 如增加索引, 调整组合索引字段顺序, 去除选择性很差的索引字段等等
-   table, 合理拆分, 适度冗余 如将很少使用的大字段拆分到独立表, 非常频繁的小字段冗余到“引用表”
-   SQL, 调整 SQL 写法, 充分利用现有索引, 避免不必要的扫描, 排序及其他操作 如减少复杂 join, 减少 order by, 尽量 union all, 避免子查询等
-   数据类型, 够用就好, 减少不必要使用大字段 如 tinyint 够用就别总是 int, int 够用也别老 bigint, date 够用也别总是 timestamp

<img src="http://www.milky.show/images/mysql/cpu/cpu_8.png" alt="http://www.milky.show/images/mysql/cpu/cpu_8.png" style="zoom: 50%;" />

#### 减少 query 请求量(非数据库本身)

-   适当缓存, 降低缓存数据粒度, 对静态并被频繁请求的数据进行适当的缓存 如用户信息, 商品信息等
-   优化实现, 尽量去除不必要的重复请求如禁止同一页面多次重复请求相同数据的问题, 通过跨页面参数传递减少访问等
-   合理需求, 评估需求产出比, 对产出比极端底下的需求合理去除

升级 cpu 若经过减少计算和减少等待后还不能满足需求, cpu 利用率还高T_T 是时候拿出最后的杀手锏了, 升级 cpu, 是选择更快的 cpu 还是更多的 cpu 了? 

-   低延迟(快速响应), 需要更快的 cpu(每个查询只能使用一个 cpu)
-   高吞吐, 同时运行很多查询语句, 能从多个 cpu 处理查询中收益