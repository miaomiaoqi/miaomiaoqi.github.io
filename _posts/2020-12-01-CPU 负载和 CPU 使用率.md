---
layout: post
title: CPU 负载和 CPU 使用率
categories: [OperatingSystem]
description: 
keywords: 
---


* content
{:toc}




## 背景知识

### Linux 进程状态

LINUX 2.6以后的内核中, 进程一般存在7种基础状态: D-不可中断睡眠, R-可执行, S-可中断睡眠, T-暂停态, t-跟踪态, X-死亡态, Z-僵尸态, 这几种状态在PS命令中有对应解释. 

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_1.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_1.png" style="zoom:67%;" />

- D (TASK_UNINTERRUPTIBLE), 不可中断睡眠态. 顾名思义, 位于这种状态的进程处于睡眠中, 并且不允许被其他进程或中断(异步信号)打断. 因此这种状态的进程, 是无法使用kill -9杀死的(kill也是一种信号), 除非重启系统(没错, 就是这么头硬). 不过这种状态一般由I/O等待(比如磁盘I/O, 网络I/O, 外设I/O等)引起, 出现时间非常短暂, 大多很难被PS或者TOP命令捕获(除非I/O HANG死). SLEEP态进程不会占用任何CPU资源. 

- R (TASK_RUNNING), 可执行态. 这种状态的进程都位于CPU的可执行队列中, 正在运行或者正在等待运行, 即不是在上班就是在上班的路上. 

- S (TASK_INTERRUPTIBLE), 可中断睡眠态. 不同于D, 这种状态的进程虽然也处于睡眠中, 但是是允许被中断的. 这种进程一般在等待某事件的发生(比如socket连接, 信号量等), 而被挂起. 一旦这些时间完成, 进程将被唤醒转为R态. 如果不在高负载时期, 系统中大部分进程都处于S态. SLEEP态进程不会占用任何CPU资源. 

- T&t (__TASK_STOPPED & __TASK_TRACED), 暂停or跟踪态. 这种两种状态的进程都处于运行停止的状态. 不同之处是暂停态一般由于收到SIGSTOP, SIGTSTP, SIGTTIN, SIGTTOUT四种信号被停止, 而跟踪态是由于进程被另一个进程跟踪引起(比如gdb断点). 暂停态进程会释放所有占用资源. 

- Z (EXIT_ZOMBIE), 僵尸态. 这种状态的进程实际上已经结束了, 但是父进程还没有回收它的资源(比如进程的描述符, PID等). 僵尸态进程会释放除进程入口之外的所有资源. 

- X (EXIT_DEAD), 死亡态. 进程的真正结束态, 这种状态一般在正常系统中捕获不到. 



### Load Average & CPU 使用率

谈到系统性能, Load和CPU使用率是最直观的两个指标, 那么这两个指标是怎么被计算出来的呢? 是否能互相等价呢? 



**Load Average**

不少人都认为, Load代表正在CPU上运行&等待运行的进程数, 即

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_2.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_2.png" style="zoom:67%;" />

但Linux系统中, 这种描述并不完全准确. 



以下为Linux内核源码中Load Average计算方法, 可以看出来, 因此除了可执行态进程, 不可中断睡眠态进程也会被一起纳入计算, 即: 

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_3.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_3.png" style="zoom:67%;" />

```shell
602staticunsignedlongcount_active_tasks(void)
603 {
604structtask_struct*p;
605unsignedlongnr=0;
606607read_lock(&tasklist_lock);
608for_each_task(p) {
609if ((p->state==TASK_RUNNING610 (p->state&TASK_UNINTERRUPTIBLE)))
611nr+=FIXED_1;
612 }
613read_unlock(&tasklist_lock);
614returnnr;
615 }
......
625staticinlinevoidcalc_load(unsignedlongticks)
626 {
627unsignedlongactive_tasks; /* fixed-point */628staticintcount=LOAD_FREQ;
629630count-=ticks;
631if (count<0) {
632count+=LOAD_FREQ;
633active_tasks=count_active_tasks();
634CALC_LOAD(avenrun[0], EXP_1, active_tasks);
635CALC_LOAD(avenrun[1], EXP_5, active_tasks);
636CALC_LOAD(avenrun[2], EXP_15, active_tasks);
637 }
638 }
```

在前文 Linux进程状态 中有提到过, 不可中断睡眠态的进程(TASK_UNINTERRUTED)一般都在进行I/O等待, 比如磁盘, 网络或者其他外设等待. 由此我们可以看出, Load Average在Linux中体现的是整体系统负载, 即CPU负载 + Disk负载 + 网络负载 + 其余外设负载, 并不能完全等同于CPU使用率(这种情况只出现在Linux中, 其余系统比如Unix, Load还是只代表CPU负载). 

系统平均负载是CPU的Load, 它所包含的信息不是CPU的使用率状况, 而是在一段时间内CPU正在处理以及等待CPU处理的进程数之和的统计信息, 也就是CPU使用队列的长度的统计信息. 这个数字越小越好. 

平均负载是指单位时间内, 系统处于可运行状态和不可中断状态的平均进程数, 也就是平均活跃进程数, 它和 CPU 使用率并没有直接关系. 

平均负载其实就是平均活跃进程数, 进程数包含2部分. 

1. 正在使用 CPU 或者正在等待 CPU 的进程. 也就是我们常用 ps 命令看到的, 处于 R 状态(Running 或 Runnable)的进程
2. 不可中断状态的进程. 常见的是等待硬件设备的 I/O 响应, 也就是我们在 ps 命令中看到的 D 状态(Uninterruptible Sleep, 也称为 Disk Sleep)的进程



**CPU使用率**

CPU的时间分片一般可分为4大类: 用户进程运行时间 - User Time, 系统内核运行时间 - System Time, 空闲时间 - Idle Time, 被抢占时间 - Steal Time. 除了Idle Time外, 其余时间CPU都处于工作运行状态. 

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_4.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_4.png" style="zoom:67%;" />

通常而言, 我们泛指的整体CPU使用率为User Time 和 Systime占比之和(例如tsar中CPU util), 即: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_5.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_5.png)

为了便于定位问题, 大多数性能统计工具都将这4类时间片进一步细化成了8类, 如下为TOP对CPU时间片的分类. 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_6.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_6.png)

- us: 用户进程空间中未改变过优先级的进程占用CPU百分比
- sy: 内核空间占用CPU百分比
- ni: 用户进程空间内改变过优先级的进程占用CPU百分比
- id: 空闲时间百分比
- wa: 空闲&等待I/O的时间百分比
- hi: 硬中断时间百分比
- si: 软中断时间百分比
- st: 虚拟化时被其余VM窃取时间百分比

这8类分片中, 除wa和id外, 其余分片CPU都处于工作态. 





### Cpu负载和cpu利用率的区别

CPU利用率: 显示的是程序在运行期间实时占用的CPU百分比

CPU负载: 显示的是一段时间内正在使用和等待使用CPU的平均任务数. CPU利用率高, 并不意味着负载就一定大. 

举例来说: 如果我有一个程序它需要一直使用cpu的运算功能, 那么此时cpu的使用率可能达到100%, 但是cpu的工作负载则是趋近于“1”, 因为cpu仅负责一个工作嘛！如果同时执行这样的程序两个呢? cpu的使用率还是100%, 但是工作负载则变成2了. 所以也就是说, 当cpu的工作负载越大, 代表cpu必须要在不同的工作之间进行频繁的工作切换. 

**无论CPU的利用率是高是低, 跟后面有多少任务在排队(cpu负载)没有必然关系. **



### 平均负载和CPU使用率的关系

平均负载和CPU使用率的区别, CPU 使用率, 是单位时间内 CPU 繁忙情况的统计, 跟平均负载并不一定完全对应. 

1. CPU 密集型进程, 使用大量 CPU 会导致平均负载升高, 此时这两者是一致的
2. I/O 密集型进程, 等待 I/O 也会导致平均负载升高, 但 CPU 使用率不一定很高
3. 大量等待 CPU 的进程调度也会导致平均负载升高, 此时的 CPU 使用率也会比较高. 



### 什么范围是合理的? 

没有固定的合理范围. 需要和历史监控对比, 观察平均负载是否符合周期性规律. 



## 资源&瓶颈分析

从上文我们了解到, Load Average 和 CPU 使用率可被细分为不同的子域指标, 指向不同的资源瓶颈. 总体来说, 指标与资源瓶颈的对应关系基本如下图所示. 

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_7.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_7.png" style="zoom:67%;" />



### Load 高 & CPU 高

这是我们最常遇到的一类情况, 即load上涨是CPU负载上升导致. 根据CPU具体资源分配表现, 可分为以下几类: 



**CPU sys 高**

这种情况CPU主要开销在于系统内核, 可进一步查看上下文切换情况. 

- 如果非自愿上下文切换较多, 说明CPU抢占较为激烈, 大量进程由于时间片已到等原因, 被系统强制调度, 进而发生的上下文切换. 

- 如果自愿上下文切换较多, 说明可能存在I/O, 内存等系统资源瓶颈, 大量进程无法获取所需资源, 导致的上下文切换. 



**CPU si高**

这种情况CPU大量消耗在软中断, 可进一步查看软中断类型. 一般而言, 网络I/O或者线程调度引起软中断最为常见: 

- NET_TX & NET_RX. NET_TX是发送网络数据包的软中断, NET_RX是接收网络数据包的软中断, 这两种类型的软中断较高时, 系统存在网络I/O瓶颈可能性较大. 

- SCHED. SCHED为进程调度以及负载均衡引起的中断, 这种中断出现较多时, 系统存在较多进程切换, 一般与非自愿上下文切换高同时出现, 可能存在CPU瓶颈. 



**CPU us高**

这种情况说明资源主要消耗在应用进程, 可能引发的原因有以下几类: 

- 死循环或代码中存在 CPU 密集计算. 这种情况多核 CPU us 会同时上涨. 

* 内存问题, 导致大量FULLGC, 阻塞线程. 这种情况一般只有一核CPU us上涨. 

* 资源等待造成线程池满, 连带引发CPU上涨. 这种情况下, 线程池满等异常会同时出现. 



### Load 高 & CPU 低

这种情况出现的根本原因在于不可中断睡眠态(TASK_UNINTERRUPTIBLE)进程数较多, 即CPU负载不高, 但I/O负载较高. 可进一步定位是磁盘I/O还是网络I/O导致. 



## 排查策略

利用现有常用的工具, 我们常用的排查策略基本如下图所示: 

<img src="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_8.png" alt="http://www.milky.show/images/operatingsystem/cpuaverage/cpu_8.png" style="zoom:67%;" />

从问题发现到最终定位, 基本可分为四个阶段: 



#### 资源瓶颈定位

这一阶段通过全局性能检测工具, 初步定位资源消耗异常位点. 

常用的工具有: 

- top, vmstat, tsar(历史)

- 中断: /proc/softirqs, /proc/interrupts
- I/O: iostat, dstat



#### 热点进程定位

定位到资源瓶颈后, 可进一步分析具体进程资源消耗情况, 找到热点进程. 

常用工具有: 

- 上下文切换: pidstat -w
- CPU: pidstat -u
- I/O: iotop, pidstat -d
- 僵尸进程: ps



#### 线程&进程内部资源定位

找到具体进程后, 可细化分析进程内部资源开销情况. 

常用工具有: 

- 上下文切换: pidstat -w -p [pid]
- CPU: pidstat -u -p [pid]
- I/O: lsof



#### 热点事件&方法分析

获取到热点线程后, 我们可用trace或者dump工具, 将线程反向关联, 将问题范围定位到具体方法&堆栈. 

常用的工具有: 

- perf: Linux自带性能分析工具, 功能类似hotmethod, 基于事件采样原理, 以性能事件为基础, 支持针对处理器相关性能指标与操作系统相关性能指标的性能剖析. 
- jstack

- 结合ps -Lp或者pidstat -p一起使用, 可初步定位热点线程. 
- 结合zprofile-threaddump一起使用, 可统计线程分布, 等锁情况, 常用与线程数增加分析. 

- strace: 跟踪进程执行时的系统调用和所接收的信号. 
- tcpdump: 抓包分析, 常用于网络I/O瓶颈定位.

[https://www.cnblogs.com/zhangwangvip/p/12626400.html](https://www.cnblogs.com/zhangwangvip/p/12626400.html)





## 如何设置线程池数量

可能很多人都看到过一个线程数设置的理论: 

- CPU 密集型的程序 - 核心数 + 1
- I/O 密集型的程序 - 核心数 * 2

不会吧, 不会吧, 真的有人按照这个理论规划线程数? 

### 线程数和CPU利用率的小测试

抛开一些操作系统, 计算机原理不谈, 说一个基本的理论(不用纠结是否严谨, 只为好理解): **一个CPU核心, 单位时间内只能执行一个线程的指令**

那么理论上, 我一个线程只需要不停的执行指令, 就可以跑满一个核心的利用率. 

来写个死循环空跑的例子验证一下: 

测试环境: AMD Ryzen 5 3600, 6 - Core, 12 - Threads

```java
public class CPUUtilizationTest {
    public static void main(String[] args) {
        //死循环, 什么都不做
        while (true){
        }
    }
}
```

运行这个例子后, 来看看现在CPU的利用率: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_9.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_9.png)

从图上可以看到, 我的3号核心利用率已经被跑满了

那基于上面的理论, 我多开几个线程试试呢? 

```java
public class CPUUtilizationTest {
    public static void main(String[] args) {

        for (int j = 0; j < 6; j++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    while (true){
                    }
                }
            }).start();
        }
    }
}
```

此时再看CPU利用率, 1/2/5/7/9/11 几个核心的利用率已经被跑满: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_10.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_10.png)

那如果开12个线程呢, 是不是会把所有核心的利用率都跑满? 答案一定是会的: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_11.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_11.png)

如果此时我把上面例子的线程数继续增加到 24 个线程, 会出现什么结果呢? 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_12.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_12.png)

从上图可以看到, CPU 利用率和上一步一样, 还是所有核心 100%, 不过此时负载已经从 11.x 增加到了 22.x, 说明此时 CPU 更繁忙, 线程的任务无法及时执行. 

现代 CPU 基本都是多核心的, 比如我这里测试用的 AMD 3600, 6 核心 12 线程(超线程), 我们可以简单的认为它就是12核心CPU. 那么我这个CPU就可以同时做 12 件事, 互不打扰. 

如果要执行的线程大于核心数, 那么就需要通过操作系统的调度了. 操作系统给每个线程分配CPU时间片资源, 然后不停的切换, 从而实现“并行”执行的效果. 

但是这样真的更快吗? 从上面的例子可以看出, 一个线程就可以把一个核心的利用率跑满. 如果每个线程都很“霸道”, 不停的执行指令, 不给CPU空闲的时间, 并且同时执行的线程数大于CPU的核心数, 就会导致操作系统更频繁的执行切换线程执行, 以确保每个线程都可以得到执行. 

不过切换是有代价的, 每次切换会伴随着寄存器数据更新, 内存页表更新等操作. 虽然一次切换的代价和I/O操作比起来微不足道, 但如果线程过多, 线程切换的过于频繁, 甚至在单位时间内切换的耗时已经大于程序执行的时间, 就会导致CPU资源过多的浪费在上下文切换上, 而不是在执行程序, 得不偿失. 

上面死循环空跑的例子, 有点过于极端了, 正常情况下不太可能有这种程序. 

大多程序在运行时都会有一些 I/O 操作, 可能是读写文件, 网络收发报文等, 这些 I/O 操作在进行时时需要等待反馈的. 比如网络读写时, 需要等待报文发送或者接收到, 在这个等待过程中, 线程是等待状态, CPU 没有工作. 此时操作系统就会调度 CPU 去执行其他线程的指令, 这样就完美利用了 CPU 这段空闲期, 提高了 CPU 的利用率. 

上面的例子中, 程序不停的循环什么都不做, CPU 要不停的执行指令, 几乎没有啥空闲的时间. 如果插入一段 I/O 操作呢, I/O 操作期间 CPU 是空闲状态, CPU 的利用率会怎么样呢? 先看看单线程下的结果: 

```java
public class CPUUtilizationTest {
    public static void main(String[] args) throws InterruptedException {

        for (int n = 0; n < 1; n++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    while (true){
                        // 每次空循环 1亿 次后, sleep 50ms, 模拟 I/O 等待、切换
                        for (int i = 0; i < 100_000_000l; i++) {
                        }
                        try {
                            Thread.sleep(50);
                        }
                        catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                }
            }).start();
        }
    }
}
```

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_13.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_13.png)

哇, 唯一有利用率的 9 号核心, 利用率也才 50%, 和前面没有 sleep 的 100% 相比, 已经低了一半了. 现在把线程数调整到 12 个看看: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_14.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_14.png)

单个核心的利用率 60 左右, 和刚才的单线程结果差距不大, 还没有把 CPU 利用率跑满, 现在将线程数增加到 18: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_15.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_15.png)

此时单核心利用率, 已经接近 100% 了. 由此可见, 当线程中有 I/O 等操作不占用CPU资源时, 操作系统可以调度 CPU 可以同时执行更多的线程. 

现在将 I/O 事件的频率调高看看呢, 把循环次数减到一半, 50_000_000, 同样是 18 个线程: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_16.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_16.png)

此时每个核心的利用率, 大概只有70%左右了. 

### 线程数和 CPU 利用率的小总结

上面的例子, 只是辅助, 为了更好的理解线程数/程序行为/CPU 状态的关系, 来简单总结一下: 

- 一个极端的线程(不停执行“计算”型操作时), 就可以把单个核心的利用率跑满, 多核心CPU最多只能同时执行等于核心数的“极端”线程数
- 如果每个线程都这么“极端”, 且同时执行的线程数超过核心数, 会导致不必要的切换, 造成负载过高, 只会让执行更慢
- I/O 等暂停类操作时, CPU 处于空闲状态, 操作系统调度 CPU 执行其他线程, 可以提高 CPU 利用率, 同时执行更多的线程
- I/O 事件的频率频率越高, 或者等待/暂停时间越长, CPU 的空闲时间也就更长, 利用率越低, 操作系统可以调度 CPU 执行更多的线程

### 线程数规划的公式

前面的铺垫, 都是为了帮助理解, 现在来看看书本上的定义. 《Java 并发编程实战》介绍了一个线程数计算的公式: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_17.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_17.png)

如果希望程序跑到 CPU 的目标利用率, 需要的线程数公式为: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_18.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_18.png)

公式很清晰, 现在来带入上面的例子试试看: 

如果我期望目标利用率为90%(多核90), 那么需要的线程数为: 

核心数12 * 利用率0.9 * (1 + 50(sleep时间)/50(循环50_000_000耗时)) ≈ 22

现在把线程数调到 22, 看看结果: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_19.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_19.png)

现在 CPU 利用率大概 80+, 和预期比较接近了, 由于线程数过多, 还有些上下文切换的开销, 再加上测试用例不够严谨, 所以实际利用率低一些也正常. 

把公式变个形, 还可以通过线程数来计算 CPU 利用率: 

![http://www.milky.show/images/operatingsystem/cpuaverage/cpu_20.png](http://www.milky.show/images/operatingsystem/cpuaverage/cpu_20.png)

线程数22 / (核心数12 * (1 + 50(sleep时间)/50(循环50_000_000耗时))) ≈ 0.9

虽然公式很好, 但在真实的程序中, 一般很难获得准确的等待时间和计算时间, 因为程序很复杂, 不只是“计算”. 一段代码中会有很多的内存读写, 计算, I/O 等复合操作, 精确的获取这两个指标很难, 所以光靠公式计算线程数过于理想化. 

### 真实程序中的线程数

那么在实际的程序中, 或者说一些Java的业务系统中, 线程数(线程池大小)规划多少合适呢? 

**先说结论: 没有固定答案, 先设定预期, 比如我期望的CPU利用率在多少, 负载在多少, GC频率多少之类的指标后, 再通过测试不断的调整到一个合理的线程数**

比如一个普通的, SpringBoot 为基础的业务系统, 默认Tomcat容器+HikariCP连接池+G1回收器, 如果此时项目中也需要一个业务场景的多线程(或者线程池)来异步/并行执行业务流程. 

此时我按照上面的公式来规划线程数的话, 误差一定会很大. 因为此时这台主机上, 已经有很多运行中的线程了, Tomcat有自己的线程池, HikariCP也有自己的后台线程, JVM也有一些编译的线程, 连G1都有自己的后台线程. 这些线程也是运行在当前进程、当前主机上的, 也会占用CPU的资源. 

**所以受环境干扰下, 单靠公式很难准确的规划线程数, 一定要通过测试来验证. **

流程一般是这样: 

1. 分析当前主机上, 有没有其他进程干扰

2. 分析当前JVM进程上, 有没有其他运行中或可能运行的线程

3. 设定目标

4. - 目标CPU利用率 - 我最高能容忍我的CPU飙到多少? 
    - 目标GC频率/暂停时间 - 多线程执行后, GC频率会增高, 最大能容忍到什么频率, 每次暂停时间多少? 
    - 执行效率 - 比如批处理时, 我单位时间内要开多少线程才能及时处理完毕
    - ……

5. 梳理链路关键点, 是否有卡脖子的点, 因为如果线程数过多, 链路上某些节点资源有限可能会导致大量的线程在等待资源(比如三方接口限流, 连接池数量有限, 中间件压力过大无法支撑等)

6. 不断的增加/减少线程数来测试, 按最高的要求去测试, 最终获得一个“满足要求”的线程数**

**而且而且而且！不同场景下的线程数理念也有所不同: **

- Tomcat 中的 maxThreads, 在 Blocking I/O 和 No-Blocking I/O 下就不一样
- Dubbo 默认还是单连接呢, 也有 I/O线程(池)和业务线程(池)的区分, I/O 线程一般不是瓶颈, 所以不必太多, 但业务线程很容易称为瓶颈
- Redis 6.0 以后也是多线程了, 不过它只是 I/O 多线程, “业务”处理还是单线程

**所以, 不要纠结设置多少线程了. 没有标准答案, 一定要结合场景, 带着目标, 通过测试去找到一个最合适的线程数. **

可能还有同学可能会有疑问: “我们系统也没啥压力, 不需要那么合适的线程数, 只是一个简单的异步场景, 不影响系统其他功能就可以”

很正常, 很多的内部业务系统, 并不需要啥性能, 稳定好用符合需求就可以了. 那么我的推荐的线程数是: CPU核心数



### 附录

Java 获取 CPU 核心数

```java
Runtime.getRuntime().availableProcessors() // 获取逻辑核心数, 如6核心12线程, 那么返回的是12
```

Linux 获取 CPU 核心数

```java
# 总核数 = 物理CPU个数 X 每颗物理CPU的核数 
# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数

# 查看物理CPU个数
cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l

# 查看每个物理CPU中core的个数(即核数)
cat /proc/cpuinfo| grep "cpu cores"| uniq

# 查看逻辑CPU的个数
cat /proc/cpuinfo| grep "processor"| wc -l
```

