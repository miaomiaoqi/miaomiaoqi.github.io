---
layout: post
title: "Redis 常见问题"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## Redis 为什么用单线程

Redis的版本很多3.x、4.x、6.x，版本不同架构也是不同的，不限定版本问是否单线程也不太严谨。

1.   版本3.x ，最早版本，也就是大家口口相传的redis是单线程，阳哥2016年讲解的redis就是3.X的版本。

2.   版本4.x，严格意义来说也不是单线程，而是负责处理客户端请求的线程是单线程，但是开始加了点多线程的东西(异步删除)。---貌似

3.   2020年5月版本的6.0.x后及2022年出的7.0版本后，告别了大家印象中的单线程，用一种全新的多线程来解决问题。---实锤

Redis是单线程主要是指Redis的网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求时包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。这也是Redis对外提供键值存储服务的主要流程。

但Redis的其他功能，比如持久化RDB、AOF、异步删除、集群数据同步等等，其实是由额外的线程执行的。

Redis命令工作线程是单线程的，但是，整个Redis来说，是多线程的

### Redis3.x单线程时代但性能依旧很快的主要原因

基于内存操作：Redis 的所有数据都存在内存中，因此所有的运算都是内存级别的，所以他的性能比较高

数据结构简单：Redis 的数据结构是专门设计的，而这些简单的数据结构的查找和操作的时间大部分复杂度都是 O(1)，因此性能比较高；

多路复用和非阻塞 I/O：Redis使用 I/O多路复用功能来监听多个 socket连接客户端，这样就可以使用一个线程连接来处理多个请求，减少线程切换带来的开销，同时也避免了 I/O 阻塞操作

避免上下文切换：因为是单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生

### 既然单线程这么好, 为什么又加入了多线程特性

正常情况下使用 del 指令可以很快的删除数据，而当被删除的 key 是一个非常大的对象时，例如时包含了成千上万个元素的 hash 集合时，那么 del 指令就会造成 Redis 主线程卡顿。

这就是redis3.x单线程时代最经典的故障，大key删除的头疼问题，

由于redis是单线程的，del bigKey .....

等待很久这个线程才会释放，类似加了一个synchronized锁，你可以想象高并发下，程序堵成什么样子？

使用惰性删除可以有效避免 Redis 卡顿的问题

比如当我（Redis）需要删除一个很大的数据时，因为是单线程原子命令操作，这就会导致 Redis 服务卡顿，

于是在 Redis 4.0 中就新增了多线程的模块，当然此版本中的多线程主要是为了解决删除数据效率比较低的问题的。

| unlink key                                             |
| ------------------------------------------------------ |
| flushdb async                                          |
| flushall async                                         |
| 把删除工作交给了后台的小弟（子线程）异步来删除数据了。 |

因为Redis是单个主线程处理，redis之父antirez一直强调"Lazy Redis is better Redis".

而lazy free的本质就是把某些cost(主要时间复制度，占用主线程cpu时间片)较高删除操作，

从redis主线程剥离让bio子线程来处理，极大地减少主线阻塞时间。从而减少删除导致性能和稳定性问题。



## BigKey

### MoreKey

生产上限制 keys */flushdb/flushall 等危险命令以防止误删误用？通过配置设置禁用这些命令，redis.conf在SECURITY这一项中

使用 Scan 命令

SCAN 返回一个包含两个元素的数组， 

第一个元素是用于进行下一次迭代的新游标， 

第二个元素则是一个数组， 这个数组中包含了所有被迭代的元素。如果新游标返回零表示迭代已结束。

SCAN的遍历顺序

非常特别，它不是从第一维数组的第零位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。

### 多大算 BigKey

参考阿里规范, string 类型控制在 10kb 以内, hash, list, set, zset 元素个数不超过 5000 个

### 哪些危害

内存不均，集群迁移困难

超时删除，大key删除作梗

网络流量阻塞

### 如何产生

社交类: 王心凌粉丝列表，典型案例粉丝逐步递增

汇总统计: 某个报表, 月日年累计

### 如何发现

1.   redis-cli \--bigkeys

     **好处，见最下面总结**

     给出每种数据结构Top 1 bigkey，同时给出每种数据类型的键值个数+平均大小

     **不足**

     想查询大于10kb的所有key，\--bigkeys参数就无能为力了，**需要用到memory usage来计算每个键值的字节数**

     redis-cli --bigkeys -a 111111 

     | redis-cli -h 127.0.0.1 -p 6379 -a 111111 --bigkeys           |
     | ------------------------------------------------------------ |
     | 每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1 |

2.   memory usage

### 如何删除

非字符串的 bigkey, 不要使用 del 删除, 使用 hscan, sscan, zscan 方式渐进删除, 同时要防止 bigkey 过期自动删除问题(例如一个 200 万的 zset 设置 1 小时过期, 会触发 del 操作, 造成阻塞, 而且该操作不会出现在慢查询中(latency 可查))

string: 一般用del，如果过于庞大unlink

hash: 使用hscan每次获取少量field-value，再使用hdel删除每个field

list: 使用ltrim渐进式逐步删除，直到全部删除完成

set: 使用sscan每次获取部分元素，再使用srem命令删除每个元素

zset: 使用zscan每次获取部分元素，再使用ZREMRANGEBYRANK命令删除每个元素



### BigKey 生产调优



## fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

## 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

## AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

<img src="https://miaomiaoqi.github.io/images/redis/redis_64.png" alt="https://miaomiaoqi.github.io/images/redis/redis_64.png" style="zoom: 33%;" />

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 `no-appendfsync-on-rewrite=yes`, 根据写入量使用 SSD 磁盘



## 无底洞问题

2010 年, Facebook 有了 3000 个 Memcache 节点, 但是发现了一个问题, 加了一个机器后, 性能没能提升, 反而下降了, 因为在集群模式下, 批量操作会随着机器节点数的增加, 时间复杂度而增加, 批量操作的 key 会分散到不同的机器上去执行, 那么这条命令的性能就要等到最慢的那台机器返回才是真正执行完成

**如何优化**

* 命令本身优化: 例如慢查询 keys, hgetall bigkey

* 减少网络通信次数
* 降低接入成本: 例如客户端长连接/连接池, NIO 等



## 缓存预热

通过 @PostConstruct 预加载数据库中的数据到 redis 中, 防止用户流量一开始打到数据库中



## 缓存雪崩

缓存雪崩是指在某一个时间段内, 缓存集中过期失效, 如果这个时间段内有大量请求, 而查询数据量巨大, 所有的请求都会达到存储层, 存储层的调用量会暴增, 请求全部转发到 DB, DB 瞬时压力过重雪崩. 

1.  Redis突然宕机
2.  大部分数据失效

### 解决方法

**redis高可用**

redis有可能挂掉, 多增加几台redis实例, (一主多从或者多主多从), 这样一台挂掉之后其他的还可以继续工作, 其实就是搭建的集群. 

**限流降级**

在缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个key只允许一个线程查询数据和写缓存, 其他线程等待. 

**数据预热**

数据加热的含义就是在正式部署之前, 我先把可能的数据先预先访问一遍, 这样部分可能大量访问的数据就会加载到缓存中. 在即将发生大并发访问前手动触发加载缓存不同的key. 

**设置不同的失效时间**

对不同的数据使用不同的失效时间, 甚至对相同的数据, 不同的请求使用不同的失效时间, 例如, 我们要缓存 user 数据, 会对每个用户的数据设置不同的缓存过期时间, 可以定义一个基础时间, 假设10秒, 然后加上一个两秒以内的随机数, 过期时间为10～12秒, 就会避免缓存雪崩. 避免同一时间缓存全部失效

**双缓存**

缓存 A 和 B, 比如 A 的失效时间是 20 分钟, B 不失效. 比如从 A 中没读到, 就去 B 中读, 然后异步起一个线程同步到 A. 





## 缓存穿透

什么是缓存穿透, 它就是指当用户在查询一条数据的时候, 而此时数据库和缓存却没有关于这条数据的任何记录, 而这条数据在缓存中没找到就会向数据库请求获取数据. 它拿不到数据时, 是会一直查询数据库, 这样会对数据库的访问造成很大的压力. 

如:用户查询一个 id = -1 的商品信息, 一般数据库 id 值都是从 1 开始自增, 很明显这条信息是不在数据库中, 当没有信息返回时, 会一直向数据库查询, 给当前数据库的造成很大的访问压力. 

这时候我们要想一想, 该如何解决这个问题呢?

一般我们可以想到从缓存开始出发, 想如果我们给缓存设置一个如果当前数据库不存在的信息, 把它缓存成一个空对象, 返回给用户. 

这是一个解决方案, 也就是我们常说的缓存空对象(代码维护简单, 但是效果不是很好). 

Redis 也为我们提供了一种解决方案, 那就是布隆过滤器(代码维护比较复杂, 效果挺好的). 

在流量大时, 可能DB就挂掉了, 要是有人利用不存在的key频繁攻击我们的应用, 这就是漏洞. 

### 造成缓存穿透的原因

业务自身代码或者数据出现问题

一些恶意攻击, 爬虫等造成大量空命中

### 如何发现

监控业务的响应时间, 如果业务的响应时间突然变慢, 那么有可能是大量请求打到了存储层

业务本身逻辑问题

相关指标: 总调用数, 缓存层命中数, 存储层命中数

### 解决方法

#### 缓存空对象

空值做缓存, 再次接收到同样的查询请求时, 若命中缓存并且值为空, 就会直接返回, 不会透传到数据库, 避免缓存击穿, **即缓存层中存了更多的键, 这就需要更多的内存空间, 可以对其设置一个较短的过期时间, 让其自动清除**, 优点是实时性高, 代码维护简单. 当然, 有时恶意袭击者可以猜到我们使用了这种方案, 每次都会使用不同的参数来查询, 这就需要我们对输入的参数进行过滤, 例如, 如果我们使用ID进行查询, 则可以对ID的格式进行分析, 如果不符合产生ID的规则, 就直接拒绝, 或者在ID上放入时间信息, 根据时间信息判断ID是否合法, 或者是否是我们曾经生成的ID, 这样可以拦截一定的无效请求.

<img src="https://miaomiaoqi.github.io/images/redis/redis_81.png" alt="https://miaomiaoqi.github.io/images/redis/redis_81.png" style="zoom: 67%;" />

如果大量不存在的请求过来, 那么这时候缓存岂不是会缓存许多空对象了吗~~~

没错哦！这也是使用缓存空对象会导致的一个问题:如果时间一长这样会导致缓存中存在大量空对象, 这样不仅会占用许多的内存空间, 还会浪费许多资源呀！. 那这有没有什么可以解决的方法呢? 我们来想一想:我们可以将这些对象在一段时间之后清理下不久可以了吗 ~

嗯嗯, 没错！在想想 Redis 里是不是给我们提供了有关过期时间的命令呀(*^▽^*), 这样我们可以在设置空对象的时间, 顺便设置一个过期时间, 就可以解决个问题了呀！

```bash
setex key seconds valule:设置键值对的同时指定过期时间(s)
```

在Java 中直接调用 API 操作即可:

```java
redisCache.put(Integer.toString(id), null, 60) //过期时间为 60s
```



#### 布隆过滤器拦截

如果布隆过滤器认为某个键不存在, 那么就不会访问存储层, 适用于数据命中不高, 数据相对固定实时性低(通常是数据集较大)的应用场景, 代码维护较为复杂, 但是缓存空间占用少

我们也可以简单理解为是一个不怎么精确的 set 结构(set 具有去重的效果). 但是有个小问题是:当你使用它的 contains 方法去判断某个对象是否存在时, 它可能会误判. 也就是说布隆过滤器不是特别不精确, 但是只要参数设置的合理, 它的精确度可以控制的相对足够精确, 只会有小小的误判概率(这是可以接受的呀 ~). 当布隆过滤器说某个值存在时, 这个值可能不存在；当它说不存在时, 那就肯定不存在. 

布隆过滤器的特点

1.  一个非常大的二进制位数组(数组中只存在 0 和 1)
2.  拥有若干个哈希函数(Hash Function)
3.  在空间效率和查询效率都非常高
4.  布隆过滤器不会提供删除方法, 在代码维护上比较困难. 

每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数. 所谓无偏就是能够把元素的 hash 值算得比较均匀. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_82.png" alt="https://miaomiaoqi.github.io/images/redis/redis_82.png" style="zoom: 67%;" />

向布隆过滤器中添加 key 时, 会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置, 每个 hash 函数都会算得一个不同的位置. 再把位数组的这几个位置都置为 1 就完成了 add 操作. ( 每一个 key 都通过若干的hash函数映射到一个巨大位数组上, 映射成功后, 会在把位数组上对应的位置改为1. )

**那为什么布隆过滤器会存在误判率呢?**

误判吗? 人生哪有不摔跤, 只要锄头挥得好, 照样能挖到. (咳咳咳, 说偏了...)

其实它会误判是如下这个情况:

<img src="https://miaomiaoqi.github.io/images/redis/redis_83.png" alt="https://miaomiaoqi.github.io/images/redis/redis_83.png" style="zoom: 67%;" />

当 key1 和 key2 映射到位数组上的位置为 1 时, 假设这时候来了个 key3, 要查询是不是在里面, 恰好 key3 对应位置也映射到了这之间, 那么布隆过滤器会认为它是存在的, 这时候就会产生误判(因为明明 key3 是不在的). 

O(∩_∩)O哈哈~, 这时候你会问了:如何提高布隆过滤器的准确率呢? 

**要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:**

1.  哈希函数的好坏
2.  存储空间大小
3.  哈希函数个数

hash函数的设计也是一个十分重要的问题, 对于好的hash函数能大大降低布隆过滤器的误判率. 

(这就好比优秀的配件之所以能够运行这么顺畅就在于其内部设计的得当)

同时, 对于一个布隆过滤器来说, 如果其位数组越大的话, 那么每个key通过hash函数映射的位置会变得稀疏许多, 不会那么紧凑, 有利于提高布隆过滤器的准确率. 同时, 对于一个布隆过滤器来说, 如果key通过许多hash函数映射, 那么在位数组上就会有许多位置有标志, 这样当用户查询的时候, 在通过布隆过滤器来找的时候, 误判率也会相应降低. 

#### Google 布隆过滤器 Guava 解决缓存穿透



### 如何选择

针对于一些恶意攻击, 攻击带过来的大量 key 是不存在的, 那么我们采用第一种方案就会缓存大量不存在 key 的数据.此时我们采用第一种方案就不合适了, 我们完全可以先对使用第二种方案进行过滤掉这些 key.针对这种 key 异常多, 请求重复率比较低的数据, 我们就没有必要进行缓存, 使用第二种方案直接过滤掉.而对于空数据的 key 有限的, 重复率比较高的, 我们则可以采用第一种方式进行缓存.





## 缓存击穿

缓存击穿是指有某个key经常被查询, 经常被用户特殊关怀, 用户非常 love 它 (*^▽^*), 也就类比“熟客” 或者 一个key经常不被访问. 但是这时候, 如果这个key在缓存的过期时间失效的时候或者这是个冷门key时, 这时候突然有大量有关这个key的访问请求, 这样会导致大并发请求直接穿透缓存, 请求数据库, 瞬间对数据库的访问压力增大, 这个和缓存雪崩的区别在于这里针对某一key缓存, 前者则是很多key. 

**归纳起来:造成缓存击穿的原因有两个. **

(1)一个“冷门”key, 突然被大量用户请求访问. 

(2)一个“热门”key, 在缓存中时间恰好过期, 这时有大量用户来进行访问. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_84.png" alt="https://miaomiaoqi.github.io/images/redis/redis_84.png" style="zoom: 67%;" />

对于缓存击穿的问题:我们常用的解决方案是加锁. 对于key过期的时候, 当key要查询数据库的时候加上一把锁, 这时只能让第一个请求进行查询数据库, 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

如果我们是在单机环境下:直接使用常用的锁即可(如:Lock, Synchronized等), 在分布式环境下我们可以使用分布式锁, 如:基于数据库, 基于Redis或者zookeeper 的分布式锁. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_85.png" alt="https://miaomiaoqi.github.io/images/redis/redis_85.png" style="zoom: 67%;" />



### 解决方法

**永久缓存**

可以将爆款的缓存失效时间设置为永久. 

**互斥锁**

利用互斥锁, 缓存失效的时候, 先去获得锁, 得到锁了, 再去请求数据库. 没得到锁, 则休眠一段时间重试. 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 



## Redis 分布式锁







## Redis, MySQL 双写一致性问题

最经典的缓存+数据库读写的模式, 就是 Cache Aside Pattern.读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.更新的时候, 先更新数据库, 然后再删除缓存.

**为什么是删除缓存, 而不是更新缓存?**

原因很简单, 很多时候, 在复杂点的缓存场景, 缓存不单单是数据库中直接取出来的值.比如可能更新了某个表的一个字段, 然后其对应的缓存, 是需要查询另外两个表的数据并进行运算, 才能计算出缓存最新的值的.

另外更新缓存的代价有时候是很高的. 是不是说, 每次修改数据库的时候, 都一定要将其对应的缓存更新一份? 也许有的场景是这样, 但是对于比较复杂的缓存数据计算的场景, 就不是这样了.

如果你频繁修改一个缓存涉及的多个表, 缓存也频繁更新.但是问题在于, 这个缓存到底会不会被频繁访问到? 

举个栗子, 一个缓存涉及的表的字段, 在 1 分钟内就修改了 20 次, 或者是 100 次, 那么缓存更新 20 次, 100 次; 但是这个缓存在 1 分钟内只被读取了 1 次, 有大量的冷数据.实际上, 如果你只是删除缓存的话, 那么在 1 分钟内, 这个缓存不过就重新计算一次而已, 开销大幅度降低, 用到缓存才去算缓存.

其实删除缓存, 而不是更新缓存, 就是一个 lazy 计算的思想, 不要每次都重新做复杂的计算, 不管它会不会用到, 而是让它到需要被使用的时候再重新计算.

像 mybatis, hibernate 都有懒加载思想.查询一个部门, 部门带了一个员工的 list, 没有必要说每次查询部门, 都把里面的 1000 个员工的数据也同时查出来.80% 的情况, 查这个部门, 就只是要访问这个部门的信息就可以了.先查部门, 同时要访问里面的员工, 那么这个时候只有在你要访问里面的员工的时候, 才会去数据库里面查询 1000 个员工.

### 先更新数据库, 后更新缓存

<img src="https://miaomiaoqi.github.io/images/redis/redis_74.png" alt="https://miaomiaoqi.github.io/images/redis/redis_74.png" style="zoom: 67%;" />

由上面流程图可知道, **请求 A 更新缓存应该比请求 B 更新缓存早才对, 但是因为网络等原因, B 却比 A 更早更新了缓存.**

这就导致了**脏数据**, 因此不考虑 先更新数据库, 后更新缓存 这个更新策略.



### 先删除缓存, 在更新数据库

<img src="https://miaomiaoqi.github.io/images/redis/redis_75.png" alt="https://miaomiaoqi.github.io/images/redis/redis_75.png" style="zoom:67%;" />

如果同时有一个**请求 A 进行更新操作, 另一个请求 B 进行查询操作**.

**就会导致不一致的情形出现**.而且, 如果不采用给缓存设置过期时间策略, 该数据永远都是脏数据.



### 先更新数据库, 在删除缓存

因为可能存在删除缓存失败的问题, 提供一个补偿措施即可, 例如利用消息队列.

FaceBook 也是采用这种方式.

当然, 这种方式也会产生数据不一致问题.

1.  缓存刚好失效

2.  请求A查询数据库, 得一个旧值

3.  请求B将新值写入数据库

4.  请求B删除缓存

5.  请求A将查到的旧值写入缓存



### 小结

一致性问题是分布式常见问题, 还可以再分为最终一致性和强一致性.数据库和缓存双写, 就必然会存在不一致的问题.答这个问题, 先明白一个前提.就是如果对数据有强一致性要求, 不能放缓存.我们所做的一切, 只能保证最终一致性.另外, 我们所做的方案其实从根本上来说, 只能说降低不一致发生的概率, 无法完全避免. **因此, 有强一致性要求的数据, 不能放缓存.**



## 热点 key 重建优化

### 三个目标

减少重建缓存的次数

数据尽可能一致

减少潜在危险

### 两个解决方法

**互斥锁(mutex key)**

```java
String get(String key) {
    String value = redis.get(key);
    if(value == null) {
        String mutexKey = "mutexKey:" + key;
        if(redis.set(mutexKey, "1", "ex 180", "nx")) {
            value = db.get(key);
            redis.set(key,  value);
            redis.delete(mutexKey);
        } else {
            // 其他线程休息 50 毫秒后重试
            Thread.sleep(50);
            get(key);
        }
    }
    return value;
}
```

**永不过期**

* 缓存层面: 没有设置过期使用(没有使用 expire)
* 功能层面: 为每个 value 添加逻辑过期时间, 但发现超过逻辑过期时间后, 会使用单独的线程去构建缓存

```java
String get(final String key) {
    V v = redis.get(key);
    String value = v.getValue();
    long logicTimeout = v.getValue();
    if (logicTimeout >= System.currentTimeMillis) {
        String mutexKey = "mutexKey:" + key;
        if (redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            // 异步更新后台执行
            threadPool.execute(new Runnable(){
                public void run() {
                    String dbValue = db.get(key);
                    redis.set(key,  (dbValue,  newLoginTimeout));
                    redis.delete(keyMutex);
                }
            });
        }
    }
    return value;
}
```

|   方案   |           优点            |                       缺点                       |
| :------: | :-----------------------: | :----------------------------------------------: |
|  互斥锁  |   思路简单, 保持一致性    |          代码复杂度增加, 存在死锁的风险          |
| 永不过期 | 基本杜绝热点 key 重建问题 | 不保证一致性, 逻辑过期时间增加维护成本和内存成本 |





## 单线程 Redis 为什么这么快?

**完全基于内存，绝大部分请求是纯粹的内存操作，非常快速**

**基本对象使用多种底层数据结构, 且灵活变化是 redis 高性能的另一个原因**

**采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗**

**采用了非阻塞 I/O 多路复用机制**

我们现在要仔细的说一说I/O多路复用机制, 因为这个说法实在是太通俗了, 通俗到一般人都不懂是什么意思.博主打一个比方: 小曲在S城开了一家快递店, 负责同城快送服务.小曲因为资金限制, 雇佣了一批快递员, 然后小曲发现资金不够了, 只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递, 小曲就让一个快递员盯着, 然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题

    几十个快递员基本上时间都花在了抢车上了, 大部分快递员都处在闲置状态, 谁抢到了车, 谁就能去送快递

    随着快递的增多, 快递员也越来越多, 小曲发现快递店里越来越挤, 没办法雇佣新的快递员了

    快递员之间的协调很花时间

    综合上述缺点, 小曲痛定思痛, 提出了下面的经营方式

* 经营方式二

    小曲只雇佣一个快递员.然后呢, 客户送来的快递, 小曲按送达地点标注好, 然后依次放在一个地方.最后, 那个快递员依次的去取快递, 一次拿一个, 然后开着车去送快递, 送好了就回来拿下一个快递.

    对比上述两种经营方式对比, 是不是明显觉得第二种, 效率更高, 更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:

    * 经营方式一就是传统的并发模型, 每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员), 通过跟踪每个I/O流的状态(每个快递的送达地点), 来管理多个I/O流.

    下面类比到真实的redis线程模型, 如图所示

    <img src="https://miaomiaoqi.github.io/images/redis/redis_1.png" alt="https://miaomiaoqi.github.io/images/redis/redis_1.png" style="zoom:50%;" />





## IO 多路复用

在Redis6/7中，非常受关注的第一个新特性就是多线程。

这是因为，Redis一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF重写）。但是，从网络IO处理到实际的读写命令处理，都是由单个线程完成的。

 

随着网络硬件的性能提升，Redis的性能瓶颈有时会出现在网络IO的处理上，也就是说，单个主线程处理网络请求的速度跟不上底层网络硬件的速度,

 

为了应对这个问题:

采用多个IO线程来处理网络请求，提高网络请求处理的并行度，Redis6/7就是采用的这种方法。

 

但是，Redis的多IO线程只是用来处理网络请求的，对于读写操作命令Redis仍然使用单线程来处理。这是因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥加锁机制了(不管加锁操作处理)，这样一来，Redis线程模型实现就简单了