---
layout: post
title: "Redis 常见问题"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

## 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

## AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

<img src="http://www.milky.show/images/redis/redis_64.png" alt="http://www.milky.show/images/redis/redis_64.png" style="zoom: 33%;" />

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 `no-appendfsync-on-rewrite=yes`, 根据写入量使用 SSD 磁盘



## 无底洞问题

2010 年, Facebook 有了 3000 个 Memcache 节点, 但是发现了一个问题, 加了一个机器后, 性能没能提升, 反而下降了, 因为在集群模式下, 批量操作会随着机器节点数的增加, 时间复杂度而增加, 批量操作的 key 会分散到不同的机器上去执行, 那么这条命令的性能就要等到最慢的那台机器返回才是真正执行完成

**如何优化**

* 命令本身优化: 例如慢查询 keys, hgetall bigkey

* 减少网络通信次数
* 降低接入成本: 例如客户端长连接/连接池, NIO 等

## 缓存穿透

什么是缓存穿透, 它就是指当用户在查询一条数据的时候, 而此时数据库和缓存却没有关于这条数据的任何记录, 而这条数据在缓存中没找到就会向数据库请求获取数据. 它拿不到数据时, 是会一直查询数据库, 这样会对数据库的访问造成很大的压力. 

如:用户查询一个 id = -1 的商品信息, 一般数据库 id 值都是从 1 开始自增, 很明显这条信息是不在数据库中, 当没有信息返回时, 会一直向数据库查询, 给当前数据库的造成很大的访问压力. 

这时候我们要想一想, 该如何解决这个问题呢?

一般我们可以想到从缓存开始出发, 想如果我们给缓存设置一个如果当前数据库不存在的信息, 把它缓存成一个空对象, 返回给用户. 

这是一个解决方案, 也就是我们常说的缓存空对象(代码维护简单, 但是效果不是很好). 

Redis 也为我们提供了一种解决方案, 那就是布隆过滤器(代码维护比较复杂, 效果挺好的). 

在流量大时, 可能DB就挂掉了, 要是有人利用不存在的key频繁攻击我们的应用, 这就是漏洞. 

### 造成缓存穿透的原因

业务自身代码或者数据出现问题

一些恶意攻击, 爬虫等造成大量空命中

### 如何发现

监控业务的响应时间, 如果业务的响应时间突然变慢, 那么有可能是大量请求打到了存储层

业务本身逻辑问题

相关指标: 总调用数, 缓存层命中数, 存储层命中数

### 解决方法

#### 缓存空对象

空值做缓存, 再次接收到同样的查询请求时, 若命中缓存并且值为空, 就会直接返回, 不会透传到数据库, 避免缓存击穿, **即缓存层中存了更多的键, 这就需要更多的内存空间, 可以对其设置一个较短的过期时间, 让其自动清除**, 优点是实时性高, 代码维护简单. 当然, 有时恶意袭击者可以猜到我们使用了这种方案, 每次都会使用不同的参数来查询, 这就需要我们对输入的参数进行过滤, 例如, 如果我们使用ID进行查询, 则可以对ID的格式进行分析, 如果不符合产生ID的规则, 就直接拒绝, 或者在ID上放入时间信息, 根据时间信息判断ID是否合法, 或者是否是我们曾经生成的ID, 这样可以拦截一定的无效请求.

<img src="http://www.milky.show/images/redis/redis_81.png" alt="http://www.milky.show/images/redis/redis_81.png" style="zoom: 67%;" />

如果大量不存在的请求过来, 那么这时候缓存岂不是会缓存许多空对象了吗~~~

没错哦！这也是使用缓存空对象会导致的一个问题:如果时间一长这样会导致缓存中存在大量空对象, 这样不仅会占用许多的内存空间, 还会浪费许多资源呀！. 那这有没有什么可以解决的方法呢? 我们来想一想:我们可以将这些对象在一段时间之后清理下不久可以了吗 ~

嗯嗯, 没错！在想想 Redis 里是不是给我们提供了有关过期时间的命令呀(*^▽^*), 这样我们可以在设置空对象的时间, 顺便设置一个过期时间, 就可以解决个问题了呀！

```bash
setex key seconds valule:设置键值对的同时指定过期时间(s)
```

在Java 中直接调用 API 操作即可:

```java
redisCache.put(Integer.toString(id), null, 60) //过期时间为 60s
```



#### 布隆过滤器拦截

如果布隆过滤器认为某个键不存在, 那么就不会访问存储层, 适用于数据命中不高, 数据相对固定实时性低(通常是数据集较大)的应用场景, 代码维护较为复杂, 但是缓存空间占用少

我们也可以简单理解为是一个不怎么精确的 set 结构(set 具有去重的效果). 但是有个小问题是:当你使用它的 contains 方法去判断某个对象是否存在时, 它可能会误判. 也就是说布隆过滤器不是特别不精确, 但是只要参数设置的合理, 它的精确度可以控制的相对足够精确, 只会有小小的误判概率(这是可以接受的呀 ~). 当布隆过滤器说某个值存在时, 这个值可能不存在；当它说不存在时, 那就肯定不存在. 

布隆过滤器的特点

1.  一个非常大的二进制位数组(数组中只存在 0 和 1)
2.  拥有若干个哈希函数(Hash Function)
3.  在空间效率和查询效率都非常高
4.  布隆过滤器不会提供删除方法, 在代码维护上比较困难. 

每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数. 所谓无偏就是能够把元素的 hash 值算得比较均匀. 

<img src="http://www.milky.show/images/redis/redis_82.png" alt="http://www.milky.show/images/redis/redis_82.png" style="zoom: 67%;" />

向布隆过滤器中添加 key 时, 会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置, 每个 hash 函数都会算得一个不同的位置. 再把位数组的这几个位置都置为 1 就完成了 add 操作. ( 每一个 key 都通过若干的hash函数映射到一个巨大位数组上, 映射成功后, 会在把位数组上对应的位置改为1. )

**那为什么布隆过滤器会存在误判率呢?**

误判吗? 人生哪有不摔跤, 只要锄头挥得好, 照样能挖到. (咳咳咳, 说偏了...)

其实它会误判是如下这个情况:

<img src="http://www.milky.show/images/redis/redis_83.png" alt="http://www.milky.show/images/redis/redis_83.png" style="zoom: 67%;" />

当 key1 和 key2 映射到位数组上的位置为 1 时, 假设这时候来了个 key3, 要查询是不是在里面, 恰好 key3 对应位置也映射到了这之间, 那么布隆过滤器会认为它是存在的, 这时候就会产生误判(因为明明 key3 是不在的). 

O(∩_∩)O哈哈~, 这时候你会问了:如何提高布隆过滤器的准确率呢? 

**要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:**

1.  哈希函数的好坏
2.  存储空间大小
3.  哈希函数个数

hash函数的设计也是一个十分重要的问题, 对于好的hash函数能大大降低布隆过滤器的误判率. 

(这就好比优秀的配件之所以能够运行这么顺畅就在于其内部设计的得当)

同时, 对于一个布隆过滤器来说, 如果其位数组越大的话, 那么每个key通过hash函数映射的位置会变得稀疏许多, 不会那么紧凑, 有利于提高布隆过滤器的准确率. 同时, 对于一个布隆过滤器来说, 如果key通过许多hash函数映射, 那么在位数组上就会有许多位置有标志, 这样当用户查询的时候, 在通过布隆过滤器来找的时候, 误判率也会相应降低. 

### 如何选择

针对于一些恶意攻击, 攻击带过来的大量 key 是不存在的, 那么我们采用第一种方案就会缓存大量不存在 key 的数据.此时我们采用第一种方案就不合适了, 我们完全可以先对使用第二种方案进行过滤掉这些 key.针对这种 key 异常多, 请求重复率比较低的数据, 我们就没有必要进行缓存, 使用第二种方案直接过滤掉.而对于空数据的 key 有限的, 重复率比较高的, 我们则可以采用第一种方式进行缓存.



## 缓存击穿

缓存击穿是指有某个key经常被查询, 经常被用户特殊关怀, 用户非常 love 它 (*^▽^*), 也就类比“熟客” 或者 一个key经常不被访问. 但是这时候, 如果这个key在缓存的过期时间失效的时候或者这是个冷门key时, 这时候突然有大量有关这个key的访问请求, 这样会导致大并发请求直接穿透缓存, 请求数据库, 瞬间对数据库的访问压力增大, 这个和缓存雪崩的区别在于这里针对某一key缓存, 前者则是很多key. 

**归纳起来:造成缓存击穿的原因有两个. **

(1)一个“冷门”key, 突然被大量用户请求访问. 

(2)一个“热门”key, 在缓存中时间恰好过期, 这时有大量用户来进行访问. 

<img src="http://www.milky.show/images/redis/redis_84.png" alt="http://www.milky.show/images/redis/redis_84.png" style="zoom: 67%;" />

对于缓存击穿的问题:我们常用的解决方案是加锁. 对于key过期的时候, 当key要查询数据库的时候加上一把锁, 这时只能让第一个请求进行查询数据库, 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

如果我们是在单机环境下:直接使用常用的锁即可(如:Lock, Synchronized等), 在分布式环境下我们可以使用分布式锁, 如:基于数据库, 基于Redis或者zookeeper 的分布式锁. 

<img src="http://www.milky.show/images/redis/redis_85.png" alt="http://www.milky.show/images/redis/redis_85.png" style="zoom: 67%;" />



### 解决方法

**永久缓存**

可以将爆款的缓存失效时间设置为永久. 

**互斥锁**

利用互斥锁, 缓存失效的时候, 先去获得锁, 得到锁了, 再去请求数据库. 没得到锁, 则休眠一段时间重试. 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

## 缓存雪崩

缓存雪崩是指在某一个时间段内, 缓存集中过期失效, 如果这个时间段内有大量请求, 而查询数据量巨大, 所有的请求都会达到存储层, 存储层的调用量会暴增, 请求全部转发到 DB, DB 瞬时压力过重雪崩. 

1.  Redis突然宕机
2.  大部分数据失效

### 解决方法

**redis高可用**

redis有可能挂掉, 多增加几台redis实例, (一主多从或者多主多从), 这样一台挂掉之后其他的还可以继续工作, 其实就是搭建的集群. 

**限流降级**

在缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个key只允许一个线程查询数据和写缓存, 其他线程等待. 

**数据预热**

数据加热的含义就是在正式部署之前, 我先把可能的数据先预先访问一遍, 这样部分可能大量访问的数据就会加载到缓存中. 在即将发生大并发访问前手动触发加载缓存不同的key. 

**设置不同的失效时间**

对不同的数据使用不同的失效时间, 甚至对相同的数据, 不同的请求使用不同的失效时间, 例如, 我们要缓存 user 数据, 会对每个用户的数据设置不同的缓存过期时间, 可以定义一个基础时间, 假设10秒, 然后加上一个两秒以内的随机数, 过期时间为10～12秒, 就会避免缓存雪崩. 避免同一时间缓存全部失效

**双缓存**

缓存 A 和 B, 比如 A 的失效时间是 20 分钟, B 不失效. 比如从 A 中没读到, 就去 B 中读, 然后异步起一个线程同步到 A. 



## Redis, MySQL 双写一致性问题

最经典的缓存+数据库读写的模式, 就是 Cache Aside Pattern.读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.更新的时候, 先更新数据库, 然后再删除缓存.

**为什么是删除缓存, 而不是更新缓存?**

原因很简单, 很多时候, 在复杂点的缓存场景, 缓存不单单是数据库中直接取出来的值.比如可能更新了某个表的一个字段, 然后其对应的缓存, 是需要查询另外两个表的数据并进行运算, 才能计算出缓存最新的值的.

另外更新缓存的代价有时候是很高的. 是不是说, 每次修改数据库的时候, 都一定要将其对应的缓存更新一份? 也许有的场景是这样, 但是对于比较复杂的缓存数据计算的场景, 就不是这样了.

如果你频繁修改一个缓存涉及的多个表, 缓存也频繁更新.但是问题在于, 这个缓存到底会不会被频繁访问到? 

举个栗子, 一个缓存涉及的表的字段, 在 1 分钟内就修改了 20 次, 或者是 100 次, 那么缓存更新 20 次, 100 次; 但是这个缓存在 1 分钟内只被读取了 1 次, 有大量的冷数据.实际上, 如果你只是删除缓存的话, 那么在 1 分钟内, 这个缓存不过就重新计算一次而已, 开销大幅度降低, 用到缓存才去算缓存.

其实删除缓存, 而不是更新缓存, 就是一个 lazy 计算的思想, 不要每次都重新做复杂的计算, 不管它会不会用到, 而是让它到需要被使用的时候再重新计算.

像 mybatis, hibernate 都有懒加载思想.查询一个部门, 部门带了一个员工的 list, 没有必要说每次查询部门, 都把里面的 1000 个员工的数据也同时查出来.80% 的情况, 查这个部门, 就只是要访问这个部门的信息就可以了.先查部门, 同时要访问里面的员工, 那么这个时候只有在你要访问里面的员工的时候, 才会去数据库里面查询 1000 个员工.

### 先更新数据库, 后更新缓存

<img src="http://www.milky.show/images/redis/redis_74.png" alt="http://www.milky.show/images/redis/redis_74.png" style="zoom: 67%;" />

由上面流程图可知道, **请求 A 更新缓存应该比请求 B 更新缓存早才对, 但是因为网络等原因, B 却比 A 更早更新了缓存.**

这就导致了**脏数据**, 因此不考虑 先更新数据库, 后更新缓存 这个更新策略.



### 先删除缓存, 在更新数据库

<img src="http://www.milky.show/images/redis/redis_75.png" alt="http://www.milky.show/images/redis/redis_75.png" style="zoom:67%;" />

如果同时有一个**请求 A 进行更新操作, 另一个请求 B 进行查询操作**.

**就会导致不一致的情形出现**.而且, 如果不采用给缓存设置过期时间策略, 该数据永远都是脏数据.



### 先更新数据库, 在删除缓存

因为可能存在删除缓存失败的问题, 提供一个补偿措施即可, 例如利用消息队列.

FaceBook 也是采用这种方式.

当然, 这种方式也会产生数据不一致问题.

1.  缓存刚好失效

2.  请求A查询数据库, 得一个旧值

3.  请求B将新值写入数据库

4.  请求B删除缓存

5.  请求A将查到的旧值写入缓存



### 小结

一致性问题是分布式常见问题, 还可以再分为最终一致性和强一致性.数据库和缓存双写, 就必然会存在不一致的问题.答这个问题, 先明白一个前提.就是如果对数据有强一致性要求, 不能放缓存.我们所做的一切, 只能保证最终一致性.另外, 我们所做的方案其实从根本上来说, 只能说降低不一致发生的概率, 无法完全避免. **因此, 有强一致性要求的数据, 不能放缓存.**



## 热点 key 重建优化

### 三个目标

减少重建缓存的次数

数据尽可能一致

减少潜在危险

### 两个解决方法

**互斥锁(mutex key)**

```java
String get(String key) {
    String value = redis.get(key);
    if(value == null) {
        String mutexKey = "mutexKey:" + key;
        if(redis.set(mutexKey, "1", "ex 180", "nx")) {
            value = db.get(key);
            redis.set(key,  value);
            redis.delete(mutexKey);
        } else {
            // 其他线程休息 50 毫秒后重试
            Thread.sleep(50);
            get(key);
        }
    }
    return value;
}
```

**永不过期**

* 缓存层面: 没有设置过期使用(没有使用 expire)
* 功能层面: 为每个 value 添加逻辑过期时间, 但发现超过逻辑过期时间后, 会使用单独的线程去构建缓存

```java
String get(final String key) {
    V v = redis.get(key);
    String value = v.getValue();
    long logicTimeout = v.getValue();
    if (logicTimeout >= System.currentTimeMillis) {
        String mutexKey = "mutexKey:" + key;
        if (redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            // 异步更新后台执行
            threadPool.execute(new Runnable(){
                public void run() {
                    String dbValue = db.get(key);
                    redis.set(key,  (dbValue,  newLoginTimeout));
                    redis.delete(keyMutex);
                }
            });
        }
    }
    return value;
}
```

|   方案   |           优点            |                       缺点                       |
| :------: | :-----------------------: | :----------------------------------------------: |
|  互斥锁  |   思路简单, 保持一致性    |          代码复杂度增加, 存在死锁的风险          |
| 永不过期 | 基本杜绝热点 key 重建问题 | 不保证一致性, 逻辑过期时间增加维护成本和内存成本 |



## 