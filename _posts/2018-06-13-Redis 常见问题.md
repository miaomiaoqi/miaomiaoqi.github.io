---
layout: post
title: "Redis 常见问题"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## Redis 为什么用单线程

Redis的版本很多3.x、4.x、6.x，版本不同架构也是不同的，不限定版本问是否单线程也不太严谨。

1.   版本3.x ，最早版本，也就是大家口口相传的redis是单线程，阳哥2016年讲解的redis就是3.X的版本。

2.   版本4.x，严格意义来说也不是单线程，而是负责处理客户端请求的线程是单线程，但是开始加了点多线程的东西(异步删除)。---貌似

3.   2020年5月版本的6.0.x后及2022年出的7.0版本后，告别了大家印象中的单线程，用一种全新的多线程来解决问题。---实锤

Redis是单线程主要是指Redis的网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求时包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。这也是Redis对外提供键值存储服务的主要流程。

但Redis的其他功能，比如持久化RDB、AOF、异步删除、集群数据同步等等，其实是由额外的线程执行的。

Redis命令工作线程是单线程的，但是，整个Redis来说，是多线程的

### Redis3.x单线程时代但性能依旧很快的主要原因

基于内存操作：Redis 的所有数据都存在内存中，因此所有的运算都是内存级别的，所以他的性能比较高

数据结构简单：Redis 的数据结构是专门设计的，而这些简单的数据结构的查找和操作的时间大部分复杂度都是 O(1)，因此性能比较高；

多路复用和非阻塞 I/O：Redis使用 I/O多路复用功能来监听多个 socket连接客户端，这样就可以使用一个线程连接来处理多个请求，减少线程切换带来的开销，同时也避免了 I/O 阻塞操作

避免上下文切换：因为是单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生

### 既然单线程这么好, 为什么又加入了多线程特性

正常情况下使用 del 指令可以很快的删除数据，而当被删除的 key 是一个非常大的对象时，例如时包含了成千上万个元素的 hash 集合时，那么 del 指令就会造成 Redis 主线程卡顿。

这就是redis3.x单线程时代最经典的故障，大key删除的头疼问题，

由于redis是单线程的，del bigKey .....

等待很久这个线程才会释放，类似加了一个synchronized锁，你可以想象高并发下，程序堵成什么样子？

使用惰性删除可以有效避免 Redis 卡顿的问题

比如当我（Redis）需要删除一个很大的数据时，因为是单线程原子命令操作，这就会导致 Redis 服务卡顿，

于是在 Redis 4.0 中就新增了多线程的模块，当然此版本中的多线程主要是为了解决删除数据效率比较低的问题的。

| unlink key                                             |
| ------------------------------------------------------ |
| flushdb async                                          |
| flushall async                                         |
| 把删除工作交给了后台的小弟（子线程）异步来删除数据了。 |

因为Redis是单个主线程处理，redis之父antirez一直强调"Lazy Redis is better Redis".

而lazy free的本质就是把某些cost(主要时间复制度，占用主线程cpu时间片)较高删除操作，

从redis主线程剥离让bio子线程来处理，极大地减少主线阻塞时间。从而减少删除导致性能和稳定性问题。



## BigKey

### MoreKey

生产上限制 keys */flushdb/flushall 等危险命令以防止误删误用？通过配置设置禁用这些命令，redis.conf在SECURITY这一项中

使用 Scan 命令

SCAN 返回一个包含两个元素的数组， 

第一个元素是用于进行下一次迭代的新游标， 

第二个元素则是一个数组， 这个数组中包含了所有被迭代的元素。如果新游标返回零表示迭代已结束。

SCAN的遍历顺序

非常特别，它不是从第一维数组的第零位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。

### 多大算 BigKey

参考阿里规范, string 类型控制在 10kb 以内, hash, list, set, zset 元素个数不超过 5000 个

### 哪些危害

内存不均，集群迁移困难

超时删除，大key删除作梗

网络流量阻塞

### 如何产生

社交类: 王心凌粉丝列表，典型案例粉丝逐步递增

汇总统计: 某个报表, 月日年累计

### 如何发现

1.   redis-cli \--bigkeys

     **好处，见最下面总结**

     给出每种数据结构Top 1 bigkey，同时给出每种数据类型的键值个数+平均大小

     **不足**

     想查询大于10kb的所有key，\--bigkeys参数就无能为力了，**需要用到memory usage来计算每个键值的字节数**

     redis-cli --bigkeys -a 111111 

     | redis-cli -h 127.0.0.1 -p 6379 -a 111111 --bigkeys           |
     | ------------------------------------------------------------ |
     | 每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1 |

2.   memory usage

### 如何删除

非字符串的 bigkey, 不要使用 del 删除, 使用 hscan, sscan, zscan 方式渐进删除, 同时要防止 bigkey 过期自动删除问题(例如一个 200 万的 zset 设置 1 小时过期, 会触发 del 操作, 造成阻塞, 而且该操作不会出现在慢查询中(latency 可查))

string: 一般用del，如果过于庞大unlink

hash: 使用hscan每次获取少量field-value，再使用hdel删除每个field

list: 使用ltrim渐进式逐步删除，直到全部删除完成

set: 使用sscan每次获取部分元素，再使用srem命令删除每个元素

zset: 使用zscan每次获取部分元素，再使用ZREMRANGEBYRANK命令删除每个元素



### BigKey 生产调优



## fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

## 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

## AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

<img src="https://miaomiaoqi.github.io/images/redis/redis_64.png" alt="https://miaomiaoqi.github.io/images/redis/redis_64.png" style="zoom: 33%;" />

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 `no-appendfsync-on-rewrite=yes`, 根据写入量使用 SSD 磁盘



## 无底洞问题

2010 年, Facebook 有了 3000 个 Memcache 节点, 但是发现了一个问题, 加了一个机器后, 性能没能提升, 反而下降了, 因为在集群模式下, 批量操作会随着机器节点数的增加, 时间复杂度而增加, 批量操作的 key 会分散到不同的机器上去执行, 那么这条命令的性能就要等到最慢的那台机器返回才是真正执行完成

**如何优化**

* 命令本身优化: 例如慢查询 keys, hgetall bigkey

* 减少网络通信次数
* 降低接入成本: 例如客户端长连接/连接池, NIO 等



## 缓存预热

通过 @PostConstruct 预加载数据库中的数据到 redis 中, 防止用户流量一开始打到数据库中



## 缓存雪崩

缓存雪崩是指在某一个时间段内, 缓存集中过期失效, 如果这个时间段内有大量请求, 而查询数据量巨大, 所有的请求都会达到存储层, 存储层的调用量会暴增, 请求全部转发到 DB, DB 瞬时压力过重雪崩. 

1.  Redis突然宕机
2.  大部分数据失效

### 解决方法

**redis高可用**

redis有可能挂掉, 多增加几台redis实例, (一主多从或者多主多从), 这样一台挂掉之后其他的还可以继续工作, 其实就是搭建的集群. 

**限流降级**

在缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个key只允许一个线程查询数据和写缓存, 其他线程等待. 

**数据预热**

数据加热的含义就是在正式部署之前, 我先把可能的数据先预先访问一遍, 这样部分可能大量访问的数据就会加载到缓存中. 在即将发生大并发访问前手动触发加载缓存不同的key. 

**设置不同的失效时间**

对不同的数据使用不同的失效时间, 甚至对相同的数据, 不同的请求使用不同的失效时间, 例如, 我们要缓存 user 数据, 会对每个用户的数据设置不同的缓存过期时间, 可以定义一个基础时间, 假设10秒, 然后加上一个两秒以内的随机数, 过期时间为10～12秒, 就会避免缓存雪崩. 避免同一时间缓存全部失效

**双缓存**

缓存 A 和 B, 比如 A 的失效时间是 20 分钟, B 不失效. 比如从 A 中没读到, 就去 B 中读, 然后异步起一个线程同步到 A. 





## 缓存穿透

什么是缓存穿透, 它就是指当用户在查询一条数据的时候, 而此时数据库和缓存却没有关于这条数据的任何记录, 而这条数据在缓存中没找到就会向数据库请求获取数据. 它拿不到数据时, 是会一直查询数据库, 这样会对数据库的访问造成很大的压力. 

如:用户查询一个 id = -1 的商品信息, 一般数据库 id 值都是从 1 开始自增, 很明显这条信息是不在数据库中, 当没有信息返回时, 会一直向数据库查询, 给当前数据库的造成很大的访问压力. 

这时候我们要想一想, 该如何解决这个问题呢?

一般我们可以想到从缓存开始出发, 想如果我们给缓存设置一个如果当前数据库不存在的信息, 把它缓存成一个空对象, 返回给用户. 

这是一个解决方案, 也就是我们常说的缓存空对象(代码维护简单, 但是效果不是很好). 

Redis 也为我们提供了一种解决方案, 那就是布隆过滤器(代码维护比较复杂, 效果挺好的). 

在流量大时, 可能DB就挂掉了, 要是有人利用不存在的key频繁攻击我们的应用, 这就是漏洞. 

### 造成缓存穿透的原因

业务自身代码或者数据出现问题

一些恶意攻击, 爬虫等造成大量空命中

### 如何发现

监控业务的响应时间, 如果业务的响应时间突然变慢, 那么有可能是大量请求打到了存储层

业务本身逻辑问题

相关指标: 总调用数, 缓存层命中数, 存储层命中数

### 解决方法

#### 缓存空对象

空值做缓存, 再次接收到同样的查询请求时, 若命中缓存并且值为空, 就会直接返回, 不会透传到数据库, 避免缓存击穿, **即缓存层中存了更多的键, 这就需要更多的内存空间, 可以对其设置一个较短的过期时间, 让其自动清除**, 优点是实时性高, 代码维护简单. 当然, 有时恶意袭击者可以猜到我们使用了这种方案, 每次都会使用不同的参数来查询, 这就需要我们对输入的参数进行过滤, 例如, 如果我们使用ID进行查询, 则可以对ID的格式进行分析, 如果不符合产生ID的规则, 就直接拒绝, 或者在ID上放入时间信息, 根据时间信息判断ID是否合法, 或者是否是我们曾经生成的ID, 这样可以拦截一定的无效请求.

<img src="https://miaomiaoqi.github.io/images/redis/redis_81.png" alt="https://miaomiaoqi.github.io/images/redis/redis_81.png" style="zoom: 67%;" />

如果大量不存在的请求过来, 那么这时候缓存岂不是会缓存许多空对象了吗~~~

没错哦！这也是使用缓存空对象会导致的一个问题:如果时间一长这样会导致缓存中存在大量空对象, 这样不仅会占用许多的内存空间, 还会浪费许多资源呀！. 那这有没有什么可以解决的方法呢? 我们来想一想:我们可以将这些对象在一段时间之后清理下不久可以了吗 ~

嗯嗯, 没错！在想想 Redis 里是不是给我们提供了有关过期时间的命令呀(*^▽^*), 这样我们可以在设置空对象的时间, 顺便设置一个过期时间, 就可以解决个问题了呀！

```bash
setex key seconds valule:设置键值对的同时指定过期时间(s)
```

在Java 中直接调用 API 操作即可:

```java
redisCache.put(Integer.toString(id), null, 60) //过期时间为 60s
```



#### 布隆过滤器拦截

如果布隆过滤器认为某个键不存在, 那么就不会访问存储层, 适用于数据命中不高, 数据相对固定实时性低(通常是数据集较大)的应用场景, 代码维护较为复杂, 但是缓存空间占用少

我们也可以简单理解为是一个不怎么精确的 set 结构(set 具有去重的效果). 但是有个小问题是:当你使用它的 contains 方法去判断某个对象是否存在时, 它可能会误判. 也就是说布隆过滤器不是特别不精确, 但是只要参数设置的合理, 它的精确度可以控制的相对足够精确, 只会有小小的误判概率(这是可以接受的呀 ~). 当布隆过滤器说某个值存在时, 这个值可能不存在；当它说不存在时, 那就肯定不存在. 

布隆过滤器的特点

1.  一个非常大的二进制位数组(数组中只存在 0 和 1)
2.  拥有若干个哈希函数(Hash Function)
3.  在空间效率和查询效率都非常高
4.  布隆过滤器不会提供删除方法, 在代码维护上比较困难. 

每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数. 所谓无偏就是能够把元素的 hash 值算得比较均匀. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_82.png" alt="https://miaomiaoqi.github.io/images/redis/redis_82.png" style="zoom: 67%;" />

向布隆过滤器中添加 key 时, 会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置, 每个 hash 函数都会算得一个不同的位置. 再把位数组的这几个位置都置为 1 就完成了 add 操作. ( 每一个 key 都通过若干的hash函数映射到一个巨大位数组上, 映射成功后, 会在把位数组上对应的位置改为1. )

**那为什么布隆过滤器会存在误判率呢?**

误判吗? 人生哪有不摔跤, 只要锄头挥得好, 照样能挖到. (咳咳咳, 说偏了...)

其实它会误判是如下这个情况:

<img src="https://miaomiaoqi.github.io/images/redis/redis_83.png" alt="https://miaomiaoqi.github.io/images/redis/redis_83.png" style="zoom: 67%;" />

当 key1 和 key2 映射到位数组上的位置为 1 时, 假设这时候来了个 key3, 要查询是不是在里面, 恰好 key3 对应位置也映射到了这之间, 那么布隆过滤器会认为它是存在的, 这时候就会产生误判(因为明明 key3 是不在的). 

O(∩_∩)O哈哈~, 这时候你会问了:如何提高布隆过滤器的准确率呢? 

**要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:**

1.  哈希函数的好坏
2.  存储空间大小
3.  哈希函数个数

hash函数的设计也是一个十分重要的问题, 对于好的hash函数能大大降低布隆过滤器的误判率. 

(这就好比优秀的配件之所以能够运行这么顺畅就在于其内部设计的得当)

同时, 对于一个布隆过滤器来说, 如果其位数组越大的话, 那么每个key通过hash函数映射的位置会变得稀疏许多, 不会那么紧凑, 有利于提高布隆过滤器的准确率. 同时, 对于一个布隆过滤器来说, 如果key通过许多hash函数映射, 那么在位数组上就会有许多位置有标志, 这样当用户查询的时候, 在通过布隆过滤器来找的时候, 误判率也会相应降低. 

#### Google 布隆过滤器 Guava 解决缓存穿透



### 如何选择

针对于一些恶意攻击, 攻击带过来的大量 key 是不存在的, 那么我们采用第一种方案就会缓存大量不存在 key 的数据.此时我们采用第一种方案就不合适了, 我们完全可以先对使用第二种方案进行过滤掉这些 key.针对这种 key 异常多, 请求重复率比较低的数据, 我们就没有必要进行缓存, 使用第二种方案直接过滤掉.而对于空数据的 key 有限的, 重复率比较高的, 我们则可以采用第一种方式进行缓存.





## 缓存击穿

缓存击穿是指有某个key经常被查询, 经常被用户特殊关怀, 用户非常 love 它 (*^▽^*), 也就类比“熟客” 或者 一个key经常不被访问. 但是这时候, 如果这个key在缓存的过期时间失效的时候或者这是个冷门key时, 这时候突然有大量有关这个key的访问请求, 这样会导致大并发请求直接穿透缓存, 请求数据库, 瞬间对数据库的访问压力增大, 这个和缓存雪崩的区别在于这里针对某一key缓存, 前者则是很多key. 

**归纳起来:造成缓存击穿的原因有两个. **

(1)一个“冷门”key, 突然被大量用户请求访问. 

(2)一个“热门”key, 在缓存中时间恰好过期, 这时有大量用户来进行访问. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_84.png" alt="https://miaomiaoqi.github.io/images/redis/redis_84.png" style="zoom: 67%;" />

对于缓存击穿的问题:我们常用的解决方案是加锁. 对于key过期的时候, 当key要查询数据库的时候加上一把锁, 这时只能让第一个请求进行查询数据库, 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

如果我们是在单机环境下:直接使用常用的锁即可(如:Lock, Synchronized等), 在分布式环境下我们可以使用分布式锁, 如:基于数据库, 基于Redis或者zookeeper 的分布式锁. 

<img src="https://miaomiaoqi.github.io/images/redis/redis_85.png" alt="https://miaomiaoqi.github.io/images/redis/redis_85.png" style="zoom: 67%;" />



### 解决方法

**永久缓存**

可以将爆款的缓存失效时间设置为永久. 

**互斥锁**

利用互斥锁, 缓存失效的时候, 先去获得锁, 得到锁了, 再去请求数据库. 没得到锁, 则休眠一段时间重试. 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 



## Redis 分布式锁







## Redis, MySQL 双写一致性问题

最经典的缓存+数据库读写的模式, 就是 Cache Aside Pattern.读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.更新的时候, 先更新数据库, 然后再删除缓存.

**为什么是删除缓存, 而不是更新缓存?**

原因很简单, 很多时候, 在复杂点的缓存场景, 缓存不单单是数据库中直接取出来的值.比如可能更新了某个表的一个字段, 然后其对应的缓存, 是需要查询另外两个表的数据并进行运算, 才能计算出缓存最新的值的.

另外更新缓存的代价有时候是很高的. 是不是说, 每次修改数据库的时候, 都一定要将其对应的缓存更新一份? 也许有的场景是这样, 但是对于比较复杂的缓存数据计算的场景, 就不是这样了.

如果你频繁修改一个缓存涉及的多个表, 缓存也频繁更新.但是问题在于, 这个缓存到底会不会被频繁访问到? 

举个栗子, 一个缓存涉及的表的字段, 在 1 分钟内就修改了 20 次, 或者是 100 次, 那么缓存更新 20 次, 100 次; 但是这个缓存在 1 分钟内只被读取了 1 次, 有大量的冷数据.实际上, 如果你只是删除缓存的话, 那么在 1 分钟内, 这个缓存不过就重新计算一次而已, 开销大幅度降低, 用到缓存才去算缓存.

其实删除缓存, 而不是更新缓存, 就是一个 lazy 计算的思想, 不要每次都重新做复杂的计算, 不管它会不会用到, 而是让它到需要被使用的时候再重新计算.

像 mybatis, hibernate 都有懒加载思想.查询一个部门, 部门带了一个员工的 list, 没有必要说每次查询部门, 都把里面的 1000 个员工的数据也同时查出来.80% 的情况, 查这个部门, 就只是要访问这个部门的信息就可以了.先查部门, 同时要访问里面的员工, 那么这个时候只有在你要访问里面的员工的时候, 才会去数据库里面查询 1000 个员工.

### 先更新数据库, 后更新缓存

<img src="https://miaomiaoqi.github.io/images/redis/redis_74.png" alt="https://miaomiaoqi.github.io/images/redis/redis_74.png" style="zoom: 67%;" />

由上面流程图可知道, **请求 A 更新缓存应该比请求 B 更新缓存早才对, 但是因为网络等原因, B 却比 A 更早更新了缓存.**

这就导致了**脏数据**, 因此不考虑 先更新数据库, 后更新缓存 这个更新策略.



### 先删除缓存, 在更新数据库

<img src="https://miaomiaoqi.github.io/images/redis/redis_75.png" alt="https://miaomiaoqi.github.io/images/redis/redis_75.png" style="zoom:67%;" />

如果同时有一个**请求 A 进行更新操作, 另一个请求 B 进行查询操作**.

**就会导致不一致的情形出现**.而且, 如果不采用给缓存设置过期时间策略, 该数据永远都是脏数据.



### 先更新数据库, 在删除缓存

因为可能存在删除缓存失败的问题, 提供一个补偿措施即可, 例如利用消息队列.

FaceBook 也是采用这种方式.

当然, 这种方式也会产生数据不一致问题.

1.  缓存刚好失效

2.  请求A查询数据库, 得一个旧值

3.  请求B将新值写入数据库

4.  请求B删除缓存

5.  请求A将查到的旧值写入缓存



### 小结

一致性问题是分布式常见问题, 还可以再分为最终一致性和强一致性.数据库和缓存双写, 就必然会存在不一致的问题.答这个问题, 先明白一个前提.就是如果对数据有强一致性要求, 不能放缓存.我们所做的一切, 只能保证最终一致性.另外, 我们所做的方案其实从根本上来说, 只能说降低不一致发生的概率, 无法完全避免. **因此, 有强一致性要求的数据, 不能放缓存.**



## 热点 key 重建优化

### 三个目标

减少重建缓存的次数

数据尽可能一致

减少潜在危险

### 两个解决方法

**互斥锁(mutex key)**

```java
String get(String key) {
    String value = redis.get(key);
    if(value == null) {
        String mutexKey = "mutexKey:" + key;
        if(redis.set(mutexKey, "1", "ex 180", "nx")) {
            value = db.get(key);
            redis.set(key,  value);
            redis.delete(mutexKey);
        } else {
            // 其他线程休息 50 毫秒后重试
            Thread.sleep(50);
            get(key);
        }
    }
    return value;
}
```

**永不过期**

* 缓存层面: 没有设置过期使用(没有使用 expire)
* 功能层面: 为每个 value 添加逻辑过期时间, 但发现超过逻辑过期时间后, 会使用单独的线程去构建缓存

```java
String get(final String key) {
    V v = redis.get(key);
    String value = v.getValue();
    long logicTimeout = v.getValue();
    if (logicTimeout >= System.currentTimeMillis) {
        String mutexKey = "mutexKey:" + key;
        if (redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            // 异步更新后台执行
            threadPool.execute(new Runnable(){
                public void run() {
                    String dbValue = db.get(key);
                    redis.set(key,  (dbValue,  newLoginTimeout));
                    redis.delete(keyMutex);
                }
            });
        }
    }
    return value;
}
```

|   方案   |           优点            |                       缺点                       |
| :------: | :-----------------------: | :----------------------------------------------: |
|  互斥锁  |   思路简单, 保持一致性    |          代码复杂度增加, 存在死锁的风险          |
| 永不过期 | 基本杜绝热点 key 重建问题 | 不保证一致性, 逻辑过期时间增加维护成本和内存成本 |





## 单线程 Redis 为什么这么快?

**完全基于内存，绝大部分请求是纯粹的内存操作，非常快速**

**基本对象使用多种底层数据结构, 且灵活变化是 redis 高性能的另一个原因**

**采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗**

**采用了非阻塞 I/O 多路复用机制**

我们现在要仔细的说一说I/O多路复用机制, 因为这个说法实在是太通俗了, 通俗到一般人都不懂是什么意思.博主打一个比方: 小曲在S城开了一家快递店, 负责同城快送服务.小曲因为资金限制, 雇佣了一批快递员, 然后小曲发现资金不够了, 只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递, 小曲就让一个快递员盯着, 然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题

    几十个快递员基本上时间都花在了抢车上了, 大部分快递员都处在闲置状态, 谁抢到了车, 谁就能去送快递

    随着快递的增多, 快递员也越来越多, 小曲发现快递店里越来越挤, 没办法雇佣新的快递员了

    快递员之间的协调很花时间

    综合上述缺点, 小曲痛定思痛, 提出了下面的经营方式

* 经营方式二

    小曲只雇佣一个快递员.然后呢, 客户送来的快递, 小曲按送达地点标注好, 然后依次放在一个地方.最后, 那个快递员依次的去取快递, 一次拿一个, 然后开着车去送快递, 送好了就回来拿下一个快递.

    对比上述两种经营方式对比, 是不是明显觉得第二种, 效率更高, 更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:

    * 经营方式一就是传统的并发模型, 每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员), 通过跟踪每个I/O流的状态(每个快递的送达地点), 来管理多个I/O流.

    下面类比到真实的redis线程模型, 如图所示

    <img src="https://miaomiaoqi.github.io/images/redis/redis_1.png" alt="https://miaomiaoqi.github.io/images/redis/redis_1.png" style="zoom:50%;" />





## IO 多路复用

### 多路复用解决的问题

并发多客户端连接，在多路复用之前最简单和典型的方案：同步阻塞网络IO模型

这种模式的特点就是用一个进程来处理一个网络连接(一个用户请求)，比如一段典型的示例代码如下。

直接调用 recv 函数从一个 socket 上读取数据。

```c
int main() {
	...
	recv(sock, ...) // 从用户角度来看非常简单，一个recv一用，要接收的数据就到我们手里了。
}
```

我们来总结一下这种方式：

*   优点就是这种方式非常容易让人理解，写起代码来非常的自然，符合人的直线型思维。

*   缺点就是性能差，每个用户请求到来都得占用一个进程来处理，来一个请求就要分配一个进程跟进处理，

*   类似一个学生配一个老师，一位患者配一个医生，可能吗？进程是一个很笨重的东西。一台服务器上创建不了多少个进程。

进程在 Linux 上是一个开销不小的家伙，先不说创建，光是上下文切换一次就得几个微秒。所以为了高效地对海量用户提供服务，必须要让一个进程能同时处理很多个 tcp 连接才行。现在假设一个进程保持了 10000 条连接，那么如何发现哪条连接上有数据可读了、哪条连接可写了 ？

我们当然可以采用循环遍历的方式来发现 IO 事件，但这种方式太低级了。

我们希望有一种更高效的机制，在很多连接中的某条上有 IO 事件发生的时候直接快速把它找出来。

其实这个事情 Linux 操作系统已经替我们都做好了，它就是我们所熟知的 IO 多路复用机制。这里的复用指的就是对进程的复用

I/O: 网络 I/O

多路：多个客户端连接（连接就是套接字描述符，即 socket 或者 channel），指的是多条 TCP 连接

复用：用一个进程来处理多条的连接，使用单进程就能够实现同时处理多个客户端的连接

实现了用一个进程来处理大量的用户连接, 可以分select->poll->epoll三个阶段来描述。



### Redis的IO多路复用

Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，一次放到文件事件分派器，事件分派器将事件分发给事件处理器。

<img src="https://miaomiaoqi.github.io/images/redis/redis_110.png" alt="https://miaomiaoqi.github.io/images/redis/redis_110.png" style="zoom:50%;" /> 

Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现

 

所谓 I/O 多路复用机制，就是说通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。这种机制的使用需要 select 、 poll 、 epoll 来配合。多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。

Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符） 

Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：

*   多个套接字、

*   IO多路复用程序、

*   文件事件分派器、

*   事件处理器。

因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型

从Redis6开始，将网络数据读写、请求协议解析通过多个IO线程的来处理 ，对于真正的命令执行来说，仍然使用单线程操作，一举两得，便宜占尽！！！

<img src="https://miaomiaoqi.github.io/images/redis/redis_111.png" alt="https://miaomiaoqi.github.io/images/redis/redis_111.png" style="zoom:50%;" /> 



### 吃米线举例

上午开会，错过了公司食堂的饭点， 中午就和公司的首席架构师一起去楼下的米线店去吃米线。我们到了一看，果然很多人在排队。

 

架构师马上发话了：嚯，请求排队啊！你看这位收银点菜的，像不像nginx的反向代理？只收请求，不处理，把请求都发给后厨去处理。

我们交了钱，拿着号离开了点餐收银台，找了个座位坐下等餐。

架构师：你看，这就是异步处理，我们下了单就可以离开等待，米线做好了会通过小喇叭“回调”我们去取餐；

如果同步处理，我们就得在收银台站着等餐，后面的请求无法处理，客户等不及肯定会离开了。

 

接下里架构师盯着手中的纸质号牌。

 

架构师：你看，这个纸质号牌在后厨“服务器”那里也有，这不就是表示会话的ID吗？

有了它就可以把大家给区分开，就不会把我的排骨米线送给别人了。过了一会， 排队的人越来越多，已经有人表示不满了，可是收银员已经满头大汗，忙到极致了。

 

架构师：你看他这个系统缺乏弹性扩容， 现在这么多人，应该增加收银台，可以没有其他收银设备，老板再着急也没用。

老板看到在收银这里帮不了忙，后厨的订单也累积得越来越多， 赶紧跑到后厨亲自去做米线去了。

 

架构师又发话了：幸亏这个系统的后台有并行处理能力，可以随意地增加资源来处理请求（做米线）。

我说：他就这点儿资源了，除了老板没人再会做米线了。

不知不觉，我们等了20分钟， 但是米线还没上来。

架构师：你看，系统的处理能力达到极限，超时了吧。

这时候收银台前排队的人已经不多了，但是还有很多人在等米线。

 

老板跑过来让这个打扫卫生的去收银，让收银小妹也到后厨帮忙。打扫卫生的做收银也磕磕绊绊的，没有原来的小妹灵活。

 

架构师：这就叫服务降级，为了保证米线的服务，把别的服务都给关闭了。

又过了20分钟，后厨的厨师叫道：237号， 您点的排骨米线没有排骨了，能换成番茄的吗？

架构师低声对我说：瞧瞧， 人太多， 系统异常了。然后他站了起来：不行，系统得进行补偿操作：退费。

 

说完，他拉着我，饿着肚子，头也不回地走了。



同步: 调用者要一直等待调用结果的通知后才能进行后续的执行，现在就要，我可以等，等出结果为止

异步: 指被调用方先返回应答让调用者先回去，然后再计算调用结果，计算完最终结果后再通知并返回给调用方, 异步调用要想获得结果一般通过回调

同步与异步的理解: 同步、异步的讨论对象是被调用者(服务提供者)，重点在于获得调用结果的消息通知方式上

阻塞: 调用方一直在等待而且别的事情什么都不做，当前进/线程会被挂起，啥都不干

非阻塞: 调用在发出去后，调用方先去忙别的事情，不会阻塞当前进/线程，而会立即返回

阻塞与非阻塞的理解: 阻塞、非阻塞的讨论对象是调用者(服务请求者)，重点在于等消息时候的行为，调用者是否能干其它事

4 种组合方式:

*   同步阻塞：服务员说快到你了，先别离开我后台看一眼马上通知你。客户在海底捞火锅前台干等着，啥都不干。
*   同步非阻塞：服务员说快到你了，先别离开。客户在海底捞火锅前台边刷抖音边等着叫号
*   异步阻塞：服务员说还要再等等，你先去逛逛，一会儿通知你。客户怕过号在海底捞火锅前台拿着排号小票啥都不干，一直等着店员通知
*   异步非阻塞：服务员说还要再等等，你先去逛逛，一会儿通知你。拿着排号小票+刷着抖音，等着店员通知



### I/O 多路复用

I/O多路复用在英文中其实叫 I/O multiplexing

I/O multiplexing 这里面的 multiplexing 指的其实是在单个线程通过记录跟踪每一个Sock(I/O流)的状态来同时管理多个I/O流. 目的是尽量多的提高服务器的吞吐能力。

大家都用过nginx，nginx使用epoll接收请求，ngnix会有很多链接进来， epoll会把他们都监视起来，然后像拨开关一样，谁有数据就拨向谁，然后调用相应的代码处理。redis类似同理

#### 文件描述符

文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。



#### 是什么

IO multiplexing就是我们说的select，poll，epoll，有些技术书籍也称这种IO方式为event driven IO事件驱动IO。就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。可以基于一个阻塞对象并同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程，每次new一个线程)，这样可以大大节省系统资源。所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select，poll，epoll等函数就可以返回。

<img src="https://miaomiaoqi.github.io/images/redis/redis_112.png" alt="https://miaomiaoqi.github.io/images/redis/redis_112.png" style="zoom:50%;" />



#### 说人话

模拟一个tcp服务器处理30个客户socket，一个监考老师监考多个学生，谁举手就应答谁。

假设你是一个监考老师，让30个学生解答一道竞赛考题，然后负责验收学生答卷，你有下面几个选择：

第一种选择：按顺序逐个验收，先验收A，然后是B，之后是C、D。。。这中间如果有一个学生卡住，全班都会被耽误,你用循环挨个处理socket，根本不具有并发能力。 

第二种选择：你创建30个分身线程，每个分身线程检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。

第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。这种就是IO复用模型。Linux下的select、poll和epoll就是干这个的。

将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor反应模式。



#### Redis单线程如何处理那么多并发客户端连接，为什么单线程，为什么快

Redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到事件分派器，事件分派器将事件分发给事件处理器。

<img src="https://miaomiaoqi.github.io/images/redis/redis_113.png" alt="https://miaomiaoqi.github.io/images/redis/redis_113.png" style="zoom:50%;" />

Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符） 

所谓 I/O 多路复用机制，就是说通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。这种机制的使用需要 select 、 poll 、 epoll 来配合。多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。

所谓 I/O 多路复用机制，就是说通过一种考试监考机制，一个老师可以监视多个考生，一旦某个考生举手想要交卷了，能够通知监考老师进行相应的收卷子或批改检查操作。所以这种机制需要调用班主任(select/poll/epoll)来配合。多个考生被同一个班主任监考，收完一个考试的卷子再处理其它人，无需等待所有考生，谁先举手就先响应谁，当又有考生举手要交卷，监考老师看到后从讲台走到考生位置，开始进行收卷处理。



### Reactor 模式

基于 I/O 复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。

Reactor 模式，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式。即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术。

<img src="https://miaomiaoqi.github.io/images/redis/redis_114.png" alt="https://miaomiaoqi.github.io/images/redis/redis_114.png" style="zoom:50%;" />

Reactor 模式中有 2 个关键组成：

*   Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人；

*   Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际办理人。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。

Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）

Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。

它的组成结构为4部分：

*   多个套接字、

*   IO多路复用程序、

*   文件事件分派器、

*   事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型



### select 方法

优点

*   select 其实就是把NIO中用户态要遍历的fd数组(我们的每一个socket链接，安装进ArrayList里面的那个)拷贝到了内核态，让内核态来遍历，因为用户态判断socket是否有数据还是要调用内核态的，所有拷贝到内核态后，这样遍历判断的时候就不用一直用户态和内核态频繁切换了
*   从代码中可以看出，select系统调用后，返回了一个置位后的&rset，这样用户态只需进行很简单的二进制比较，就能很快知道哪些socket需要read数据，有效提高了效率

缺点

1、bitmap最大1024位，一个进程最多只能处理1024个客户端

 

2、&rset不可重用，每次socket有数据就相应的位会被置位

 

3、文件描述符数组拷贝到了内核态(只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）)，仍然有开销。select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）

 

4、select并没有通知用户态哪一个socket有数据，仍然需要O(n)的遍历。select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）

 

 

我们自己模拟写的是，RedisServerNIO.java,只不过将它内核化了

select方式，既做到了一个线程处理多个客户端连接（文件描述符），又减少了系统调用的开销（多个文件描述符只有一次 select 的系统调用 + N次就绪状态的文件描述符的 read 系统调用

### poll 方法

优点

1、poll使用pollfd数组来代替select中的bitmap，数组没有1024的限制，可以一次管理更多的client。它和 select 的主要区别就是，去掉了 select 只能监听 1024 个文件描述符的限制。

 

2、当pollfds数组中有事件发生，相应的revents置位为1，遍历的时候又置位回零，实现了pollfd数组的重用

缺点

poll 解决了select缺点中的前两条，其本质原理还是select的方法，还存在select中原来的问题 

*   pollfds数组拷贝到了内核态，仍然有开销

*   poll并没有通知用户态哪一个socket有数据，仍然需要O(n)的遍历

### epoll 方法

多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，

变成了一次系统调用 + 内核层遍历这些文件描述符。

epoll是现在最先进的IO多路复用器，Redis、Nginx，linux中的Java NIO都使用的是epoll。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。

1、一个socket的生命周期中只有一次从用户态拷贝到内核态的过程，开销小

2、使用event事件通知机制，每次socket中有数据会主动通知内核，并加入到就绪链表中，不需要遍历所有的socket

 

在多路复用IO模型中，会有一个内核线程不断地去轮询多个 socket 的状态，只有当真正读写事件发送时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有真正有读写事件进行时，才会使用IO资源，所以它大大减少来资源占用。多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈





<img src="https://miaomiaoqi.github.io/images/redis/redis_115.png" alt="https://miaomiaoqi.github.io/images/redis/redis_115.png" style="zoom:50%;" />







 多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，

变成了一次系统调用 + 内核层遍历这些文件描述符。 

所谓 I/O 多路复用机制，就是说通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。这种机制的使用需要 select 、 poll 、 epoll 来配合。多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象上等待，无需阻塞等待所有连接。当某条连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理；



<img src="https://miaomiaoqi.github.io/images/redis/redis_116.png" alt="https://miaomiaoqi.github.io/images/redis/redis_116.png" style="zoom:50%;" />





在Redis6/7中，非常受关注的第一个新特性就是多线程。

这是因为，Redis一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF重写）。但是，从网络IO处理到实际的读写命令处理，都是由单个线程完成的。

 

随着网络硬件的性能提升，Redis的性能瓶颈有时会出现在网络IO的处理上，也就是说，单个主线程处理网络请求的速度跟不上底层网络硬件的速度,

 

为了应对这个问题:

采用多个IO线程来处理网络请求，提高网络请求处理的并行度，Redis6/7就是采用的这种方法。

 

但是，Redis的多IO线程只是用来处理网络请求的，对于读写操作命令Redis仍然使用单线程来处理。这是因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥加锁机制了(不管加锁操作处理)，这样一来，Redis线程模型实现就简单了