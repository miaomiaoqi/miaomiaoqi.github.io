---
layout: post
title: Java 并发知识
categories: [Java]
description: 
keywords: 
---

* content
{:toc}


## 基本概念

* 并发

    同时拥有两个或者多个线程, 如果程序在单核处理器上运行, 多个线程将交替地换入或者换出内存, 这些线程是同时"存在"的, 每个线程都处于执行过程中的某个状态, 如果运行在多核处理器上, 此时, 程序中的每个线程都将分配到一个处理器核上, 因此可以同时运行

    多个线程操作相同的资源, **保证线程安全**, 合理使用资源

* 高并发

    高并发(High Concurrency)是互联网分布式系统架构设计中必须考虑的因素之一, 它通常是指, 通过设计保证系统能够**同时并行处理**很多请求

    服务能同时处理很多请求, **提高程序性能**

* CPU多级缓存

    CPU的频率太快了, 快到主存跟不上, 这样在处理器时钟周期内, CPU常常需要等待主存, 浪费资源. 所以Cache出现, 是为了缓解CPU和内存之间速度的不匹配问题(结构: cpu -> cache -> memory)

    * CPU Cache有什么意义

        1. 时间局部性: 如果某个数据被访问, 那么在不久的将来它可能再次被访问

        1. 空间局部性: 如果某个数据被访问, 那么与它相邻的数据很快也可能被访问

    * 缓存一致性(MESI)

        用于保证多个CPU Cache之间缓存共享数据的一致

        <img src="http://www.milky.show/images/concurrency/1.png" alt="http://www.milky.show/images/concurrency/1.png" style="zoom:67%;" />

* CPU乱序执行优化

    处理器为提高运算速度而做出违背代码原有顺序的优化

* Java内存模型(Java Memory Model, JMM)

    规范Java虚拟机与计算机内存是如何协调工作的, 规定了一个线程如何和何时可以看到其他线程修改过的共享变量的值, 以及在必须时如何同步地访问共享变量

    <img src="http://www.milky.show/images/concurrency/2.png" alt="http://www.milky.show/images/concurrency/1.png" style="zoom: 50%;" />

    * 同步八种操作

        1. lock(锁定)

            作用于主内存的变量, 把一个变量标识位一条线程独占的状态

        1. unlock(解锁)

            作用于主内存的变量, 把一个处于锁定状态的变量释放出来, 释放后的变量才可以被其他线程锁定

        1. read(读取)

            作用于主内存的变量, 把一个变量值从主内存传输到线程的工作内存中, 以便随后的load动作使用

        1. load(载入)

            作用于工作内存的变量, 它把read操作从主内存中得到的变量值放入工作内存的变量副本中

        1. use(使用)

            作用于工作内存的变量, 把工作内存中的一个变量值传递给执行引擎

        1. assign(赋值)

            作用于工作内存的变量, 它把一个从执行引擎接收到的值赋值给工作内存的变量

        1. store(存储)

            作用于工作内存的变量, 把工作内存中的一个变量的值传送到主内存中, 以便随后的write的操作

        1. write(写入)

            作用于主内存的变量, 它把store操作从工作内存中一个变量的值传送到主内存的变量中

    * 同步规则

        1. 如果要把一个变量从主内存中复制到工作内存中, 就需要按顺序的执行read和load操作, 如果把变量从工作内存中同步回主内存中, 就要按顺序的执行store和write操作. 但java内存模型只要求上述操作必须按顺序执行, 而没有保证必须是连续执行

        1. 不允许read和load, store和write操作之一单独出现

        1. 不允许一个线程丢弃它的最近assign的操作, 即变量在工作内存中改变了之后必须同步到主内存中

        1. 不允许一个线程无原因地(没有发生过任何assign操作)把数据从工作内存同步回主内存中

        1. 一个新的变量只能在主内存中诞生, 不允许在工作内存中直接使用一个未初始化(load或assign)的变量. 即就是对一个变量实施use和store操作之前, 必须先执行过了assign和load操作

        1. 一个变量在同一时刻只允许一条线程对其进行lock操作, 但lock操作可以被同一条线程重复执行多次, 多次执行lock后, 只有执行相同次数的unlock操作, 变量才会被解锁. lock和unlock必须成对出现

        1. 如果一个变量执行lock操作, 将会清空工作内存中此变量的值, 在执行引擎使用这个变量前需重新执行load或assign操作初始化变量的值

        1. 如果一个变量事先没有被lock操作锁定, 则不允许对它执行unlock操作; 也不允许去unlock一个被其他线程锁定的变量

        1. 对一个变量执行unlock操作之前, 必须先把此变量同步到主内存中(执行store和write操作)

        <img src="http://www.milky.show/images/concurrency/3.png" alt="http://www.milky.show/images/concurrency/1.png" style="zoom: 50%;" />

        <img src="http://www.milky.show/images/concurrency/4.png" alt="http://www.milky.show/images/concurrency/1.png" style="zoom:50%;" />









## 线程安全性

当多个线程访问某个类时, 不管运行时环境采用何种调度方式或者这些进程将如何交替执行, 并且在主调代码中不需要任何额外的同步或协同, 这个类都能表现出正确的行为, 那么就称这个类是线程安全的

### 原子性

提供了互斥访问, 同一时刻只能有一个线程来对它进行操作

* Atomic包

    AtomicXXX: CAS, Unsafe.compareAndSwapInt

    AtomicLong和LongAdder

    AtomicReference, AtomicXxxFieldUpdater

    AtomicStampReference 解决CAS的ABA问题

    AtomicBoolean

* 锁

    synchronized 依赖 JVM

    * 修饰代码块

        大括号括起来的对象, 作用于**调用的对象**

    * 修饰方法

        整个方法, 作用于**调用的对象**

    * 修饰静态方法

        整个静态方法, 作用于**所有对象**

    * 修饰类

        括号括起来的部分, 作用于**所有对象**

    Lock 依赖特殊的 CPU 指令, 代码实现, ReentrantLock

* 对比

    * synchronized

        不可中断锁, 适合竞争不激烈, 可读性好

    * Lock

        可中断锁, 多样化同步, 竞争激烈时能维持常态

    * Atomic

        竞争激烈时能维持常态, 比Lock性能好, 但只能同步一个值

### 可见性

一个线程对主内存的修改可以及时的被其他线程观察到

导致共享变量在线程间不可见的原因

* 线程交叉执行

* 重排序结合线程交叉执行

* 共享变量更新后的值没有在工作内存与主内存间及时更新

JMM 关于 synchronized的两条规定

* 线程解锁前, 必须把共享变量的最新值刷新到主内存中

* 线程加锁前, 将清空工作内存中共享变量的值, 从而使用共享变量时需要从主内存中重新读取最新的值**(加锁与解锁是同一把锁)**

volatile关键字, 通过加入内存屏障和禁止重排序优化来实现

* 对volatile变量写操作时, 会在写操作后加入一条store屏障指令, 将本地内存中的共享变量值刷新到主存中

    <img src="http://www.milky.show/images/concurrency/5.png" alt="http://www.milky.show/images/concurrency/5.png" style="zoom:50%;" />

* 对volatile变量读操作时, 会在读操作前加入一条load屏障指令, 从主内存中读取共享变量

    <img src="http://www.milky.show/images/concurrency/6.png" alt="http://www.milky.show/images/concurrency/6.png" style="zoom:50%;" />

### 有序性

一个线程观察其他线程中的指令执行顺序, 由于指令重排序的存在, 该观察结果一般杂乱无序

在Java内存模型中, 允许编译器和处理器对指令进行重排序, 但是重排序过程不会影响到单线程程序的执行, 却会影响到多线程并发执行的正确性

* happens-before原则

    * 程序次序规则

        一个线程内, 按照代码顺序, 书写在前面的操作先行发生于书写在后面的操作, 只是保证单线程操作的正确性

    * 锁定规则

        一个unlock操作先行发生于后面对同一个锁的lock操作

    * volatile变量规则

        对一个变量的写操作先行发生于后面对这个变量的读操作

    * 传递规则

        如果操作A先行发生于操作B, 而操作B又先行发生于操作C, 则可以得出操作A先行发生于操作C

    * 线程启动原则

        Thread对象的start()方法先行发生于此线程的每一个动作

    * 线程中断规则

        对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生

    * 线程终结规则

        线程中所有操作都先行发生于线程的终止检测, 我们可以通过Thread.join()方法结束. Thread.isAlive()的返回值手段检测到线程已经终止执行

    * 对象终结规则

        一个对象的初始化完成先行发生于他的finalize()方法的开始



## Lock 简介, 地位, 作用

锁是一种工具, 用于控制对共享资源的访问

Lock 和 Synchronized, 这两个是最常见的锁, 它们都可以达到线程安全的目的, 但是在使用上和功能上又有较大的不同

Lock 并不是用来代替 Synchronized 的, 而是当使用 Synchronized 不合适或不足以满足要求的时候, 来提供高级功能的

Lock 接口最常见的实现类是 ReentrantLock

### 为什么需要 Lock

#### 为什么 synchronized 不够用

效率低: 锁的释放情况少, 试图获得锁时不能设定超时, 不能中断一个正在试图获得锁的线程

不够灵活(读写锁更灵活): 加锁和释放的时机单一, 每个锁仅有单一的条件(某个对象), 可能是不够的

#### Lock 主要方法介绍

lock(): 最普通的获取锁, 如果锁已经被其他线程获取了, 则进行等待

tryLock(), tryLock(long time, TimeUnit unit) 和 lockInterruptibly()

Lock 不会像 Synchronized 一样在异常时自动释放锁, 因此最佳实践是, 在 finally 中释放锁, 以保证发生异常时锁一定释放



### 可见性保证

happens-before 原则



## 锁的分类

<img src="http://www.milky.show/images/java/lock/lock_1.png" alt="http://www.milky.show/images/java/lock/lock_1.png" style="zoom: 33%;" />

### 乐观锁和悲观锁

互斥同步锁(悲观锁)的劣势

*   阻塞和唤醒带来的性能劣势
*   永久阻塞: 如果持有锁的线程被永久阻塞, 比如遇到了无限循环, 死锁等活跃性问题, 那么等待该线程释放锁的那几个悲催的线程, 将永远也得不到执行
*   优先级反转

非互斥同步锁(乐观锁)

#### 悲观锁

如果我不锁住这个资源, 别人就会来争抢, 就会造成数据结果错误, 所以每次悲观锁为了确保结果的正确性, 会在每次获取并修改数据时, 把数据锁住, 让别人无法访问该数据, 这样就可以确保数据内容万无一失

Java 中的悲观锁的实现就是 synchronized 和 Lock 相关类

#### 乐观锁

认为自己在处理操作的时候不会有其他线程来干扰, 所以并不会锁住被操作对象

在更新的时候, 去对比在我修改的期间数据有没有被其他人改变过: 如果没被改变过, 就说明真的是只有我自己在操作, 那我就正常去修改数据

如果数据和我一开始拿到的不一样了, 说明其他人在这段时间内改过数据, 那我就不能继续刚才的更新数据过程了, 我会选择放弃, 报错, 重试等策略

乐观锁的实现一般都是利用 CAS 算法来实现的

#### 开销对比

悲观锁的原始开销要高于乐观锁, 但是特点是一劳永逸, 临界区持锁时间就算越来越差, 也不会对互斥锁的开销造成影响

乐观锁一开始的开销比悲观锁小, 但是如果自旋时间很长或者不停重试, 那么消耗的资源也会越来越多

#### 两种锁各自的使用场景

悲观锁适合并发写入多的情况, 适用于临界区斥锁时间比较长的情况, 悲观锁可以避免大量的无用自旋等消耗, 典型情况:

*   临界区有 IO 操作
*   临界区代码复杂或者循环量大
*   临界区竞争非常激烈

乐观锁适合并发写入少, 大部分是读取的场景, 不加锁的能让读取性能大福提高



### 可重入锁(ReentrantLock)和非可重入锁

#### 可重入锁

可以反复获得同一把锁, 内部维护了计数器, 避免死锁, 提升封装性

#### 非可重入锁

不可以重复获取同一把锁



### 公平锁和非公平锁

公平指的是按照线程请求的顺序来分配锁; 非公平指的是**不完全按照请求的顺序**, 在一定情况下可以插队

非公平也同样不提倡"插队"行为, 这里的非公平, 指的是"在合适的时机"插队, 而不是盲目插队

**非公平锁避免唤醒带来的空档期**

#### 公平锁

如果在创建 ReentrantLock 对象时, 参数填写为 true, 那么这就是个公平锁

#### 非公平锁

默认情况下都是非公平锁

### 共享锁(读锁)和排它锁(写锁)

共享锁, 又称为读锁, 获得共享锁之后, 可以查看但无法修改和删除数据, 其他线程此时也可以获取到共享锁, 也可以查看但无法修改和删除数据

排它锁又称为独占锁, 独享锁, synchronized 就是典型的排它锁, **其他线程无法读写**

**共享锁和排它锁的典型是读写锁 ReentrantReadWriteLock, 其中读锁是共享锁, 写锁是排它锁**

在没有读写锁之前, 我们假设使用 ReentrantLock, 那么虽然我们保证了线程安全, 但是也浪费了一定的资源: 多个读操作同时进行, 并没有线程安全问题

在读的地方使用读锁, 在写的地方使用写锁, 灵活控制, 如果没有写锁的情况下, 读是物阻塞的, 提高了程序的执行效率

#### 读写锁的规则

1.  多个线程只申请读锁, 都可以申请到
2.  如果有一个线程已经占用了读锁, 则此时其他线程如果要申请写锁, 则申请写锁的线程会一直等待释放读锁
3.  如果有一个线程已经占用了写锁, 则此时其他线程如果要申请写锁或者读锁, 则申请的线程会一直等待释放写锁

#### 读写锁的插队策略

公平锁: 不允许插队, 会完全按照顺序执行

非公平锁:

*   写锁可以随时插队, 保证在大量读的情况下可以写入
*   读锁仅在等待队列头结点不是想获取写锁的线程的时候可以插队

#### 读写锁的升降级

**ReentrantReadWriteLock 支持锁的降级(写锁变读锁), 不支持升级(容易造成死锁)**



### 自旋锁和阻塞锁

阻塞或唤醒一个 Java 线程需要操作系统切换 CPU 状态来完成, 这种状态转换需要耗费处理器时间, 如果同步代码块中的内容过于简单, 状态转换消耗的时间有可能比用户代码执行的时间还要常, 在许多场景中, 同步资源的锁定时间很短, 为了这一小段时间去切换线程, 线程挂起和恢复现场的花费可能会让系统得不偿失如果物理机有多个处理器, 能够让两个或以上的线程同时并行执行, 我们就可以让后面那个请求锁的线程不放弃 CPU 的执行时间, 看看持有锁的线程是否很快就会释放锁, 而为了让当前线程"稍等一下", 我们需要让当前线程进行自旋, 如果在自旋完成后前面锁定同步资源的线程已经释放了锁, 那么当前线程就可以不必阻塞而是直接获取同步资源, 从而避免切换线程的开销, 这就是自旋锁. 阻塞锁和自旋锁相反, 阻塞锁如果遇到没拿到锁的情况, 会直接把线程阻塞, 知道被唤醒.

如果被锁占用的时间很长, 那么自选的线程只会白白浪费处理器资源, 在自旋的过程中, 一直消耗 CPU, 所以虽然自旋锁的其实开销低于悲观锁, 但是随着自旋时间的增长, 开销也是线性增长的.

在 java1.5 版本及以上的并发框架 java.util.concurrent 的 atomic 包下的类基本都是自旋锁的实现.

AtomicInteger 的实现, 自旋锁的实现原理是 CAS, Atomicinteger 中调用 unsafe 进行自增操作的源码中的 do-while 循环就是一个自旋操作, 如果修改过程中遇到其他线程竞争导致没修改成功, 就在 while 里死循环, 直至修改成功.



### 可中断锁

在 Java 中, synchronized 就是不可中断锁, 而 Lock 是可中断锁, 因为 tryLock(time) 和 lockInterruptibly 都能响应中断

如果某一线程 A 正在执行锁中的代码, 另一线程 B 正在等待获取该锁, 可能由于等待时间过长, 线程 B 不想等待了, 想先处理其他事情, 我们可以中断它, 这就是可中断锁了.



### 锁优化

#### Java 虚拟机对锁的优化

自旋锁和自适应

锁消除

锁粗化

#### 我们写代码时如何优化

缩小同步代码块

尽量不要锁住方法

减少请求锁的次数

避免人为制造"热点"

锁中尽量不要再包含锁

选择合适的锁类型或合适的工具类





## 原子类

不可分割

一个操作是**不可中断**的, 几遍是多线程的情况下也可以保证

java.util.concurrent.atomic

元子类的作用和锁类似, 是为了保证并发情况下**线程安全**, 不过元子类相比于锁, 有一定的**优势**.

粒度更细: 原子变量可以把竞争范围缩小到边浪级别, 这是我们可以获得的最细粒度的情况了, 通常锁的粒度都要大于原子变量的粒度.

效率更高: 通常, 使用原子类的效率会比使用锁的效率更高, 除了**高度竞争**的情况.

### 6 类原子类总览

| 分类                               | 类                                                           |
| ---------------------------------- | ------------------------------------------------------------ |
| Atomic*基本类型原子类              | AtomicInteger<br />AtomicLong<br />AtomicBoolean             |
| Atomic*Array 数组类型原子类        | AtomicIntegerArray<br />AtomicLongArray<br />AtomicReferenceArray |
| Atomic*Reference 引用类型原子类    | AtomicReference<br />AtomicStampedReference<br />AtomicMarkableReference |
| Atomic*FieldUpdater 升级类型原子类 | AtomicIntegerFieldUpdater<br />AtomicLongFieldUpdater<br />AtomicReferenceFieldUpdater |
| Adder 累加器                       | LongAdder<br />DoubleAdder                                   |
| Accumulator 累加器                 | LongAccumulator<br />DoubleAccumulator                       |

### Atomic* 基本类型原子类常用方法

public final int get() // 获取当前的值

public final int getAndSet(int newValue) // 获取当前的值, 并且设置新的值

public final int getAndIncrement() // 获取当前的值, 并自增, 避免 a++ 问题

public final int getAndDecrement() // 获取当前的值, 并自减

public final int getAndAdd(int delta) // 获取当前的值, 并加上预期的值

boolean compareAndSet(int expect, int update) // 如果输入的数值等于预期值, 则以原子方式将该值设置为输入值(update)



### Adder 累加器

是 Java8 引入的, 相对是比较新的一个类

高并发下 LongAdder 比 AtomicLong 效率高, 不过本质是空间换时间

竞争激烈的时候, LongAdder 把不同线程对应到不同的 Cell 上进行修改, 降低了冲突的概率, 是多段锁的理念, 提高了并发性





## Java 中是如何利用 CAS 实现原子操作的

AtomicInteger 加载 Unsafe 工具, 从来**直接操作内存**数据.

用 Unsafe 来实现底层操作.

用 volatile 修饰 value 字段, 保证可见性.



## final 关键字和不变性

### 不变性(Immutable)

如果对象在创建后, 状态就不能被修改, 那么它就是不可变的.

例如: person 对象, age 和 name 都不能再变.

具有不变性的对象**一定是线程安全**的, 我们不需要对其采取任何额外的安全措施, 也能保证线程安全.

### final 的作用

**类防止被继承, 方法防止被重写, 变量防止被修改.**

天生是**线程安全**的, 而不需要额外的同步开销.

#### final 修饰变量

final instance variable(类中的 final 属性)

*   第一种是在声明变量的等号右边直接赋值
*   第二种就是构造函数中赋值
*   第三种就是在类的初始代码块中赋值(不常用)
*   如果不采用第一种赋值方法, 那么就必须在第 2,3 种挑一个来赋值, 而不能不赋值, 这是 final 语法所规定的

final static variable(类中的 static final 属性)

*   声明变量的等号右边直接赋值
*   static 初始代码块赋值, 但是不能用普通的初始代码块赋值

final local variable(方法中的 final 变量)

*   不规定赋值时机, 只要求在使用前必须赋值, 这和方法中的非 final 变量的要求也是一样的

#### final 修饰方法

构造方法不允许 final 修饰

普通方法不可被重写, 也就是不能被 override

static 方法不能被重写

#### final 修饰类

类不可被继承

典型的 String 类就是 final 的, 我们从没见过哪个类是继承 String 类的

### 注意点

被 final 修饰的变量, 意味着**值不能被修改**. 如果变量是对象, 那么对象的**引用不能变**, 但是对象自身的**内容依然可以变化.**

final 使用原则: 良好的编程习惯

### 不变性和 final 的关系

不变性并不意味着, 简单地用 final 修饰就是不可变

*   对于基本数据类型, 确实被 final 修饰后就具有不变性
*   但是对于对象类型, 需要改对象保证自身被创建后, 状态永远不会变才可以

如何利用 final 实现对象不可变

*   把所有属性都声明为 final?
*   一个属性是对象类型的不可变对象的正确例子

### 栈封闭技术

在方法里新建的局部变量, 实际上是存储在每个线程四有的栈空间, 而每个栈的栈空间是不能被其他线程所访问到的, 所以不会有线程安全问题. 这就是著名的"栈封闭"技术, 是"线程封闭"技术的一种情况



## 实现多线程的官方正确方法

### 方法一: 实现 Runnable 接口

实现 Runnable 接口更好, 解耦更好, 还可以继承类, 最终调用 target.run()

### 方法二: 继承 Thread 类

整个 run() 方法被重写



### 同时使用两种方法会怎么样?

从面向对象的思想去考虑, run 方法就被覆盖了, 经典的三行代码就会被覆盖, 所以不会调用 Runnable 的 run() 方法了









## 并发容器精讲

**ConcurrentHashMap**: 线程安全的 HashMap

**CopyOnWriteArrayList**: 线程安全的 List

**BlockingQueue**: 这是一个接口, 表示阻塞队列, 非常适合用于作为数据共享的通道

ConcurrentLinkedQueue: 高效的非阻塞并发队列, 使用链表实现. 可以看做一个线程安全的 LinkedList

ConcurrentSkipListMap: 是一个 Map, 使用跳表的数据结构进行快速查找



### 集合类的历史

Vector 和 Hashtable: 早期 JDK 线程安全的 AarrayList 和 HashMap, 性能不好, 因为方法都是用 synchronized 修饰的

HashMap 和 ArrayList: 这两个类不是线程安全的, 但是可以用 Collections.synchronizedList(new ArrayList\<E>()) 和 Collections.synchronizedMap(new HashMap\<E\>())使之变成线程安全的, 本质还是使用 synchronized

ConcurrentHashMap 和 CopyOnWriteArrayList: 取代同步的 HashMap 和同步的 ArrayList(时代巨轮滚滚向前)

### ConcurrentHashMap

#### Map 简介

HashMap: 根据 hashcode 定位, 允许 key 为 null, 线程不安全

Hashtable: 和 HashMap 功能一样, 但是性能低下, 已淘汰

LinkedHashMap: 是 HashMap 的子类

TreeMap: 实现了 SortedMap 接口, 可以排序

#### 为什么 HashMap 是线程不安全的

同时 put 碰撞导致数据丢失

同时 put 扩容导致数据丢失

HashMap 死循环造成的 CPU100%(JDK1.7 下存在), 因为在多线程情况下 HashMap 扩容造成循环链表

#### 为什么需要 ConcurrentHashMap

#### HashMap 分析

#### JDK1.7 的 ConcurrentHashMap 实现和分析

JDK1.7 中的 ConcurrentHashMap 最外层是多个 Segment, 每个 Segment 的底层数据结构与 HashMap 类似, 仍然是数组和链表组成的拉链法

每个 Segment 独立上 ReentrantLock 锁, 每个 Segnemnt 之间互不影响, 提高了并发效率

ConcurrentHashMap 默认有 16 个 Segments, 所以最多可以同时支持 16 个线程并发写(操作分别分布在不同的 Segment 上). 这个默认值可以在初始化的时候设置为其他值, 但是一旦初始化以后, 是不可以扩容的

#### JDK1.8 的 ConcurrentHashMap 实现和分析

putValue 流程

*   判断 key value 不为空
*   计算 hash 值
*   根据对应位置节点的类型来赋值, 或者 helpTransfer, 或者增长链表, 或者给红黑树增加节点
*   检查满足阈值就"红黑树化"
*   返回 oldValue

getValue 流程

*   计算 hash 值
*   找到对应的位置, 根据情况直接取值, 红黑树里取值, 遍历链表取值
*   返回找到的结果

#### 为什么要将 1.7 改为 1.8 的结构

数据结构

*   1.7 采用 Segment + 链表
*   1.8 采用 Node + 链表 + 红黑树

Hash 碰撞

*   1.7 会一直使用链表
*   1.8 首先使用链表, 当链表长度为 8 时转化为红黑树

保证并发安全

*   1.7 采用分段锁 Segment
*   1.8 采用 CAS + Synchronized

查询复杂度

*   1.7 是遍历链表O(n)
*   1.8 是遍历链表 O(n) + 遍历红黑树 O(logN)



红黑树的占用空间比链表大, 所以一开始使用链表, 当链表长度达到 8 时会转为红黑树, 但是达到 8 的概率是千万分之一, 如果达到 8 代表链表出了问题是一种极端情况, 要转为红黑树



#### ConcurrentHashMap 也不是线程安全的?

ConcurrentHashMap 本身肯定是线程安全的, 但是在组合操作下并不保证线程安全, 作者考虑到这种情况提供了 replace() 方法



### CopyOnWriteArrayList

#### 诞生的历史和原因

代替 Vector 和 SynchronizedList, 就和 ConcurrentHashMap 代替 SynchronizedMap 的原因一样

Vector 和 SynchronizedList 的锁的粒度太大, 并发效率相对比较低, 并且迭代时无法编辑

Copy-On-Write 并发容器还包括 CopyOnWriteArraySet, 用来代替同步 Set

#### 适用场景

读操作可以尽可能快, 而写即使慢一些也没有太大关系

读多写少: 黑名单, 监听器

#### 读写规则

回顾读写锁: 读读共享, 其他都互斥(写写互斥, 读写互斥, 写读互斥)

读写锁规则的升级: 读取是完全不用加锁的, 并且更厉害的是, 写入也不会阻塞读取操作. 只有写入和写入之间需要进行同步等待

#### 实现原理

CopyOnWrite 就是在写的时候复制一份新的出来, 这样写的过程中就是在一个全新的内存中, 读就不会受影响了

**创建新副本, 读写分离**

#### 缺点

数据一致性问题: CopyOnWrite 容器只能保证数据的最终一致性, 不能保证数据的实时一致性. 所以如果你希望写入的数据马上能读到, 请不要使用 CopyOnWrite 容器

内存占用问题: 因为 CopyOnWrite 的写是复制机制, 所以在进行写操作的时候, 内存里会同时驻扎两个对象的内存



### BlockingQueue

#### 为什么要使用队列

用队列可以在线程间传递数据: 生产者消费者模式, 银行转账.

考虑锁等线程安全问题的重任从"你"转移到了"队列"上.

#### 什么是阻塞队列

阻塞队列是具有阻塞功能的队列, 所以它首先是一个队列, 其次是具有阻塞功能.

通常阻塞队列的一端是给生产者放数据用, 另一端给消费者拿数据用. 阻塞队列是线程安全的, 所以生产者和消费者都可以是多线程的.

阻塞功能: 最有特色的两个带有阻塞功能的方法

take()方法: 获取并移除队列的头结点, 一旦如果执行 take 的时候, 队列里无数据, 则阻塞, 直到队列里有数据.

put()方法: 插入元素, 但是如果队列已满, 那么久无法继续插入, 则阻塞, 直到队列里有了空闲空间

是否有界(容量有多大): 这是一个非常重要的属性, 无界队列意味着里面可以容纳非常多(Integer.MAX_VALUE, 约为 2 的 31 次方, 是非常大的一个数, 可以近似认为是无限容量)

阻塞队列和线程池的关系: 阻塞队列是线程池的重要组成部分

#### 主要方法介绍

put, take

add(满了会抛出异常), remove(空了会抛出异常), element(返回队列头元素, 如果空了会抛出异常)

offer(增加, 会返回一个 boolean 值), poll(取出并删除, 如果为空会返回 null), peek(取出)

#### ArrayBlockingQueue

有界

指定容量

公平: 还可以指定是否需要保证公平, 如果想保证公平的话, 那么等待了最长时间的线程会被优先处理, 不过这会同时带来一定的性能 消耗

#### LinkedBlockingQueue

无界

容量 Integer.MAX_VALUE

内部结构: Node, 两把锁

#### PriorityBlockingQueue

支持优先级

自然顺序(而不是先进先出)

无界队列

PriorityQueue 的线程安全版本

#### SynchronousQueue

它的容量为 0

需要注意的是, SynchronousQueue 的容量不是 1 而是 0, 因为 SynchronousQueue 不需要去持有元素, 它所做的就是直接传递(direct handoff)

效率很高

SynchronousQueue 没有 peek 等函数, 因为 peek 的含义是取出头结点, 但是 SynchronousQueue 的容量是 0, 所以连头结点都没有, 也就没有 peek 方法. 同理, 没有 iterate 相关方法

是一个几号的用来直接传递的并发数据结构

SynchronousQueue 是线程池 Executors.newCachedThreadPool() 使用的阻塞队列



## 控制并发流程

### 什么是控制并发流程

控制并发流程的工具类, 作用就是帮助我们程序员更容易得让线程之间合作

让线程之间互相配合, 来满足业务逻辑

比如让线程 A 等待线程 B 执行完成后在执行等合作策略

| 类             | 作用                                                         | 说明                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Semaphore      | 信号量, 可以通过控制"许可证"数量, 来保证线程之间的配合       | 线程只有在拿到"许可证"后才能继续运行. 相比于其他的同步器, 更灵活. |
| CyclicBarrier  | 线程会等待, 直到足够多线程达到了事先规定的数目. 一旦达到触发条件, 就可以进行下一步的动作. | 适用于线程之间相互等待处理结果就绪的场景                     |
| Phaser         | 和 CyclicBarrier 类似, 但是计数可变                          | Java7 加入的                                                 |
| CountDownLatch | 和 CyclicBarrier 类似, 数量地见到 0 时, 触发动作             | 不可重复使用                                                 |
| Exchanger      | 让两个线程在合适时交换对象                                   | 适用场景: 当两个线程工作在同一个类的不同实例上时, 用于交换数据 |
| Condition      | 可以控制线程的"等待"和"唤醒"                                 | 是 Object.wait() 的升级版                                    |



### CountDownLatch 倒计时门闩

#### CountDownLatch 类的作用

并发流程控制的工具

*   倒数门闩
*   例子: 购物拼团; 大巴(游乐园坐过山车排队), 人满发车;
*   流程: 倒数结束之前, 一直处于等待状态, 直到倒计时结束了, 此线程才继续工作

#### 类的主要方法介绍

CountDownLatch(int count): 仅有一个构造函数, 参数 count 为需要倒数的数值

await(): 调用 await() 方法的线程会被挂起, 它会等待直到 count 值为 0 才继续执行

countDown(): 将 count 值减 1, 直到为 0 时, 等待的线程会被唤醒

#### 两个典型用法

用法一: 一个线程等待多个线程都执行完毕, 再继续自己的工作

用法二: 多个线程等待某一个线程的信号, 同时开始执行

### Semaphore 信号量

Semaphore 可以用来限制或管理数量有限的资源的使用情况

污染不能太多, 污染许可证只能发 3 张

信号量的作用是维护一个"许可证"的计数, 线程可以"获取"许可证, 那信号量剩余的许可证就减一, 线程也可以"释放"一个许可证, 那信号量剩余的许可证就加一, 当信号量所拥有的许可证数量为 0, 那么下一个还想要获取许可证的线程, 就需要等待, 直到有另外的线程释放了许可证

#### 信号量使用流程

初始化 Semaphore 并指定许可证的数量

在需要被现在的代码前加 acquire() 或者 acquireUninterruptibly() 方法

在任务执行结束后, 调用 release() 来释放许可证

#### 信号量的主要方法

new Semaphore(int permits, boolean fair): 这里可以设置是否要使用公平策略, 如果传入 true, 那么 Semaphore 会把之前等待的线程放到 FIFO 的队列里, 以便于当有了新的许可证, 可以分发给之前等待了最长时间的线程.

tryAcquire(): 看看现在有没有空闲的许可证, 如果有的话就获取, 如果没有的话也没关系, 我不必陷入阻塞, 我可以去做别的事, 过一会再来查看许可证的空闲情况.

tryAcquire(timeout): 和 tryAcquire()一样, 但是多了一个超时时间, 比如"在 3 秒内获取不到去可证, 我就去做别的事"

release(): 释放许可证

#### 注意点

获取和释放的许可证数量必须一致, 否则比如每次都获取 2 个但是只释放 1 个甚至不释放, 随着时间的推移, 到最后许可证数量不够用, 会导致程序卡死(虽然信号量类并不对是否和获取的数量做规定, 但是这是我们的编程规范, 否则容易出错)

注意在初始化 Semaphore 的时候设置公平性, 一般设置为 true 会更合理

并不是必须由获取许可证的线程释放那个许可证, 事实上, 获取和释放许可证对线程并无要求, 也是是 A 获取了, 然后由 B 释放, 只要逻辑合理即可

信号量的作用, 除了控制临界区最多同时有 N 个线程访问外, 另一个作用是可以实现"条件等待", 例如线程 1 需要在线程 2 完成准备工作后才能开始工作, 那么就线程 1 acquire(), 而线程 2 完成任务后 release(), 这样的话, 相当于是轻量级的 CountDownLatch

### Condition 接口(又称条件对象)

#### Condition 作用

当线程 1 需要等待某个条件的时候, 它就去执行 condition.await()方法, 一旦执行了 await()方法, 线程就会进入阻塞状态

然后通常会有另外一个线程, 假设是线程 2, 去执行对应的条件, 直到这个条件达成的时候, 线程 2 就会去执行 condition.signal()方法, 这时 JVM 就会从阻塞的线程里找, 找到那些等待该 condition 的线程, 当线程 1 就会收到可执行信号的时候, 它的线程状态就会变成 Runnable 可执行状

signalAll()会唤起所有的正在等待的线程

signal()是公平的, 只会唤起等待时间最长的线程

#### Condition 注意点

实际上, 如果说 Lock 用来代替 synchronized, 那么 Condition 就是用来代替相对应的 Object.wait/notify 的, 所以在用法和性质上, 几乎都一样

await 方法会自动释放持有的 Lock 锁, 和 Object.wait 一样, 不需要自己手动先释放锁

调用 await 的时候, 必须持有锁, 否则会抛出异常, 和 Object.wait 一样

### CyclicBarrier 循环栅栏

CyclicBarrier 循环栅栏和 CountDownLatch 很类似, 都能阻塞一组线程

当有大量线程相互配合, 分别计算不同人物, 并且需要最后统一汇总的时候, 我们可以使用 CyclicBarrier. CyclicBarrier 可以构造一个集结点, 当某一个线程执行完毕, 它就会到集结点等待, 知道所有线程都到了集结点, 那么该栅栏就被撤销, 所有线程再统一触发, 继续执行剩下的任务

#### CyclicBarrier 和 CountDownLatch 的区别

作用不同: CyclicBarrier 要等固定数量的线程都到达了栅栏位置才能继续执行, 而 CountDownLatch 只需等待数字到 0, 也就是说, CountDownLatch 用于事件, 但是 CyclicBarrier 是用于线程的

可重用性不同: CountDownLatch 在倒数到 0 并触发门闩打开后, 就不能再次使用了, 除非新建新的示例; 而 CyclicBarrier 可以重复使用



## AQS(AbstractQueuedSynchronizer, 并发灵魂人物, 进阶必备)

### 学习 AQS 的思路

学习 AQS 的目的主要是想理解原理, 提高技术, 以及应对面试

先从应用层面理解为什么需要他如何使用它, 然后再看一看我们 Java 代码的设计者是如何使用它的了解它的应用场景

这样之后我们再去分析它的结构, 这样的话我们就学习得更加轻松了

### 为什么需要 AQS

锁和协作类有共同点: 闸门

*   我们已经学过了 ReentrantLock 和 Semaphore, 有没有发现有共同点? 很相似?
*   事实上, 不仅是 ReentrantLock 和 Semaphore, 包括 CountDownLatch, ReentrantReadWriteLock 都有这样类似的"协作"(或者叫"同步")功能, 其实它们底层都用了一个共同的基类, 这就是 AQS

因为上面的那些协作类, 它们有很多工作都是类似的, 所以如果能提取出一个工具类, 那么就可以直接使用, 对于 ReentrantLock 和 Semaphore 而言就可以屏蔽很多细节, 只关注它们自己的"业务逻辑"就可以了

### Semaphore 和 AQS 的关系

Semaphore 内部有一个 Sync 类, Sync 类继承了 AQS

CountDownLatch 与 ReentrantLock 也一样

### AQS 的作用

AQS 是一个用于构建锁, 同步器, 协作工具类的工具类(框架). 有了 AQS 以后, 更多的协作工具类都可以很方便得被写出来

一句话总结: 有了 AQS, 构建线程协作类就容易多了

### AQS 的重要性, 地位

AbstractQueuedSynchronizer 是 DougLea 写的, 从 JDK1.5 加入的一个基于 FIFO 等待队列实现的一个用于实现同步器的基础框架, 我们用 IDE 看 AQS 的实现类, 可以发现实现类有以下这些

### AQS 内部原理解析

AQS 最核心的就是三大部分

*   state
    *   这里的 state 的具体含义, 会根据具体实现类的不同而不同, 比如在 Semaphore 里, 它表示"剩余的许可证的数量", 而在 CountDownLatch 里, 它表示"还需要倒数的数量"
    *   state 是 volatile 修饰的, 会被并发地修改, 所以所有修改 state 的方法都需要保证线程安全, 比如 getState, setState 以及 compareAndSetState 操作来读取和更新这个状态. 这些方法都依赖于 j.u.c.atomic 包的支持
*   控制线程抢锁和配合的 FIFO 队列
    *   这个队列用来存放"等待的线程", AQS 就是"排队管理器", 当多个线程争用同一把锁时, 必须有排队机制将那些没能拿到锁的线程串在一起. 当锁释放时, 锁管理器就会挑选一个合适的线程来占有这个刚刚释放的锁
    *   AQS 会维护一个等待的线程队列, 把线程都放到这个队列里
*   期望协作工具类去实现的获取/释放等重要方法
    *   这里的获取和释放方法, 是利用 AQS 的协作工具类里最重要的方法, 是由协作类自己去实现的, 并且含义各不相同
    *   获取操作会依赖 state 变量, 经常会阻塞
    *   释放操作不会阻塞

### 应用实例, 源码解析

### 利用 AQS 实现一个自己的 Latch 门闩



## Future 和 Callable

### Runnable 的缺陷

不能返回一个返回值

不能抛出 checked Exception 异常

### Callable 接口

类似于 Runnable, 被其它线程执行的任务

实现 call 方法

有返回值

### Future 类

#### Future 的主要方法

get() 方法: 获取结果, get 方法的行为取决于 Callable 任务的状态, 只有以下 5 种情况

1.  任务正常完成: get 方法会立刻返回结果
2.  任务尚未完成(任务还没开始或进行中): get 将阻塞并直到任务完成
3.  任务执行过程中抛出 Exception: get 方法会抛出 ExecutionException: 这里的抛出异常, 是 call() 执行时产生的那个异常, 看到这个异常类型是 java.util.concurrent.ExecutionException. 不论 call() 执行时抛出的异常类型是什么, 最后 get 方法抛出的异常类型都是 ExecutionException
4.  任务被取消: get 方法会抛出 CancellationException
5.  任务超时: get 方法有一个重载方法, 是传入一个延迟时间的, 如果事件到了还没有获得结果, get 方法就会抛出 TimeoutException

get(long timeout, TimeUnit unit): 有超时的获取

*   超时的需要很常见
*   用 get(long timeout, TimeUnit unit)方法时, 如果 acll()在规定时间内完成了任务, 那么就会正常获取到返回值,; 而如果在指定时间内没有计算出结果, 那么就会抛出 TimeoutException
*   超时不获取, 任务需取消

cancel() 方法: 取消任务的执行

1.  如果这个任务还没有开始执行, 那么这种情况最简单, 任务会被正常的取消, 未来也不会被执行, 方法返回 true
2.  如果任务已完成, 或者已取消: 那么 cancel() 方法会执行失败, 方法返回 false
3.  如果这个任务已经开始执行了, 那么这个取消方法将不会直接取消该任务, 而是会根据我们填的参数 mayInterruptIfRunning 做判断
    1.  Future.calcel(true) 适用于任务能够处理 interrupt
    2.  Future.cancel(false) 仅用于避免启动尚未启动的任务, 适用于未能处理 interrupt 的任务, 不清楚任务是否支持取消

isDone() 方法: 判断线程是否执行完毕, 不代表任务是否执行成功, 失败了也是执行完毕

isCancelled() 方法: 判断是否被取消

#### 用法 1: 线程池的 submit 方法返回 Future 对象

首先, 我们要给线程池提交我们的任务, 提交时线程池会立刻返回给我们一个空的 Future 容器. 当线程的任务一旦执行完毕, 也就是当我们可以获取结果的时候, 线程池便会把该结果填入到之前给我们的那个 Future 中取(而不是创建一个新的 Future), 我们此时便可以从该 Future 中获得任务执行的结果

#### 用法 2: 用 FutureTask 来创建 Future

用 FutureTask 来获取 Future 和任务的结果

FutureTask 是一种包装器, 可以吧 Callable 转化成 Future 和 Runnable, 它同时实现二者的接口, 所以它既可以作为 Runnable 被线程执行, 又可以作为 Future 得到 Callable 的返回值

把 Callable 实例当做参数, 生成 FutureTask 对象, 然后把这个对象当做一个 Runnable 对象, 用线程池或另起线程去执行这个 Runnable 对象, 最后通过 FutureTask 获取刚才执行的结果

#### Future 的注意点

当 for 循环批量获取 future 的结果时, 容易发生一部分线程很慢的情况, get 方法调用时应使用 timeout 限制

Future 的生命周期不能后退, 生命周期只能前进, 不能后退. 就和线程池的生命周期一样, 一旦完全完成了任务, 它就永远停在了"已完成"的状态, 不能重头再来

### Callable 和 Future 的关系

我们可以用 Future.get() 来获取 Callable 接口返回的执行结果, 还可以通过 Future.isDone() 来判断任务是否已经执行完成了, 以及取消这个任务, 限时获取任务的结果等

在 call() 未执行完毕之前, 调用 get() 的线程(假定此时是主线程)会被阻塞, 直到 call() 方法返回结果后, 此时 future.get() 才会得到该结果, 然后主线程才会切换到 runnable 状态

所以 Future 是一个存储器, 它存储了 call() 这个任务的结果, 而这个任务的执行时间是无法提前确定的, 因为这完全取决于 call() 方法执行的情况





## 高并发处理思路与手段

### 高并发扩容

* 垂直扩容(纵向扩展)

    提高系统部件能力, 通俗来说就是增加单节点的内存大小

* 水平扩容(横向扩展)

    增加更多系统成员来实现, 通俗来说是单节点变为集群

* 数据库扩容

    * 读操作扩容

        memcache, redis, cdn等缓存

    * 写操作扩展

        Cassandra, Hbase等

### 高并发缓存

<img src="http://www.milky.show/images/concurrency/10.png" alt="http://www.milky.show/images/concurrency/10.png" style="zoom:67%;" />

* 缓存特征

    * 命中率

        命中数 / (命中数 + 没有命中数)

        命中率越高, 我们的收益越好

    * 最大元素(空间)

        可以容纳的最大数据的数量, 如果达到了阈值, 就会触发缓存清空策略

    * 清空策略

        选择合适的清空策略, 可以提高我们的命中率

        FIFO, LFU, LRU, 过期时间, 随机等

* 影响缓存命中率的因素

    1. 业务场景和业务需求

        适合对读取要求高, 实时性要求低的业务场景

    1. 缓存的设计(粒度和策略)

    1. 缓存容量与基础设施

* 缓存分类和应用场景

    * 本地缓存

        编程实现(成员变量, 局部变量, 静态变量)Guava Cache

    * 分布式缓存

        MemCache, Redis

### 高并发消息队列

<img src="http://www.milky.show/images/concurrency/11.png" alt="http://www.milky.show/images/concurrency/11.png" style="zoom:67%;" />

* 消息队列特性

    * 业务无关: 只做消息分发

    * FIFO: 先进先出

    * 容灾: 节点的动态增删和消息的持久化

    * 性能: 吞吐量

* 为什么需要消息队列

    * [生产]和[消费]的速度或稳定性等因素不一致

* 消息队列的好处

    * 业务解耦

    * 最终一致性

    * 广播

    * 错峰与流控

### 高并发应用拆分

<img src="http://www.milky.show/images/concurrency/12.png" alt="http://www.milky.show/images/concurrency/12.png" style="zoom:67%;" />

* 应用拆分原则

    * 业务优先

    * 循序渐进

    * 兼顾技术: 重构, 拆分

    * 可靠测试

* 应用拆分-思考

    * 应用间通信: RPC(dubbo等), 消息队列

    * 应用之间数据库: 每个应用都有独立的数据库

    * 避免事物操作跨应用

### 高并发应用限流

<img src="http://www.milky.show/images/concurrency/13.png" alt="http://www.milky.show/images/concurrency/13.png" style="zoom:67%;" />

### 高并发服务降级与熔断

* 服务降级

    * 自动降级: 超时, 失败次数, 故障, 限流

    * 人工降级: 秒杀, 双11大促

* 服务熔断
          

### 高并发分库分表

* 数据库瓶颈

    * 单个库数据量太大(1T~2T): 拆分多个库

    * 单个数据库服务器压力过大, 读写瓶颈: 拆分多个库

    * 单个表数据量过大: 分表

* 切库

    * 切库的基础及实际运用: 读写分离

    * 自定义注解完成数据库切库

    * 支持读数据源

### 高可用的一些手段

* 任务调度系统分布式: elastic-job + zookeeper

* 主备切换: apache curator + zookeeper分布式锁实现

* 监控报警机制



## 多线程并发最佳实践

使用本地变量

使用不可变量

最小化锁的作用域范围

使用线程池的 Executor, 而不是直接new Thread执行

宁可使用同步, 也不要使用wait和notify方法

使用BlockingQueue实现生产-消费模式

使用并发集合而不是加了锁的同步集合

使用 Semaphore 创建有界的访问

宁可使用同步代码块, 也不使用同步的方法

避免使用静态变量





## 请谈一下 AQS, 为什么 AQS 的底层是 CAS + volatile








