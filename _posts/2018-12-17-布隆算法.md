---
layout: post
title: "布隆算法"
categories: [Algorithm]
description:
keywords:
---

* content
{:toc} 
## 场景假设

* 假设我们在做一个爬虫的功能, 爬虫的原理很简单, 无非是通过种子URL来顺藤摸瓜, 爬取出网站关联的所有的子网页, 存入自己的网页库当中.

	![http://www.milky.show/images/algorithm/bloom/bloom_1.png](http://www.milky.show/images/algorithm/bloom/bloom_1.png)

* 但是这其中涉及到一个小问题, 爬取出来的URL可能存在重复, 需要被丢弃, 如果实现URL去重呢?

	* URL去重方法一:**HashSet**

		创建一个HashSet集合，把每一个URL字符串作为HashSet的key插入到集合当中，利用HashSet的Key唯一性来对URL做去重。

		![http://www.milky.show/images/algorithm/bloom/bloom_2.png](http://www.milky.show/images/algorithm/bloom/bloom_2.png)

		这个方案看似没毛病, 但是经过几轮压力测试后, 爬取的URL有好几亿个, HashSet占内存空间太多了

		**每一个URL按照20字节来算，一亿个URL就是20亿字节，也就是大约占了1.8G以上的空间。这么大的HashSet集合显然是不可取的。**

	* URL去重方法二:**Bitmap**

		获取每一个URL的HashCode，根据HashCode的值来插入到Bitmap的对应位置。如果要插入位置的值已经是1，说明该URL已重复。

		![http://www.milky.show/images/algorithm/bloom/bloom_3.png](http://www.milky.show/images/algorithm/bloom/bloom_3.png)

		使用Bitmap以后，每一个Url只占了1个Bit，一亿个Url占约12MB。假设整个Bitmap的空隙比较多，额外空间占90%，总空间也不过是120MB，相比HashSet来说大大节省了内存空间。

		**可字符串的HashCode是会有重复的, 不同Url的HashCode很可能相同**

		**String的Hashcode方法虽然尽可能做到均匀分布，但仍然免不了会有冲突的情况。HashCode的冲突意味着什么呢？意味着两个原本并不相同的Url被误判为重复Url。**

## 布隆算法

* 布隆算法是由BloomFilter音译而来的, 是一种以Bitmap集合为基础的排重算法

* 布隆算法有许多的应用场景, 比如Url的排重, 垃圾邮箱地址的过滤等领域

* 我们不能扩大单一范围, 如果把HashCode的返回值改为long类型, 可以扩大HashCode的范围, 但是Bitmap集合是装不下的, 既然不能扩大单一HashCode的范围, 我们可以增加HashCode的次数, 实现多个不同的Hash算法, 让每一个Url都计算出Hash值, 最后让各个Hash值一一比较

	1. 把第一个URL按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_4.png](http://www.milky.show/images/algorithm/bloom/bloom_4.png)

	1. 把第二个URL也按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_5.png](http://www.milky.show/images/algorithm/bloom/bloom_5.png)

	1. 依次比较每一个Hash结果，只有当全部结果都相等时，才判定两个URL相同。

		![http://www.milky.show/images/algorithm/bloom/bloom_6.png](http://www.milky.show/images/algorithm/bloom/bloom_6.png)

	**假设标准HashCode的重复几率是0.01%, 那么3个Hash结果同时重复的几率就是0.01%^3 = 0.0000000001%, 只不过布隆算法会把每一个Hash结果都映射到同一个Bitmap上, 具体流程如下**

	1. 创建一个空的Bitmap集合。

		![http://www.milky.show/images/algorithm/bloom/bloom_7.png](http://www.milky.show/images/algorithm/bloom/bloom_7.png)

	1. 把第一个URL按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_8.png](http://www.milky.show/images/algorithm/bloom/bloom_8.png)

	1. 分别判断5，17， 9 在Bitmap的对应位置是否为1，只要不同时为1，就认为该Url没有重复，于是把5，17，9的对应位置设置为1。

		![http://www.milky.show/images/algorithm/bloom/bloom_9.png](http://www.milky.show/images/algorithm/bloom/bloom_9.png)

	1. 把第二个URL按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_10.png](http://www.milky.show/images/algorithm/bloom/bloom_10.png)

	5. 分别判断10，12， 9 在Bitmap的对应位置是否为1，只要不同时为1，就认为该Url没有重复，于是把10，12， 9 的对应位置设置为1。

		![http://www.milky.show/images/algorithm/bloom/bloom_11.png](http://www.milky.show/images/algorithm/bloom/bloom_11.png)

	5. 把第三个URL按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_12.png](http://www.milky.show/images/algorithm/bloom/bloom_12.png)

	5. 分别判断4，16， 11 在Bitmap的对应位置是否为1，只要不同时为1，就认为该Url没有重复，于是把4，16， 11 的对应位置设置为1。

		![http://www.milky.show/images/algorithm/bloom/bloom_13.png](http://www.milky.show/images/algorithm/bloom/bloom_13.png)

	5. 把第四个URL按照三种Hash算法，分别生成三个不同的Hash值。

		![http://www.milky.show/images/algorithm/bloom/bloom_14.png](http://www.milky.show/images/algorithm/bloom/bloom_14.png)

	5. 分别判断5，17， 9 在Bitmap的对应位置是否为1。判断的结果是 5，17， 9 在Bitmap对应位置的值都是1，所以判定该Url**是一个重复的Url**。

* 如果一个新的URL经过三次Hash结果是10, 12, 17, 会被误认为是重复的, 这种情况叫做**误判**, 由此可见布隆算法虽然降低了Hash冲突的几率, 但是仍有一定的误判率, 为了减小误判率, 可以让Bitmap的空间更大一些, 单个URL所做的Hash多一些(一般是8次), 总之是在空间和准确率上做取舍

* 既然使用同一个Bitmap会出现误判, 为什么不让每一种Hash算法的结果对应一个独立的Bitmap呢? 如果这样的话占用的空间也会相应增加几倍, 反而不如使用HashSet了