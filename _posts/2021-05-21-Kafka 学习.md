---
layout: post
title: Kafka 学习
categories: [MessageQueue]
description: 
keywords: 
---


* content
{:toc}






## Kafka 概述

### 定义

 Kafka传统定义：Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。

 发布/订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息

 Kafka 最新定义： Kafka 是一个开源的分布式事件流平台（ Event Streaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_1.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_1.png)



### 消息队列

目前企业中比较常见的消息队列产品主要有Kafka、ActiveMQ、RabbitMQ、RocketMQ等。

在大数据场景主要采用Kafka作为消息队列

#### 传统消息队列的应用场景

传统的消息队列的主要应用场景包括：缓存**/**消峰、解耦和异步通信。

##### 缓冲/消峰

缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_2.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_2.png)

##### 解耦

解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_3.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_3.png)

##### 异步通信

异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_4.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_4.png)



#### 消息队列的两种模式

##### 点对点

消费者主动拉取数据，消息收到后清除消息

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_5.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_5.png)

##### 发布/订阅

可以有多个 topic 主题（浏览、点赞、收藏、评论等） 

消费者消费数据之后，不删除数据

消费者消费数据之后，不删除数据• 每个消费者相互独立，都可以消费到数据

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_6.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_6.png)





### Kfka 基础架构

为方便扩展，并提高吞吐量，一个 topic 分为多个 partition 

配合分区的设计，提出消费者组的概念，组内每个消费者并行消费

为提高可用性，为每个 partition 增加若干副本，类似 NameNode HA 

ZK 中记录谁是 leader，Kafka2.8.0 以后也可以配置不采用ZK 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_7.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_7.png)



**Producer**：消息生产者，就是向 Kafka broker 发消息的客户端。

**Consumer**：消息消费者，向 Kafka broker 取消息的客户端。

**Consumer Group**（**CG**）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

**Broker**：一台Kafka服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。

**Topic**：可以理解为一个队列，生产者和消费者面向的都是一个 **topic**。

**Partition**：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个**topic**可以分为多个**partition**，每个partition是一个有序的队列。每个 partition 只能被一个 consumer 消费

**Replica**：副本。一个 topic 的每个分区都有若干个副本，一个**Leader**和若干个**Follower**。

**Leader**：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是Leader。

**Follower**：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。





## 快速入门

### 安装部署

#### 集群规划

| localhost | lolcahost | localhost |
| --------- | --------- | --------- |
| zk02      | zk03      | zk04      |
| kafka02   | kafka03   | kafka04   |

#### 集群部署

1.   官方下载地址：http://kafka.apache.org/downloads.html

2.   解压缩安装包

     ```bash
     tar -xzvf kafka_2.12-3.0.0.tgz -C .
     ```

3.   修改解压后的文件名称

     ```bash
     mv kafka_2.12-3.0.0 kafka
     ```

4.   进入到 kafka 目录，修改配置文件

     ```bash
     vim config/server.properties
     ```

     输入以下内容

     ```bash
     # broker 的 全局唯一编号，不能重复 ，只能是数字 。
     # 自己修改
     broker.id=2
     # 处理网络请求 的 线程数量
     num.network.threads=3
     #用来 处理磁盘 IO 的 线程 数量
     num.io.threads=8
     # 发送套接字的缓冲区大小
     socket.send.buffer.bytes=102400
     # 接收套接字的缓冲区大小
     socket.receive.buffer.bytes=102400
     #请求套接字的缓冲区大小
     socket.request.max.bytes=104857600
     # kafka 运行日志 数据 存放的路径 ，路径不需要提前创建 k afka 自动帮你创建 ，可以配置多个磁盘路径，路径与路径之间可以用分隔
     # 自己修改
     log.dirs=/Users/miaoqi/Documents/kafka-cluster/kafka02/datas
     # topic 在当前 broker 上的分区个数
     num.partitions=1
     # 用来恢复和清理 data 下数据的线程数量
     num.recovery.threads.per.data.dir=1
     # 每个 topic 创建时的副本数，默认时 1 个副本
     offsets.topic.replication.factor=1
     # segment 文件保留的最长时间，超时将被删除
     log.retention.hours=168
     # 每个 segment 文件 的大小，默认最大 1G
     log.segment.bytes=1073741824
     # 检查过期数据的时间，默认 5 分钟检查一次是否数据过期
     log.retention.check.interval.ms=300000
     # 配置连接 Zookeeper 集群 地址 （在 zk 根目录下创建 kafka ，方便管理
     zookeeper.connect=localhost:2182,localhost:2183,localhost:2184/kafka
     ```

5.   分别在 kafka03 和 kafka04 上修改配置文件 config/server.properties 中的 broker.id=3, broker.id=4

     注：broker.id 不得重复，整个集群中唯一。

6.   配置环境变量

     ```bash
     vim ~/.zshrc
     ```

     ```bash
     # KAFKA_HOME
     export KAFKA_HOME=~/Documents/kafka-cluster/kafka02
     export PATH=$PATH:$KAFKA_HOME/bin
     ```

     ```bash
     source ~/.zshrc
     ```

7.   启动集群

     先启动Zookeeper集群，然后启动Kafka。

     ```bash
     ~/Documents/zookeeper-cluster/zk.sh start
     ```

     依次在kafka02、kafka04、kafka04节点上启动Kafka

     ```bash
     ~/Documents/kafka-cluster/kafka02/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka02/config/server.properties
     ~/Documents/kafka-cluster/kafka03/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka03/config/server.properties
     ~/Documents/kafka-cluster/kafka04/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka04/config/server.properties
     ```

8.   关闭集群 

     ```bash
     ~/Documents/kafka-cluster/kafka02/bin/kafka-server-stop.sh
     ~/Documents/kafka-cluster/kafka03/bin/kafka-server-stop.sh
     ~/Documents/kafka-cluster/kafka04/bin/kafka-server-stop.sh
     ```

     



#### 集群启停脚本

1.   在~/Documents/kafka-cluster目录下创建文件kf.sh脚本文件

     ```bash
     vim kf.sh
     ```

     脚本如下

     ```bash
     #!/bin/bash
     
     case $1 in
         "start"){
             for i in kafka02 kafka03 kafka04
             do
                 echo -------- $i 启动 ---------
                 eval "~/Documents/kafka-cluster/$i/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/$i/config/server.properties"
             done
         };;
         "stop"){
             for i in kafka02 kafka03 kafka04
             do
                 echo -------- $i 停止 ---------
                 eval "~/Documents/kafka-cluster/$i/bin/kafka-server-stop.sh"
             done
         };;
     esac
     ```

2.   添加执行权限

     ```bash
     chmod 777 kf.sh
     ```

3.   启动集群命令

     ```bash
     ./kf.sh start
     ```

4.   停止集群命令

     ```bash
     ./kf.sh stop
     ```

注意：停止Kafka集群时，一定要等Kafka所有节点进程全部停止后再停止Zookeeper集群。因为Zookeeper集群当中记录着Kafka集群相关信息，Zookeeper集群一旦先停止，Kafka集群就没有办法再获取停止进程的信息，只能手动杀死Kafka进程了。



### Kafka 命令行操作

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_8.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_8.png)

#### 主题命令行操作

1.   查看主题命令行参数

```bash
bin/kafka-topics.sh
```

| 参数                                             | 描述                              |
| ------------------------------------------------ | --------------------------------- |
| --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号 |
| --topic <String: topic>                          | 操作的topic名称                   |
| --create                                         | 创建主题                          |
| --delete                                         | 删除主题                          |
| --alter                                          | 修改主题。                        |
| --list                                           | 查看所有主题。                    |
| --describe                                       | 查看主题详细描述                  |
| --partitions <Integer: # of partitions>          | 设置分区数                        |
| --replication-factor<Integer:replication factor> | 设置分区副本                      |
| --config <String: name=value>                    | 更新系统默认的配置                |

2.   查看当前服务器中的所有topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9093 --list
     ```

3.   创建 first topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 1 --replication-factor 3 --topic first
     ```

     --topic 定义topic名

     --replication-factor 定义副本数

     --partitions 定义分区数

4.   查看first主题的详情

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first
     ```

5.   修改分区数（注意：分区数只能增加，不能减少）

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic first --partitions 3
     ```

6.   再次查看first主题的详情

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first
     ```

7.   ）删除topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic first
     ```

     

#### 生产者命令行操作

1.   查看操作生产者命令参数

     ```bash
     bin/kafka-console-producer.sh
     ```

     | 参数                                             | 描述                                |
     | ------------------------------------------------ | ----------------------------------- |
     | --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号。 |
     | --topic <String: topic>                          | 操作的topic名称                     |

2.   ）发送消息

     ```bash
     bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first
     >hello world
     >atguigu atguigu
     ```



#### 消费者命令行操作

1.   查看操作消费者命令参数

     ```bash
     bim/kafka-console-consumer.sh
     ```

     | 参数                                             | 描述                                |
     | ------------------------------------------------ | ----------------------------------- |
     | --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号。 |
     | --topic <String: topic>                          | 操作的topic名称                     |
     | --group <String: consumer group id>              | 指定消费者组名称。                  |
     | --from-beginning                                 | 从头开始消费。                      |

2.   消费消息

     消费 first 主题中的数据

     ```bash
     bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first
     ```

     把主题中所有的数据都读取出来（包括历史数据）

     ```bash
     bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic first
     ```



## Kafka 生产者

### 生产者消息发送流程

#### 发送原理

在消息发送的过程中，涉及到了两个线程——**main**线程和**Sender**线程。在main线程中创建了一个双端队列**RecordAccumulator**。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到KafkaBroker。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_9.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_9.png)

batch.size：只有数据积累到batch.size之后，sender才会发送数据。默认16k 

linger.ms：如果数据迟迟未达到batch.size，sender等待linger.ms设置的时间到了之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。

0：生产者发送过来的数据，不需要等数据落盘应答

1：生产者发送过来的数据，Leader收到数据后应答

-1（all）：生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。-1和all等价



#### 生产者重要参数列表

| 参数名称                              | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | 生产者连接集群所需的broker地址清单。例如hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置1个或者多个，中间用逗号隔开。注意这里并非需要所有的broker地址，因为生产者从给定的broker里查找到其他broker信息。 |
| key.serializer和value.serializer      | 指定发送消息的key和value的序列化类型。一定要写全类名。       |
| buffer.memory                         | RecordAccumulator缓冲区总大小，默认32m。                     |
| batch.size                            | 缓冲区一批数据最大值，默认16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加。 |
| linger.ms                             | 如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。生产环境建议该值大小为5-100ms之间。 |
| acks                                  | 0：生产者发送过来的数据，不需要等数据落盘应答。 1：生产者发送过来的数据，Leader收到数据后应答。 -1（all）：生产者发送过来的数据，Leader+和isr队列里面的所有节点收齐数据后应答。默认值是-1，-1和all是等价的。 |
| max.in.flight.requests.per.connection | 允许最多没有返回ack的次数，默认为5，开启幂等性要保证该值是1-5的数字。 |
| retries                               | 当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。默认是int最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1否则在重试此失败消息的时候，其他的消息可能发送成功了。 |
| retry.backoff.ms                      | 两次重试之间的时间间隔，默认是100ms。                        |
| enable.idempotence                    | 是否开启幂等性，默认true，开启幂等性。                       |
| compression.type                      | 生产者发送的所有数据的压缩方式。默认是none，也就是不压缩。 支持压缩类型：none、gzip、snappy、lz4和zstd |



### 异步发送 API

#### 普通异步发送

需求：创建Kafka生产者，采用异步的方式发送到KafkaBroker

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_10.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_10.png)



#### 带回调函数的异步发送

回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception），如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_11.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_11.png)

**注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试**



### 同步发送 API



### 生产者分区

#### 分区好处

#### 生产者发送消息的分区策略

#### 自定义分区器

### 生产经验-生产者如何提高吞吐量

### 生产经验-数据可靠性

### 生产经验-数据去重

#### 数据传递语意

#### 幂等性

#### 生产者事务

### 生产经验-数据有序

### 生产经验-数据乱序



## Kafka Broker





## Kafka 消费者







