---
layout: post
title: Kafka 学习
categories: [MessageQueue]
description: 
keywords: 
---


* content
{:toc}






## 介绍

初始 kafka
a distrivuted streaming platform, 分布式流处理平台, (不是一个消息系统)
kafka 是基于 zookeeper 的分布式消息系统
高吞吐率, 高性能, 实时及高可靠等特点

Kafka本身是流处理框架，可以做很多事情，流处理、消息队列等等，在大数据、日常开发都有广泛的应用，可以做消息队列使用，但和日常MQ不同，Kafka在数据一致性、事务、死信队列和时序性等方面不如消息队列。所以卡夫卡更适合处理数据量或吞吐量较大，对数据的时序性要求没有那么高，甚至对消息的丢失没那么敏感的场景。而消息队列更适合在吞吐量没那么大，但是对消息的稳定性、非重复性、时序性要求较高的场景



## 安装

安装 zookeeper

安装 kafka

1.  修改 server.properties

    listeners=PLAINTEXT://192.168.2.103:9092

    advertised.listeners=PLAINTEXT://192.168.2.100:9092

    log.dirs=/Users/miaoqi/Documents/kafka_2.11-2.4.1/kafka_log

    zookeeper.connect=localhost:2181

    zookeeper.connection.timeout.ms=6000

2.  启动 kafka



## 命令行

启动 zookeeper
`bin/zkServer.sh start -daemon conf/zoo.cfg`

启动 Kafka
`bin/kafka-server-start.sh config/server.properties &`

停止 Kafka
`bin/kafka-server-stop.sh`

创建 Topic
`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic miaoqi-topic`

查看已经创建的 Topic 信息
`bin/kafka-topics.sh --list --zookeeper 192.168.2.100:2181`

发送消息
`bin/kafka-console-producer.sh --broker-list 192.168.2.100:9092 --topic miaoqi-topic`

接收消息
`bin/kafka-console-consumer.sh --bootstrap-server 192.168.2.100:9092 --topic miaoqi-topic --from-beginning`


{"orderId":"002","price":"80"}



## 基本概念

topic: 一个虚拟的概念, 由 1 到多个 partitions 组成

partition: 实际消息存储单位

producer: 消息生产者

consumer: 消息消费者


kafka 客户端 api 类型

1. adminClient API: 允许管理和检测 topic, broker 以及其他 kafka 对象
2. producer api: 发布消息到 1 个或多个 topic
3. consumer api: 订阅一个或多个 topc, 并处理产生的消息
4. stream api: 高效的将输入流转换到输出流
5. connector api: 从一些原系统或应用程序中拉取数据到 kafka



## AdminAPI

| API                   | 作用                   |
| --------------------- | ---------------------- |
| AdminClient           | AdminClient 客户端对象 |
| NewTopic              | 创建 Topic             |
| CreateTopicsResult    | 创建 Topic 的返回结果  |
| ListTopicsResult      | 查询 Topic 列表        |
| ListTopicsOptions     | 查询 Topic 列表及选项  |
| DescribeTopicsResult  | 查询 Topics            |
| DescribeConfigsResult | 查询 Topics 配置项     |



## Producer

### Producer 发送模式

同步发送

异步发送

异步回调发送



### Producer 消息传递保障

kafka 提供了三种传递保障

*   最多一次: 收到 0 到 1 次
*   至少一次: 收到 1 到多次
*   正好一次: 有且仅有一次

传递保障依赖于 Producer 和 Consumer 共同实现

传递保障主要依赖于 Producer

```java
properties.put(ProducerConfig.RETRIES_CONFIG,"0");
```



## Consumer

### Consumer 基本概念

Consumer Group

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_2.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_2.png)

### Consumer 注意事项

单个分区的消息只能由 ConsumerGroup 中某个 Consumer 消费

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_3.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_3.png)

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_4.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_4.png)

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_5.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_5.png)

Consumer 从 Partition 中消费消息是顺序, 默认从头开始消费

单个 ConsumerGroup 会消费所有 Partition 中的消息



### 新成员组加入

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_6.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_6.png)

### 新成员组崩溃

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_7.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_7.png)

### 组成员主动离组

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_8.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_8.png)



## Stream

### Stream 基本概念

Stream 是处理分析存储在 Kafka 数据的客户端程序库

Stream 通过 state store 可以实现高效状态操作

支持原语 Processor 和高层抽象 DSL

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_9.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_9.png)

### Stream 关键词

流及流处理器

流处理拓扑

源处理器及 sink 处理器



## Connect



## 集群

### 集群部署

kafka 天然支持集群

kafka 集群依赖于 Zookeeper 进行协调

kafka 主要通过 brokerId 区分不同节点

修改 server.properties 中的配置

`broker.id`

`listeners`

`log.dirs`

### kafka 副本集

kafka 副本集是指将日志复制多份

kafka 可以为每个 topic 设置副本集

kafka 可以通过配置设置默认副本集数量

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_10.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_10.png)

### 核心概念

broker: 一般指 kafka 的部署节点

leader: 用于处理消息的接收和消费等请求

follower: 主要用于备份消息数据

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_11.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_11.png)

### 节点故障

kafka 与 zookeeper 心跳未保持视为节点故障

follower 消息落后 leader 太多也视为节点故障(配置文件)

kafka 会对故障节点进行移除

### 节点故障处理

kafka 基本不会因为节点故障而丢失数据

kafka 的语义担保也很大程度上避免数据丢失

kafka 会对消息进行集群内平衡, 减少消息在某些节点热度过高

### leader 选举

kafka 并没有采用多数投票来选举 leader

kafka 会动态维护一组 leader 数据的副本(isr)

kafka 会在 isr 中选择一个速度比较快的设为 leader(集群中的 controller, 与 zookeeper 注册最快的那一个)

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_12.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_12.png)

kafka 有一种无奈的情况, isr 中副本全部宕机, 对于上述情况, kafka 会进行 unclean leader 选举, kafka 提供了两种不同的选择处理该部分, 建议禁用 unclean leader 选举, 手动指定最小 isr

*   等待 isr 中的某个副本恢复
*   选举 isr 副本以外的节点进行选举(会丢失数据)



### 集群监控

kafka 只能依靠 kafka-run-class.shde 等命令来进行管理

kafka manager 是目前比较常见的监控工具



## SpringCloud Config

为微服务体系提供了统一外部化配置

分为服务端和客户端两类

默认使用 git 进行配置存储

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_13.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_13.png)



## SpringCloud Bus

提供了服务总线的功能

提供了服务节点与消息系统连接的功能

提供了事件处理机制和消息中间件的功能

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_14.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_14.png)



## 面试

特性一: 提供发布订阅及 topic 支持

特性二: 吞吐量高但不保证消息有序(同一 topic 的同一 partition 中保证有序)

**kafka 常见应用场景**

日志收集系统或流式系统

消息系统

用户活动跟踪或运营指标监控

**吞吐量为什么大速度为什么快**

日志顺序读写和快速检索

partition 机制

批量发送接收及数据压缩机制

通过 sendfile 实现零拷贝原则

#### 日志原理

kafka 的日志是以 partition 为单位进行保存的

日志目录格式为 topic 名称 + 数字

日志文件格式是一个"日志条目"序列

每条日志消息由 4 字节整形与 N 字节消息组成

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_15.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_15.png)

每个 partiotion 的日志会分为 N 个大小相等的 segment 中

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_16.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_16.png)

每个 segment 中消息数量不一定相等

每个 partiotion 只支持顺序读写

partition 会将消息添加到最后一个 segment 上

当 segment 达到一定阈值会 flush 到磁盘上

segment 文件分为两部分: index 和 log(data)

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_17.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_17.png)

日志读操作

1.  首先需要在存储的数据中找出 segment 文件
2.  然后通过全局 offset 计算出 segment 中的 offset
3.  通过 index 中的 offset 寻找具体数据内容

日志写操作

1.  日志允许串行的追加消息到文件最后
2.  当日志文件达到阈值则滚动到新文件上

#### 零拷贝

正常规范中会有 4 次拷贝过程

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_18.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_18.png)

**使用零拷贝的话避免了用户缓冲区的 2 次拷贝, 同时最主要的是避免了上下文的切换**

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_19.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_19.png)



### 消费者和消费者组

kafka 消费者组是 kafka 消费的单位

单个 partition 只能由消费者组中的某个消费者消费

消费者组中的单个消费者可以消费多个 partition



### producer 客户端

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_20.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_20.png)

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_21.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_21.png)

producer 单独维护了一个度列, 创建 producer 时会自动创建一个守护进程, 当调用 send 方法时, 会将消息发送到缓冲队列中, 达到一定阈值守护进程会将队列中的数据发送到 broker 中同时返回 future



### 如何保证顺序性

kafka 的特性只支持单 partition 有序

使用 kafka key + offset 可以做到业务有序



### topic 删除

![https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_22.png](https://www.miaomiaoqi.github.io/images/mq/kafka/kafka_22.png)



### 重复消费和漏消费

本质上来讲就是 offset 控制出问题

#### 重复消费

认为原因, 尤其是在 Consumer 的使用上

程序处理原因, 尤其是单次消费超时的情况

kafka 机制: 消费者重平衡时 offset 未控制好



### 线程安全问题

不是线程安全的, consumer 的两种消费方式: 多 consumer, 单 consumer 多线程处理



### leader 选举分析

新的 leader 必须要尽量包含所有消息, 即消息完整性

不能产生过多的冗余导致过多的磁盘 IO

#### 选举过程

维护一个 isr 列表, 由 isr 列表中选择 leader

选举一个 broker 作为 controller 检查 broker 级别故障

不得不说 unclean leader 选举(isr 列表都不可用且 leader 又挂了)



### 幂等性如何实现

