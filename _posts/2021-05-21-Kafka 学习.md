---
layout: post
title: Kafka 学习
categories: [MessageQueue]
description: 
keywords: 
---


* content
{:toc}






## Kafka 概述

### 定义

 Kafka传统定义：Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。

 发布/订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息分为不同的类别，订阅者只接收感兴趣的消息

 Kafka 最新定义： Kafka 是一个开源的分布式事件流平台（ Event Streaming Platform），被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_1.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_1.png)



### 消息队列

目前企业中比较常见的消息队列产品主要有Kafka、ActiveMQ、RabbitMQ、RocketMQ等。

在大数据场景主要采用Kafka作为消息队列

#### 传统消息队列的应用场景

传统的消息队列的主要应用场景包括：缓存**/**消峰、解耦和异步通信。

##### 缓冲/消峰

缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_2.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_2.png)

##### 解耦

解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_3.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_3.png)

##### 异步通信

异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_4.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_4.png)



#### 消息队列的两种模式

##### 点对点

消费者主动拉取数据，消息收到后清除消息

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_5.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_5.png)

##### 发布/订阅

可以有多个 topic 主题（浏览、点赞、收藏、评论等） 

消费者消费数据之后，不删除数据

消费者消费数据之后，不删除数据• 每个消费者相互独立，都可以消费到数据

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_6.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_6.png)





### Kfka 基础架构

为方便扩展，并提高吞吐量，一个 topic 分为多个 partition 

配合分区的设计，提出消费者组的概念，组内每个消费者并行消费

为提高可用性，为每个 partition 增加若干副本，类似 NameNode HA 

ZK 中记录谁是 leader，Kafka2.8.0 以后也可以配置不采用ZK 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_7.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_7.png)



**Producer**：消息生产者，就是向 Kafka broker 发消息的客户端。

**Consumer**：消息消费者，向 Kafka broker 取消息的客户端。

**Consumer Group**（**CG**）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

**Broker**：一台Kafka服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。

**Topic**：可以理解为一个队列，生产者和消费者面向的都是一个 **topic**。

**Partition**：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个**topic**可以分为多个**partition**，每个partition是一个有序的队列。每个 partition 只能被一个 consumer 消费

**Replica**：副本。一个 topic 的每个分区都有若干个副本，一个**Leader**和若干个**Follower**。

**Leader**：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是Leader。

**Follower**：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。





## 快速入门

### 安装部署

#### 集群规划

| localhost | lolcahost | localhost |
| --------- | --------- | --------- |
| zk02      | zk03      | zk04      |
| kafka02   | kafka03   | kafka04   |

#### 集群部署

我是在 mac 上创建了 kafka-cluster 文件夹, 分别创建了 kafka02, kafka03, kafka04

1.   官方下载地址：http://kafka.apache.org/downloads.html

2.   解压缩安装包

     ```bash
     tar -xzvf kafka_2.12-3.0.0.tgz -C .
     ```

3.   修改解压后的文件名称

     ```bash
     mv kafka_2.12-3.0.0 kafka
     ```

4.   进入到 kafka 目录，修改配置文件

     ```bash
     vim config/server.properties
     ```

     输入以下内容

     ```bash
     # broker 的 全局唯一编号，不能重复 ，只能是数字 。
     # 自己修改
     broker.id=2
     # 处理网络请求 的 线程数量
     num.network.threads=3
     #用来 处理磁盘 IO 的 线程 数量
     num.io.threads=8
     # 发送套接字的缓冲区大小
     socket.send.buffer.bytes=102400
     # 接收套接字的缓冲区大小
     socket.receive.buffer.bytes=102400
     #请求套接字的缓冲区大小
     socket.request.max.bytes=104857600
     # kafka 运行日志 数据 存放的路径 ，路径不需要提前创建 k afka 自动帮你创建 ，可以配置多个磁盘路径，路径与路径之间可以用分隔
     # 自己修改
     log.dirs=/Users/miaoqi/Documents/kafka-cluster/kafka02/datas
     # topic 在当前 broker 上的分区个数
     num.partitions=1
     # 用来恢复和清理 data 下数据的线程数量
     num.recovery.threads.per.data.dir=1
     # 每个 topic 创建时的副本数，默认时 1 个副本
     offsets.topic.replication.factor=1
     # segment 文件保留的最长时间，超时将被删除
     log.retention.hours=168
     # 每个 segment 文件 的大小，默认最大 1G
     log.segment.bytes=1073741824
     # 检查过期数据的时间，默认 5 分钟检查一次是否数据过期
     log.retention.check.interval.ms=300000
     # 自己修改
     # 配置连接 Zookeeper 集群地址在 zk 根目录下创建 kafka 目录，方便管理
     zookeeper.connect=localhost:2182,localhost:2183,localhost:2184/kafka
     ```

5.   分别在 kafka03 和 kafka04 上修改配置文件 config/server.properties 中的 broker.id=3, broker.id=4

     注：broker.id 不得重复，整个集群中唯一。

6.   配置环境变量

     ```bash
     vim ~/.zshrc
     ```

     ```bash
     # KAFKA_HOME
     export KAFKA_HOME=~/Documents/kafka-cluster/kafka02
     export PATH=$PATH:$KAFKA_HOME/bin
     ```

     ```bash
     source ~/.zshrc
     ```

7.   启动集群

     先启动Zookeeper集群，然后启动Kafka。

     ```bash
     ~/Documents/zookeeper-cluster/zk.sh start
     ```

     依次在kafka02、kafka03、kafka04节点上启动Kafka

     ```bash
     ~/Documents/kafka-cluster/kafka02/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka02/config/server.properties
     ~/Documents/kafka-cluster/kafka03/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka03/config/server.properties
     ~/Documents/kafka-cluster/kafka04/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/kafka04/config/server.properties
     ```

8.   关闭集群 

     ```bash
     ~/Documents/kafka-cluster/kafka02/bin/kafka-server-stop.sh
     ~/Documents/kafka-cluster/kafka03/bin/kafka-server-stop.sh
     ~/Documents/kafka-cluster/kafka04/bin/kafka-server-stop.sh
     ```

     



#### 集群启停脚本

1.   在~/Documents/kafka-cluster目录下创建文件kf.sh脚本文件

     ```bash
     vim kf.sh
     ```

     脚本如下

     ```bash
     #!/bin/bash
     
     case $1 in
         "start"){
             for i in kafka02 kafka03 kafka04
             do
                 echo -------- $i 启动 ---------
                 eval "~/Documents/kafka-cluster/$i/bin/kafka-server-start.sh -daemon ~/Documents/kafka-cluster/$i/config/server.properties"
             done
         };;
         "stop"){
             for i in kafka02 kafka03 kafka04
             do
                 echo -------- $i 停止 ---------
                 eval "~/Documents/kafka-cluster/$i/bin/kafka-server-stop.sh"
             done
         };;
     esac
     ```

2.   添加执行权限

     ```bash
     chmod 777 kf.sh
     ```

3.   启动集群命令

     ```bash
     ./kf.sh start
     ```

4.   停止集群命令

     ```bash
     ./kf.sh stop
     ```

注意：停止Kafka集群时，一定要等Kafka所有节点进程全部停止后再停止Zookeeper集群。因为Zookeeper集群当中记录着Kafka集群相关信息，Zookeeper集群一旦先停止，Kafka集群就没有办法再获取停止进程的信息，只能手动杀死Kafka进程了。



### Kafka 命令行操作

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_8.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_8.png)

#### 主题命令行操作

1.   查看主题命令行参数

```bash
bin/kafka-topics.sh
```

| 参数                                             | 描述                              |
| ------------------------------------------------ | --------------------------------- |
| --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号 |
| --topic <String: topic>                          | 操作的topic名称                   |
| --create                                         | 创建主题                          |
| --delete                                         | 删除主题                          |
| --alter                                          | 修改主题。                        |
| --list                                           | 查看所有主题。                    |
| --describe                                       | 查看主题详细描述                  |
| --partitions <Integer: # of partitions>          | 设置分区数                        |
| --replication-factor<Integer:replication factor> | 设置分区副本                      |
| --config <String: name=value>                    | 更新系统默认的配置                |

2.   查看当前服务器中的所有topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9093 --list
     ```

3.   创建 first topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 1 --replication-factor 3 --topic first
     ```

     --topic 定义topic名

     --replication-factor 定义副本数

     --partitions 定义分区数

4.   查看first主题的详情

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first
     ```

5.   修改分区数（注意：分区数只能增加，不能减少）

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic first --partitions 3
     ```

6.   再次查看first主题的详情

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first
     ```

7.   ）删除topic

     ```bash
     bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic first
     ```

     

#### 生产者命令行操作

1.   查看操作生产者命令参数

     ```bash
     bin/kafka-console-producer.sh
     ```

     | 参数                                             | 描述                                |
     | ------------------------------------------------ | ----------------------------------- |
     | --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号。 |
     | --topic <String: topic>                          | 操作的topic名称                     |

2.   发送消息

     ```bash
     bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first
     >hello world
     >atguigu atguigu
     ```



#### 消费者命令行操作

1.   查看操作消费者命令参数

     ```bash
     bim/kafka-console-consumer.sh
     ```

     | 参数                                             | 描述                                |
     | ------------------------------------------------ | ----------------------------------- |
     | --bootstrap-server <String: server toconnect to> | 连接的KafkaBroker主机名称和端口号。 |
     | --topic <String: topic>                          | 操作的topic名称                     |
     | --group <String: consumer group id>              | 指定消费者组名称。                  |
     | --from-beginning                                 | 从头开始消费。                      |

2.   消费消息

     消费 first 主题中的数据

     ```bash
     bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first
     ```

     把主题中所有的数据都读取出来（包括历史数据）

     ```bash
     bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic first
     ```



## Kafka 生产者

### 生产者消息发送流程

#### 发送原理

在消息发送的过程中，涉及到了两个线程——**main**线程和**Sender**线程。在main线程中创建了一个双端队列**RecordAccumulator**。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到KafkaBroker。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_9.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_9.png)

batch.size：只有数据积累到batch.size之后，sender才会发送数据。默认16k 

linger.ms：如果数据迟迟未达到batch.size，sender等待linger.ms设置的时间到了之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。

0：生产者发送过来的数据，不需要等数据落盘应答

1：生产者发送过来的数据，Leader收到数据后应答

-1（all）：生产者发送过来的数据，Leader和ISR队列里面的所有节点收齐数据后应答。-1和all等价



#### 生产者重要参数列表

| 参数名称                              | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | 生产者连接集群所需的broker地址清单。例如hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置1个或者多个，中间用逗号隔开。注意这里并非需要所有的broker地址，因为生产者从给定的broker里查找到其他broker信息。 |
| key.serializer和value.serializer      | 指定发送消息的key和value的序列化类型。一定要写全类名。       |
| buffer.memory                         | RecordAccumulator缓冲区总大小，默认32m。                     |
| batch.size                            | 缓冲区一批数据最大值，默认16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加。 |
| linger.ms                             | 如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。单位ms，默认值是0ms，表示没有延迟。生产环境建议该值大小为5-100ms之间。 |
| acks                                  | 0：生产者发送过来的数据，不需要等数据落盘应答。 1：生产者发送过来的数据，Leader收到数据后应答。 -1（all）：生产者发送过来的数据，Leader+和isr队列里面的所有节点收齐数据后应答。默认值是-1，-1和all是等价的。 |
| max.in.flight.requests.per.connection | 允许最多没有返回ack的次数，默认为5，开启幂等性要保证该值是1-5的数字。 |
| retries                               | 当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。默认是int最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1否则在重试此失败消息的时候，其他的消息可能发送成功了。 |
| retry.backoff.ms                      | 两次重试之间的时间间隔，默认是100ms。                        |
| enable.idempotence                    | 是否开启幂等性，默认true，开启幂等性。                       |
| compression.type                      | 生产者发送的所有数据的压缩方式。默认是none，也就是不压缩。 支持压缩类型：none、gzip、snappy、lz4和zstd |



### 异步发送 API

#### 普通异步发送

需求：创建Kafka生产者，采用异步的方式发送到KafkaBroker

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_10.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_10.png)

代码: 参考 messagequeue/atguigu-kafka CustomProducer



#### 带回调函数的异步发送

回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception），如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_11.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_11.png)

**注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试**

代码: 参考 messagequeue/atguigu-kafka CustomProducerCallback



### 同步发送 API

只需在异步发送的基础上，再调用一下get()方法即可

代码: 参考 messagequeue/atguigu-kafka CustomProducerSync



### 生产者分区

#### 分区好处

便于合理使用存储资源，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现**负载均衡**的效果。

提高并行度，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_12.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_12.png)

#### 生产者发送消息的分区策略

默认的分区器**DefaultPartitioner**

在IDEA中全局查找DefaultPartitioner

```java
/**
* The default partitioning strategy:
* <ul>
* <li>If a partition is specified in the record, use it
* <li>If no partition is specified but a key is present choose a
partition based on a hash of the key
* <li>If no partition or key is present choose the sticky
partition that changes when the batch is full.
*
* See KIP-480 for details about sticky partitioning.
*/
public class DefaultPartitioner implements Partitioner {
… …
}
```

```java
kafkaProducer.send(new ProducerRecord<>("first", "mmm"));
```

1.   指明partition的情况下，直接将指明的值作为partition值； 例如partition=0，所有数据写入分区0 

2.   没有指明partition值但有key的情况下，将key的hash值与topic的partition数进行取余得到partition值； 例如：key1的hash值=5， key2的hash值=6 ，topic的partition数=2，那么key1 对应的value1写入1号分区，key2对应的value2写入0号分区。

3.   既没有partition值又没有key值的情况下，Kafka采用Sticky Partition（黏性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者已完成，Kafka再随机一个分区进行使用（和上一次的分区不同）。例如：第一次随机选择0号分区，等0号分区当前批次满了（默认16k）或者linger.ms设置的时间到， Kafka再随机一个分区进行使用（如果还是0会继续随机）。

#### 自定义分区器

需求: 例如我们实现一个分区器实现，发送过来的数据中如果包含atguigu，就发往0号分区，不包含atguigu，就发往1号分区

实现步骤

1.   定义类实现Partitioner接口
2.   重写partition()方法
3.   使用分区器的方法，在生产者的配置中添加分区器参数。

代码: 参考 messagequeue/atguigu-kafka  [CustomProducerCallbackPartitions.java

### 生产经验-生产者如何提高吞吐量

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_13.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_13.png)

batch.size：批次大小，默认16k

linger.ms：等待时间，修改为5-100ms

compression.type：压缩snappy

RecordAccumulator：缓冲区大小，修改为64m

代码: 参考 messagequeue/atguigu-kafka  CustomProducerCallbackParameters



### 生产经验-数据可靠性

#### ack 应答级别

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_14.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_14.png)

思考：Leader收到数据，所有Follower都开始同步数据，但有一个Follower，因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢？

Leader维护了一个动态的in-syncreplicaset（**ISR**），意为和Leader保持同步的Follower+Leader集合(leader：0，isr:0,1,2)。

如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由**replica.lag.time.max.ms**参数设定，默认30s。例如2超时，(leader:0, isr:0,1)。

这样就不用等长期联系不上或者已经故障的节点。

#### 数据可靠性分析

如果分区副本设置为1个，或者ISR里应答的最小副本数量（min.insync.replicas默认为1）设置为1，和ack=1的效果是一样的，仍然有丢数的风险（leader：0，isr:0）。

数据完全可靠条件**=ACK**级别设置为**-1+**分区副本大于等于**2+ISR**里应答的最小副本数量大于等于**2**

#### 可靠性总结

**acks=0**，生产者发送过来数据就不管了，可靠性差，效率高；

**acks=1**，生产者发送过来数据**Leader**应答，可靠性中等，效率中等

**acks=-1**，生产者发送过来数据**Leader**和**ISR**队列里面所有**Follwer**应答，可靠性高，效率低

在生产环境中，**acks=0**很少使用；**acks=1**，一般用于传输普通日志，允许丢个别数据；**acks=-1**，一般用于传输和钱相关的数据，对可靠性要求比较高的场景

代码: 参考 messagequeue/atguigu-kafka  CustomProducerCallbackAcks



### 生产经验-数据去重

ack: -1(all): 生产者发送过来的数据，**Leader**和**ISR**队列里面的所有节点收齐数据后应答, 但这时 leader 挂掉了又选出了一个新的 leader, 此时 producer 就会向新的 leader 再发送一份数据, 造成数据重复

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_15.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_15.png)

#### 数据传递语义

至少一次（At Least Once）=ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2 

最多一次（AtMost Once）= ACK级别设置为0

总结：

At Least Once可以保证数据不丢失，但是不能保证数据不重复

At Most Once可以保证数据不重复，但是不能保证数据不丢失

精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。Kafka 0.11版本以后，引入了一项重大特性:**幂等性和事务**



#### 幂等性

幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复

精确一次（Exactly Once） = 幂等性+ 至少一次（ ack=-1 + 分区副本数>=2 + ISR最小副本数量>=2） 

重复数据的判断标准：具有<PID, Partition, SeqNumber>相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。

所以幂等性只能保证的是在单分区单会话内不重复。 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_16.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_16.png)

开启参数 **enable.idempotence** 默认为 true，false 关闭



#### 生产者事务

说明：开启事务，必须开启幂等性。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_17.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_17.png)

代码: 参考 messagequeue/atguigu-kafka  CustomProducerCallbackTransactions



### 生产经验-数据有序

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_18.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_18.png)



### 生产经验-数据乱序

kafka 在1.x版本之前保证数据单分区有序，条件如下

*   max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）

kafka 在1.x及以后版本保证数据单分区有序，条件如下

*   未开启幂等性 `max.in.flight.requests.per.connection` 需要设置为 1
*   开启幂等性 `max.in.flight.requests.per.connection` 需要设置小于等于 5, 原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据， 故无论如何，都可以保证最近5个request的数据都是有序的。 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_19.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_19.png)



## Kafka Broker

### Kafka Broker 的工作流程

#### Zookeeper 存储的 Kafka 信息

启动Zookeeper客户端

`bin/zkCli.sh`

通过ls命令可以查看kafka相关信息

`ls /kafka`

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_20.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_20.png)



#### Kafka Broker 总体的工作流程

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_21.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_21.png)



#### Kafka Broker 重要参数

| 参数名称                                | 描述                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| replica.lag.time.max.ms                 | ISR中，如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值，默认30s。 |
| auto.leader.rebalance.enable            | 默认是true。自动LeaderPartition 平衡。                       |
| leader.imbalance.per.broker.percentage  | 默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。 |
| leader.imbalance.check.interval.seconds | 默认值300秒。检查leader负载是否平衡的间隔时间。              |
| log.segment.bytes                       | Kafka中log日志是分成一块块存储的，此配置是指log日志划分成块的大小，默认值1G。 |
| log.index.interval.bytes                | 默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引 |
| log.retention.hours                     | Kafka中数据保存的时间，默认7天。                             |
| log.retention.minutes                   | Kafka中数据保存的时间，分钟级别，默认关闭。                  |
| log.retention.ms                        | Kafka中数据保存的时间，毫秒级别，默认关闭。                  |
| log.retention.check.interval.ms         | 检查数据是否保存超时的间隔，默认是5分钟。                    |
| log.retention.bytes                     | 默认等于-1，表示无穷大。超过设置的所有日志总大小，删除最早的segment。 |
| log.cleanup.policy                      | 默认是delete，表示所有数据启用删除策略； 如果设置值为compact，表示所有数据启用压缩策略。 |
| num.io.threads                          | 默认是8。负责写磁盘的线程数。整个参数值要占总核数的50%。     |
| num.replica.fetchers                    | 副本拉取线程数，这个参数占总核数的50%的1/3                   |
| num.network.threads                     | 默认是3。数据传输线程数，这个参数占总核数的50%的2/3。        |
| log.flush.interval.messages             | 强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。 |
| log.flush.interval.ms                   | 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。 |



### 生产经验-节点服役和退役



#### 服役新节点



#### 退役旧节点



### Kafka 副本

#### 副本基本信息

Kafka副本作用：提高数据可靠性。

Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。

Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。

Kafka分区中的所有副本统称为AR（Assigned Repllicas）。

AR=ISR+OSR

**ISR**，表示和Leader保持同步的Follower集合。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由**replica.lag.time.max.ms**参数设定，默认30s。Leader发生故障之后，就会从ISR中选举新的Leader。

**OSR**，表示Follower与Leader副本同步时，延迟过多的副本。



#### Leader 选举流程

Kafka集群中有一个broker的Controller会被选举为ControllerLeader，负责管理集群broker的上下线，所有topic的分区副本分配和Leader选举等工作。

Controller的信息同步工作是依赖于Zookeeper的。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_22.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_22.png)

创建一个新的topic，4个分区，4个副本

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --create --topic atguigu1 --partitions 4 --replication-factor
4
Created topic atguigu1.
```

查看Leader分布情况

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe
--topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4
Configs: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 3 Replicas: 3,0,2,1 Isr: 3,0,2,1
Topic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,3,0
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,3,1,2
Topic: atguigu1 Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0,3
```

停止掉hadoop105的kafka进程，并查看Leader分区情况

```bash
[atguigu@hadoop105 kafka]$ bin/kafka-server-stop.sh
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe
--topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4
Configs: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,2,1
Topic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,0
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1,2
Topic: atguigu1 Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0
```

停止掉hadoop104的kafka进程，并查看Leader分区情况

```bash
[ hadoop104 kafka]$ bin/kafka server stop.sh
[atguigu@hadoop102 bin/kafka topics.sh bootstrap server hadoop102:9092 describe
topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4
Configs: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 0 Replicas: 3 ,0,2,1 Isr: 0,1
Topic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,0
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1
Topic: atguigu1 Partition: 3 Leader: 1 Replicas: 2,1,0,3 Isr: 1,0
```

启动hadoop105的kafka进程，并查看Leader分区情况

```bash
[a tguigu@ hadoop105 kafka]$ bin/kafka server start.sh daemon config/server.properties
[atguigu@hadoop102 kafka]$ bin/kafka topics.sh bootstrap server hadoop102:9092 describe
topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR OX3Vl6HE8sVg PartitionCoun t: 4 ReplicationFactor: 4
Configs: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,1,3
Topic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,0,3
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1,3
Topic: atguigu1 Partition: 3 Leader: 1 Replicas: 2,1,0,3 Isr: 1,0,3
```

启动hadoop104的kafka进程，并查看Leader分区情况

```bash
[ hadoop10 4 kafka]$ bin/kafka server start.sh daemon config/server.properties
[atguigu@hadoop102 kafka]$ bin/kafka topics. sh bootstrap server hadoop102:9092 describe
topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4
Configs: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,1,3, 2
Topic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,0,3,2
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1,3,2
Topic: atguigu1 Partition: 3 Leader: 1 Replicas: 2,1,0,3 Isr: 1,0,3,2
```

停止掉hadoop103的kafka进程，并查看Leader分区情况

```bash
[ hadoop10 3 kafka]$ bin/kafka server stop.sh
[atguigu@hadoop102 kafka]$ bin/kafka topics.sh bootstrap server hadoop102:9092 describe
topic atguigu1
Topic: atguigu1 TopicId: awpgX_7WR OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4
Config s: segment.bytes=1073741824
Topic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,3,2
Topic: atguigu1 Partition: 1 Leader: 2 Replicas: 1,2,3,0 Isr: 0,3,2
Topic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,3,2
Topic: atguigu1 Part ition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 0,3,2
```





#### Leader 和 Follower 故障处理细节

**Follower 故障处理细节**

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_23.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_23.png)



**Leader 故障处理细节**

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_24.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_24.png)



#### 分区副本分配

如果kafka服务器只有4个节点，那么设置kafka的分区数大于服务器台数，在kafka底层如何分配存储副本呢？

创建16分区，3个副本, 创建一个新的topic，名称为second。

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --create --partitions 16 --replication-factor 3 --topic second
```

查看分区和副本情况。

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --describe --topic second
Topic: second4 Partition: 0 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2
Topic: second4 Partition: 1 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3
Topic: second4 Partition: 2 Leader: 2 Replicas: 2,3,0 Isr: 2,3,0
Topic: second4 Partition: 3 Leader: 3 Replicas: 3,0,1 Isr: 3,0,1
Topic: second4 Partition: 4 Leader: 0 Replicas: 0,2,3 Isr: 0,2,3
Topic: second4 Partition: 5 Leader: 1 Replicas: 1,3,0 Isr: 1,3,0
Topic: second4 Partition: 6 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1
Topic: second4 Partition: 7 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2
Topic: second4 Partition: 8 Leader: 0 Replicas: 0,3,1 Isr: 0,3,1
Topic: second4 Partition: 9 Leader: 1 Replicas: 1,0,2 Isr: 1,0,2
Topic: second4 Partition: 10 Leader: 2 Replicas: 2,1,3 Isr: 2,1,3
Topic: second4 Partition: 11 Leader: 3 Replicas: 3,2,0 Isr: 3,2,0
Topic: second4 Partition: 12 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2
Topic: second4 Partition: 13 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3
Topic: second4 Partition: 14 Leader: 2 Replicas: 2,3,0 Isr: 2,3,0
Topic: second4 Partition: 15 Leader: 3 Replicas: 3,0,1 Isr: 3,0,1
```

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_25.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_25.png)



#### 生产经验-手动调整分区副本存储

在生产环境中，每台服务器的配置和性能不一致，但是Kafka只会根据自己的代码规则创建对应的分区副本，就会导致个别服务器存储压力较大。所有需要手动调整分区副本的存储。

需求：创建一个新的topic，4个分区，两个副本，名称为three。将该topic的所有副本都存储到broker0和broker1两台服务器上。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_26.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_26.png)

手动调整分区副本存储的步骤如下：

创建一个新的topic，名称为three。

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --create --partitions 4 --replication-factor 2 --
topic three
```

查看分区副本存储情况

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --describe --topic three
```

创建副本存储计划（所有副本都指定存储在broker0、broker1中）。

```bash
[atguigu@hadoop102 kafka]$ vim increase-replication-factor.json

{
"version":1,
"partitions":[{"topic":"three","partition":0,"replicas":[0,1]},
{"topic":"three","partition":1,"replicas":[0,1]},
{"topic":"three","partition":2,"replicas":[1,0]},
{"topic":"three","partition":3,"replicas":[1,0]}]
}
```

执行副本存储计划

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file
increase-replication-factor.json --execute
```

验证副本存储计划

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file
increase-replication-factor.json --verify
```

查看分区副本存储情况

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --describe --topic three
```



#### 生产经验-LeaderPartition 负载平衡

正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_27.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_27.png)



下面拿一个主题举例说明，假设集群只有一个主题如下图所示：

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_28.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_28.png)

针对broker0节点，分区2的AR优先副本是0节点，但是0节点却不是Leader节点，所以不平衡数加1，AR副本总数是4

所以broker0节点不平衡率为1/4>10%，需要再平衡。

broker2和broker3节点和broker0不平衡率一样，需要再平衡。

Broker1的不平衡数为0，不需要再平衡

| 参数名称                                | 描述                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| auto.leader.rebalance.enable            | 默认是true。自动LeaderPartition 平衡。生产环境中，leader重选举的代价比较大，可能会带来性能影响，建议设置为false关闭。 |
| leader.imbalance.per.broker.percentage  | 默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。 |
| leader.imbalance.check.interval.seconds | 默认值300秒。检查leader负载是否平衡的间隔时间。              |



#### 生产经验-增加副本因子

在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。

创建topic

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server
hadoop102:9092 --create --partitions 3 --replication-factor 1 --
topic four
```

手动增加副本存储, 创建副本存储计划（所有副本都指定存储在broker0、broker1、broker2中）。

```bash
[atguigu@hadoop102 kafka]$ vim increase-replication-factor.json

{"version":1,"partitions":[{"topic":"four","partition":0,"replica
s":[0,1,2]},{"topic":"four","partition":1,"replicas":[0,1,2]},{"t
opic":"four","partition":2,"replicas":[0,1,2]}]}
```

执行副本存储计划。

```bash
[atguigu@hadoop102 kafka]$ bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --reassignment-json-file
increase-replication-factor.json --execute
```



### 文件存储

#### 文件存储机制

Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。每个segment包括：“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_29.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_29.png)

一个topic分为多个partition

一个partition分为多个segment

.log 日志文件

.index 偏移量索引文件

.timeindex时间戳索引文件

其他文件

说明：index和log文件以当前segment的第一条消息的offset命名。

**index文件和log文件详解**

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_30.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_30.png)

| 参数                     | 描述                                                         |
| ------------------------ | ------------------------------------------------------------ |
| log.segment.bytes        | Kafka中log日志是分成一块块存储的，此配置是指log日志划分成块的大小，默认值1G。 |
| log.index.interval.bytes | 默认4kb，kafka里面每当写入了4kb大小的日志（.log），然后就往index文件里面记录一个索引。稀疏索引。 |



#### 文件清理策略

Kafka中默认的日志保存时间为7天，可以通过调整如下参数修改保存时间。

*   log.retention.hours，最低优先级小时，默认7天。

*   log.retention.minutes，分钟。

*   log.retention.ms，最高优先级毫秒。

*   log.retention.check.interval.ms，负责设置检查周期，默认5分钟

那么日志一旦超过了设置的时间，怎么处理呢？

Kafka中提供的日志清理策略有delete和compact两种。



delete日志删除：将过期数据删除

*   log.cleanup.policy=delete所有数据启用删除策略

    基于时间：默认打开。以segment中所有记录中的最大时间戳作为该文件时间戳。

    基于大小：默认关闭。超过设置的所有日志总大小，删除最早的segment。

    log.retention.bytes，默认等于-1，表示无穷大。

    如果一个segment中有一部分数据过期，一部分没有过期，怎么处理？

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_31.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_31.png)

compact日志压缩

compact日志压缩：对于相同key的不同value值，只保留最后一个版本

*   log.cleanup.policy = compact 所有数据启用压缩策略

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_32.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_32.png)

压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。

**这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料**



### 高效读写数据

*   **Kafka**本身是分布式集群，可以采用分区技术，并行度高

*   读数据采用稀疏索引，可以快速定位要消费的数据

*   顺序写磁盘

    Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。

    ![https://miaomiaoqi.github.io/images/mq/kafka/kfk_33.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_33.png)

*   页缓存**+** 零拷贝技术

    零拷贝：Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高

    PageCache页缓存：Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用

    ![https://miaomiaoqi.github.io/images/mq/kafka/kfk_34.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_34.png)

    | 参数                        | 描述                                                         |
    | --------------------------- | ------------------------------------------------------------ |
    | log.flush.interval.messages | 强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。 |
    | log.flush.interval.ms       | 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。 |





## Kafka 消费者

### Kafka 的消费方式

pull（拉）模式： consumer采用从broker中主动拉取数据。Kafka采用这种方式。

push（推）模式： Kafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的消费速率。例如推送的速度是50m/s， Consumer1、Consumer2就来不及处理消息。

pull模式不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据。 

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_35.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_35.png)



### Kafka 消费者工作流程

#### 消费者总体工作流程

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_36.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_36.png)

#### 消费者组原理

Consumer Group（CG）：消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。

*   消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。
*   消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_37.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_37.png)



![https://miaomiaoqi.github.io/images/mq/kafka/kfk_38.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_38.png)

如果向消费组中添加更多的消费者，超过主题分区数量，则有一部分消费者就会闲置，不会接收任何消息

消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者



**消费者组初始化流程**

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_39.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_39.png)

**消费者组详细消费流程**

![https://miaomiaoqi.github.io/images/mq/kafka/kfk_40.png](https://miaomiaoqi.github.io/images/mq/kafka/kfk_40.png)





#### 消费者重要参数



### 消费者 API

#### 独立消费者案例(订阅主题)

#### 独立消费者案例(订阅分区)

#### 消费者组案例



### 生产经验-分区的分配以及再平衡

#### Range 以及再平衡

#### RoundRobin 以及再平衡

#### Sticky 以及在平衡



### offset 位移

#### offset 的默认维护位置

#### 自动提交 offset

#### 手动提交 offset

#### 指定 offset 消费

#### 指定时间消费

#### 漏消费和重复消费分析



### 生产经验-消费者事务

### 生产经验-数据积压(消费者如何提高吞吐量)



### KafkaEagle 监控





