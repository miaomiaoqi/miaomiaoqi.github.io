---
layout: post
title: "Redis 基础"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## Redis 初识

Redis（全称：Remote Dictionary Server 远程字典服务）是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。

### Redis 的特性

#### 速度快

官方称 Redis 可以达到 10W QPS, 虽然实际上不会 100% 达到 10W QPS 但是几万 QPS 还是有的, 原因有如下 3 点

* 数据存储在内存中, 内存相较于寄存器来说便宜, 相较于硬盘来说速度又快许多, 足够满足日常需求

    <img src="https://miaomiaoqi.github.io/images/redis/redis_58.png" alt="https://miaomiaoqi.github.io/images/redis/redis_58.png" style="zoom: 33%;" />

    | 类型   | 每秒读写次数 | 随机读写延迟 | 访问带宽   |
    | ------ | ------------ | ------------ | ---------- |
    | 内存   | 千万级       | 80ns         | 5GB        |
    | SSD 盘 | 35000        | 0.1-0.2ms    | 100~300MB  |
    | 机械盘 | 100 左右     | 10ms         | 100MB 左右 |

* 使用 C 语言编写

* 单线程模型

#### 持久化

Redis 所有的数据保持在内存中, 对数据的更新将异步地保存到磁盘上

#### 多种数据结构

Redis 支持 5 种经典数据结构

<img src="https://miaomiaoqi.github.io/images/redis/redis_59.png" alt="https://miaomiaoqi.github.io/images/redis/redis_59.png" style="zoom: 33%;" />

还支持其他的数据结构

* BitMaps: 位图
* HyperLogLog: 超小内存唯一值计数
* GEO: 地理信息定位

#### 支持多种编辑语言

Java, PHP, Python, Ruby, Lua, Nodejs

#### 功能丰富

发布订阅, Lua 脚本实现自定义功能, 事务, pipeline

#### 简单

最初的版本只有 23000 行代码, 源码易读, 不依赖外部, 单线程模型

#### 主从复制, 高可用, 分布式

从 Redis2.8 开始支持 Redis-Sentinel 高可用

从 Redis3.0 开始支持 Redis-Cluster 分布式



#### Redis 默认 16 个数据库

Redis是一个字典结构的存储服务器, 一个Redis实例提供了多个用来存储数据的字典, 客户端可以指定将数据存储在哪个字典中. 这与在一个关系数据库实例中可以创建多个数据库类似（如下图所示）, 所以可以将其中的每个字典都理解成一个独立的数据库. 

Redis默认支持16个数据库, 可以通过调整Redis的配置文件redis/redis.conf中的databases来修改这一个值, 设置完毕后重启Redis便完成配置. 

客户端与Redis建立连接后会默认选择0号数据库, 不过可以随时使用SELECT命令更换数据库. 

由于Redis不支持自定义数据库的名字, 所以每个数据库都以编号命名. 开发者则需要自己记录存储的数据与数据库的对应关系. 另外Redis也不支持为每个数据库设置不同的访问密码, 所以一个客户端要么可以访问全部数据库, 要么全部数据库都没有权限访问. 但是, 要正确地理解Redis的“数据库”概念这里不得不提到一个命令:

`flushall`

该命令可以清空实例下的所有数据库数据, 这与我们所熟知的关系型数据库所不同. 关系型数据库多个库常用于存储不同应用程序的数据 , 且没有方式可以同时清空实例下的所有库数据. 所以对于Redis来说这些db更像是一种命名空间, 且不适宜存储不同应用程序的数据. 比如可以使用0号数据库存储某个应用生产环境中的数据, 使用1号数据库存储测试环境中的数据, 但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据, 不同的应用应该使用不同的Redis实例存储数据. Redis非常轻量级, 一个空Redis实例占用的内在只有1M左右, 所以不用担心多个Redis实例会额外占用很多内存. 

要注意以上所说的都是基于单体Redis的情况. 而在集群的情况下不支持使用select命令来切换db, 因为Redis集群模式下只有一个db0. 再扩展一些集群与单机Reids的区别, 感兴趣的朋友可以去查阅相关的资料深入理解, 这里就不做讨论了. 

- key 批量操作支持有限:例如 mget, mset 必须在一个 slot
- Key 事务和Lua支持有限:操作的 key 必须在一个节点
- key 是数据分区的最小粒度:不支持 bigkey 分区
- 不支持多个数据库: 集群模式下只有一个 db0
- 复制只支持一层:不支持树形复制结构



### 单线程 Redis 为什么这么快?

完全基于内存，绝大部分请求是纯粹的内存操作，非常快速

基本对象使用多种底层数据结构, 且灵活变化是 redis 高性能的另一个原因

采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗

**单线程为什么这么快**

* 纯内存
* 非阻塞 IO
* 避免线程切换和竞态消耗

**单线程要注意什么**

* 一次只运行一条命令

* 拒绝长(慢)命令, keys, flushall, flushdb, slow lua script, multi/exec, operate big value(collection)

* 其实不是单线程

    fysnc file descriptor

    close file descriptor



**采用了非阻塞 I/O 多路复用机制**

我们现在要仔细的说一说I/O多路复用机制, 因为这个说法实在是太通俗了, 通俗到一般人都不懂是什么意思.博主打一个比方: 小曲在S城开了一家快递店, 负责同城快送服务.小曲因为资金限制, 雇佣了一批快递员, 然后小曲发现资金不够了, 只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递, 小曲就让一个快递员盯着, 然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题

    几十个快递员基本上时间都花在了抢车上了, 大部分快递员都处在闲置状态, 谁抢到了车, 谁就能去送快递

    随着快递的增多, 快递员也越来越多, 小曲发现快递店里越来越挤, 没办法雇佣新的快递员了

    快递员之间的协调很花时间

    综合上述缺点, 小曲痛定思痛, 提出了下面的经营方式

* 经营方式二

    小曲只雇佣一个快递员.然后呢, 客户送来的快递, 小曲按送达地点标注好, 然后依次放在一个地方.最后, 那个快递员依次的去取快递, 一次拿一个, 然后开着车去送快递, 送好了就回来拿下一个快递.

    对比上述两种经营方式对比, 是不是明显觉得第二种, 效率更高, 更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:

    * 经营方式一就是传统的并发模型, 每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员), 通过跟踪每个I/O流的状态(每个快递的送达地点), 来管理多个I/O流.

    下面类比到真实的redis线程模型, 如图所示

    <img src="https://miaomiaoqi.github.io/images/redis/redis_1.png" alt="https://miaomiaoqi.github.io/images/redis/redis_1.png" style="zoom:50%;" />



### Redis 典型使用场景

缓存：减轻 MySQL 的查询压力，提升系统性能；

排行榜：利用 Redis 的 SortSet（有序集合）实现；

计算器/限速器：利用 Redis 中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等。这类操作如果用 MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个 API 的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；

好友关系：利用集合的一些命令，比如求交集、并集、差集等。可以方便解决一些共同好友、共同爱好之类的功能；

消息队列：除了 Redis 自身的发布/订阅模式，我们也可以利用 List 来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的 DB 压力，完全可以用 List 来完成异步解耦；

Session 共享：Session 是保存在服务器的文件中，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用 Redis 保存 Session 后，无论用户落在那台机器上都能够获取到对应的 Session 信息。

### 不适用场景

数据量太大、数据访问频率非常低的业务都不适合使用 Redis，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。

### Redis 单机安装

到官网下载, tar 解压缩, make&make install 安装

#### 可执行文件说明

redis-server: Redis 服务器

redis-cli: Redis 命令行客户端 `redis-cli -a miaomiaoqi -p 6379`

redis-benchmark: Redis 性能测试工具

redis-check-aof: AOF 文件修复工具

redis-check-dump: RDB 文件检查工具

redis-sentinel: Sentinel 服务器(2.8 之后)

#### 三种启动方式

最简启动: `redis-server` 使用默认参数

动态参数启动: `redis-server --port 6380`

配置文件启动: `redis-server configPath`

#### Redis 常用配置

daemonize: 是否是守护进程启动 no|yes

port: Redis 对外端口号, 默认 6379, 对应意大利女歌手的名字 Merz

logfile: Redis 系统日志

dir: Redis 工作目录

requirepass: 密码

protected-mode: 保护模式

去除空格和注释输出 redis 配置并重定向到新的文件 `cat redis-6381.conf|grep -v "#"|grep -v "^$" > redis-6382.com`

## 数据类型和 API 的理解和使用

### 数据结构和内部编码

Redis 是基于内存的数据库, 内存相对来说还是比较贵的, 如果我们在使用数据结构时, 以时间换取空间, 可以使用一些压缩的结构比如 ziplist, 如果元素个数比较小的时候, 就可以用空间来换时间, 这就是内部编码的作用, 可以使我们的 redis 有一个更好的使用率, 我们在使用时不用关心具体内部编码的实现, 直接使用数据结构的 api 即可, 是一种面向接口编程的思想

<img src="https://miaomiaoqi.github.io/images/redis/redis_62.png" alt="https://miaomiaoqi.github.io/images/redis/redis_62.png" style="zoom: 33%;" />

### redisObject 结构体

<img src="https://miaomiaoqi.github.io/images/redis/redis_63.png" alt="https://miaomiaoqi.github.io/images/redis/redis_63.png" style="zoom: 25%;" />

### 通用命令

| **命令**        | **描述**                                                     | **用法**                                                     |      |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
| DEL             | 1. 删除给定的一个或多个key<br/>2. 不存在的Key将被忽略        | DEL key1 [key2 ...]                                          | O(1) |
| EXISTS          | 1. 检查给定 key 是否存在<br />2. 存在返回 1, 不存在返回 0, 线上可用 | EXISTS key                                                   | O(1) |
| EXPIRE          | 1. 为给定key设置生存时间, key 过期时它会被自动删除<br/>2. 对一个已经指定生存时间的 key 设置执行expire, 新的值会代替旧的值 | EXPIRE key seconds                                           | O(1) |
| EXPIREAT        | 1. 同EXPIRE, 但此命令指定的是UNIX时间戳, 单位为秒            | EXPIRE key timestamp                                         | O(1) |
| KEYS            | 1. 查找所有符合给定模式 pattern 的 key, 下面举一下例子<br/>2. KEYS \*匹配所有key<br/>3. KEYS h?llo匹配hello, hallo, hxllo等<br/>4. KEYS h*llo匹配hllo, heeeeello等<br/>5. KEYS h[ae]llo匹配hello和hallo<br/>6. 特殊符号想当做查找内容经的使用\ <br />**7. 线上禁用该命令** | KEYS pattern                                                 | O(n) |
| DBSIZE          | 计算 key 的总数, 生产可用, 内部维护了计数器                  | DBSIZE                                                       | O(1) |
| MIGRATE         | 1. 原子性地将key从当前实例传送到目标实例指定的数据库上<br/>2. 原数据库Key删除, 新数据库Key增加<br/>3. 阻塞进行迁移的两个实例, 直到迁移成功, 迁移失败, 等待超时三个之一发生 | MIGRATE host port key destination-db timeout [COPY] [REPLACE] |      |
| MOVE            | 1. 将当前数据库的key移动到给定数据库的db中<br/>2. 执行成功的条件为当前数据库有key, 给定数据库没有key | MOVE key db                                                  |      |
| PERSIST         | 1. 移除给定key的生存时间, 将key变为持久的                    | PERSIST key                                                  |      |
| RANDOMKEY       | 1. 从当前数据库随机返回且不删除一个key,                      | RANDOMKEY                                                    |      |
| RENAME          | 1. 将key改名为newkey<br/>2. 当key和newkey相同或key不存在, 报错<br/>3. newkey已存在, RENAME将覆盖旧值 | RENAME key newkey                                            |      |
| TTL             | 1. 以秒为单位, 返回给定的key剩余生存时间                     | TTL key                                                      |      |
| PTTL            | 1. 以毫秒为单位, 返回给定的key剩余生存时间                   | PTTL key                                                     |      |
| TYPE            | 1. 返回key锁存储的值的类型, string, hash, list, set, zset, none | TYPE key                                                     | O(1) |
| OBJECT ENCODING | 1. 显示数据类型的底层数据结构                                | OBJECT ENCODING key                                          |      |
| INFO MEMORY     | 1. 查看内存使用情况                                          | INFO MEMORY                                                  |      |
| UNLINK          | 非阻塞删除, 仅仅将 key 从 keyspace 元数据中删除, 真正的删除会在后续的异步中 |                                                              |      |



### 系统相关命令

| **命令**         | **描述**                                                     | **用法**                   |
| ---------------- | ------------------------------------------------------------ | -------------------------- |
| BGREWRITEAOF     | 1. 手动触发AOF重写操作, 用于减小AOF文件体积                  | BGREWRITEAOF               |
| BGSAVE           | 1. 后台异步保存当前数据库的数据到磁盘                        | BGSAVE                     |
| CLIENT KILL      | 1. 关闭地址为ip:port的客户端<br/>2. 由于Redis为单线程设计, 因此当当前命令执行完之后才会关闭客户端 | CLIENT KILL ip:port        |
| CLIENT LIST      | 1. 以可读的格式, 返回所有连接到服务器的客户端信息和统计数据  | CLIENT LIST                |
| CONFIG GET       | 1. 取得运行中的Redis服务器配置参数<br/>2. 支持*              | CONFIG GET parameter       |
| CONFIG RESETSTAT | 1. 重置INFO命令中的某些统计数据, 例如Keyspace hits, Keyspace misses等 | CONFIG RESETSTAT           |
| CONFIG REWRITE   | 1. 对**启动Redis时指定的redis.conf文件进行改写**             | CONFIG REWRITE             |
| CONFIG SET       | 1. 动态调整Redis服务器的配置而无需重启<br/>2. 修改后的配置**立即生效** | CONFIG SET parameter value |
| SELECT           | 1. 切换到指定数据库, 数据库索引index用数字指定, 以0作为起始索引值<br/>2. 默认使用0号数据库 | SELECT index               |
| DBSIZE           | 1. 返回当前数据库的Key的数量                                 | DBSIZE                     |
| DEBUG OBJECT     | 1. 这是一个调试命令, 不应当被客户端使用<br/>2. key存在时返回有关信息, key不存在时返回错误 | DEBUG OBJECT key           |
| FLUSHALL         | 1. 清空整个Redis服务器的数据<br />2. 线上禁用                | FLUSHALL                   |
| FLUSHDB          | 1. 清空当前数据库中的所有数据                                | FLUSHDB                    |
| INFO             | 1. 以一种易于解释且易于阅读的格式, 返回Redis服务器的各种信息和统计数值2. 通过给定可选参数section, 可以让命令只返回某一部分信息 | INFO [section]             |
| LASTSAVE         | 1. 返回最近一次Redis成功将数据保存到磁盘上的时间, 以UNIX时间戳格式表示 | LASTSAVE                   |
| MONITOR          | 1. 实时打印出Redis服务器接收到的命令, 调试用                 | MONITOR                    |
| SHUTDOWN         | 1. 停止所有客户端<br/>2. 如果至少有一个保存点在等待, 执行SAVE命令<br/>3. 如果AOF选项被打开, 更新AOF文件<br/>4. 关闭Redis服务器 | SHUTDOWN [SAVE\|NOSAVE]    |





### SCAN 命令

**SCAN [key] cursor [MATCH pattern] [COUNT count]**

SCAN 命令及其相关的 SSCAN 命令,  HSCAN 命令和 ZSCAN 命令都用于增量地迭代(incrementally iterate)一集元素(a collection of elements):

* SCAN 命令用于迭代当前数据库中的所有数据库键.

* SSCAN 命令用于迭代集合键中的元素.

* HSCAN 命令用于迭代哈希键中的键值对.

* ZSCAN 命令用于迭代有序集合中的元素(包括元素成员和元素分值).

以上列出的四个命令都支持增量式迭代, 它们每次执行都只会返回少量元素, 所以这些命令可以用于生产环境, 而不会出现像 KEYS 命令,  SMEMBERS 命令带来的问题 —— 当 KEYS 命令被用于处理一个大的数据库时, 又或者 SMEMBERS 命令被用于处理一个大的集合键时, 它们可能会阻塞服务器达数秒之久.

不过, 增量式迭代命令也不是没有缺点的:  举个例子, 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素, 但是对于 SCAN 这类增量式迭代命令来说, 因为在对键进行增量式迭代的过程中, 键可能会被修改, 所以增量式迭代命令只能对被返回的元素提供有限的保证 (offer limited guarantees about the returned elements).

**需要注意的是:**

* SSCAN 命令,  HSCAN 命令和 ZSCAN 命令的第一个参数总是一个数据库键.

* 而 SCAN 命令则不需要在第一个参数提供任何数据库键, 因为它迭代的是当前数据库中的所有数据库键.

#### SCAN 命令基本用法

SCAN 命令是一个基于游标的迭代器(cursor based iterator):  SCAN 命令每次被调用之后, 都会向用户返回一个新的游标, 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数, 以此来延续之前的迭代过程.

当 SCAN 命令的游标参数被设置为 0 时, 服务器将开始一次新的迭代, 而当服务器向用户返回值为 0 的游标时, 表示迭代已结束.

首先使用 `keys *` 可以看到数据库中一共有19条数据, key* 共14条, akey\* 共5条

```bash
127.0.0.1:6379> keys *
 1) "key13"
 2) "key7"
 3) "akey5"
 4) "key11"
 5) "key12"
 6) "key14"
 7) "key6"
 8) "key2"
 9) "akey3"
10) "key3"
11) "key9"
12) "key10"
13) "key1"
14) "akey4"
15) "key5"
16) "akey2"
17) "akey1"
18) "key4"
19) "key8"
```

使用 `scan` 命令迭代过程如下:

```bash
127.0.0.1:6379> scan 0
1) "30"
2)  1) "key13"
    2) "key3"
    3) "key4"
    4) "key11"
    5) "key12"
    6) "akey1"
    7) "akey5"
    8) "key1"
    9) "key2"
   10) "akey3"
127.0.0.1:6379> scan 30
1) "0"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
   6) "key14"
   7) "akey4"
   8) "key5"
   9) "akey2"
127.0.0.1:6379>
```

在上面这个例子中, 第一次迭代使用 0 作为游标, 表示开始一次新的迭代.

第二次迭代使用的是第一次迭代时返回的游标, 也即是命令回复第一个元素的值 —— 30 .

从上面的示例可以看到, SCAN 命令的回复是一个包含两个元素的数组, 第一个数组元素是用于进行下一次迭代的新游标, 而第二个数组元素则是一个数组, 这个数组中包含了所有被迭代的元素.

在第二次调用 SCAN 命令时, 命令返回了游标 0 , 这表示迭代已经结束, 整个数据集(collection)已经被完整遍历过了.

以 0 作为游标开始一次新的迭代, 一直调用 SCAN 命令, 直到命令返回游标 0 , 我们称这个过程为一次**完整遍历**(full iteration).

#### SCAN 命令的保证(guarantees)

SCAN 命令, 以及其他增量式迭代命令, 在进行完整遍历的情况下可以为用户带来以下保证:  从完整遍历开始直到完整遍历结束期间, 一直存在于数据集内的所有元素都会被完整遍历返回;  这意味着, 如果有一个元素, 它从遍历开始直到遍历结束期间都存在于被遍历的数据集当中, 那么 SCAN 命令总会在某次迭代中将这个元素返回给用户.

然而因为增量式命令仅仅使用游标来记录迭代状态, 所以这些命令带有以下缺点: 

* 同一个元素可能会被返回多次. 处理重复元素的工作交由应用程序负责, 比如说, 可以考虑将迭代返回的元素仅仅用于可以安全地重复执行多次的操作上.
* 如果一个元素是在迭代过程中被添加到数据集的, 又或者是在迭代过程中从数据集中被删除的, 那么这个元素可能会被返回, 也可能不会, 这是未定义的(undefined).

#### SCAN 命令每次执行返回的元素数量

增量式迭代命令并不保证每次执行都返回某个给定数量的元素.

增量式命令甚至可能会返回零个元素, 但只要命令返回的游标不是 `0` , 应用程序就不应该将迭代视作结束.

不过命令返回的元素数量总是符合一定规则的, 在实际中: 

- 对于一个大数据集来说, 增量式迭代命令每次最多可能会返回数十个元素; 
- 而对于一个足够小的数据集来说, 如果这个数据集的底层表示为编码数据结构(encoded data structure, 适用于是小集合键, 小哈希键和小有序集合键), 那么增量迭代命令将在一次调用中返回数据集中的所有元素.

最后, 用户可以通过增量式迭代命令提供的 `COUNT` 选项来指定每次迭代返回元素的最大值.

#### COUNT 选项

虽然增量式迭代命令不保证每次迭代所返回的元素数量, 但我们可以使用 `COUNT` 选项, 对命令的行为进行一定程度上的调整.

基本上, `COUNT` 选项的作用就是让用户告知迭代命令, 在每次迭代中应该从数据集里返回多少元素.

虽然 `COUNT` 选项**只是对增量式迭代命令的一种提示**(hint), 但是在大多数情况下, 这种提示都是有效的.

- `COUNT` 参数的默认值为 `10` .
- 在迭代一个足够大的, 由哈希表实现的数据库, 集合键, 哈希键或者有序集合键时, 如果用户没有使用 `MATCH` 选项, 那么命令返回的元素数量通常和 `COUNT` 选项指定的一样, 或者比 `COUNT` 选项指定的数量稍多一些.
- 在迭代一个编码为整数集合(intset, 一个只由整数值构成的小集合),  或者编码为压缩列表(ziplist, 由不同值构成的一个小哈希或者一个小有序集合)时, 增量式迭代命令通常会无视 `COUNT` 选项指定的值, 在第一次迭代就将数据集包含的所有元素都返回给用户.

#### MATCH 选项

和 [*KEYS*](http://doc.redisfans.com/key/keys.html#keys) 命令一样, 增量式迭代命令也可以通过提供一个 glob 风格的模式参数, 让命令只返回和给定模式相匹配的元素, 这一点可以通过在执行增量式迭代命令时, 通过给定 `MATCH <pattern>` 参数来实现.

以下是一个使用 `MATCH` 选项进行迭代的示例:

```bash
127.0.0.1:6379> SCAN 0 match key* count 5
1) "26"
2) 1) "key13"
   2) "key3"
   3) "key4"
   4) "key11"
   5) "key12"
127.0.0.1:6379> SCAN 26 match key* count 5
1) "30"
2) 1) "key1"
   2) "key2"
127.0.0.1:6379> SCAN 30 match key* count 5
1) "3"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
127.0.0.1:6379> SCAN 3 match key* count 5
1) "0"
2) 1) "key14"
   2) "key5"
```

#### 并发执行多个迭代

在同一时间, 可以有任意多个客户端对同一数据集进行迭代, 客户端每次执行迭代都需要传入一个游标, 并在迭代执行之后获得一个新的游标, 而这个游标就包含了迭代的所有状态, 因此, 服务器无须为迭代记录任何状态.

#### 中途停止迭代

因为迭代的所有状态都保存在游标里面, 而服务器无须为迭代保存任何状态, 所以客户端可以在中途停止一个迭代, 而无须对服务器进行任何通知.

即使有任意数量的迭代在中途停止, 也不会产生任何问题.

#### 使用错误的游标进行增量式迭代

使用间断的(broken), 负数, 超出范围或者其他非正常的游标来执行增量式迭代并不会造成服务器崩溃, 但可能会让命令产生未定义的行为.

未定义行为指的是, 增量式命令对返回值所做的保证可能会不再为真.

只有两种游标是合法的: 

1. 在开始一个新的迭代时, 游标必须为 `0`.
2. 增量式迭代命令在执行之后返回的, 用于延续(continue)迭代过程的游标.

#### 迭代终结的保证

增量式迭代命令所使用的算法只保证在数据集的大小有界(bounded)的情况下, 迭代才会停止, 换句话说, 如果被迭代数据集的大小不断地增长的话, 增量式迭代命令可能永远也无法完成一次完整迭代.

从直觉上可以看出, 当一个数据集不断地变大时, 想要访问这个数据集中的所有元素就需要做越来越多的工作, 能否结束一个迭代取决于用户执行迭代的速度是否比数据集增长的速度更快.



### 字符串类型(String)

实际上 type=string 代表 value 存储的是一个普通字符串, 那么对应的 encoding 可以是 raw 或者是 int, 如果是 int 则代表实际 redis 内部是按数值型类存储和表示这个字符串的, 当然前提是这个字符串本身可以用数值表示, **比如"20"这样的字符串, 当遇到 incr, decr 等操作时会转成数值型进行计算, 此时 redisObject 的 encoding 字段为 int**.如果你试图对 name 进行 incr 操作则报错.

int: 8 个字节的长整型
embstr: 小于等于 39 个字节的字符串
raw: 大于 39 个字节的字符串
Redis 会根据当前值的类型和长度决定使用哪种内部编码实现

1. 整数类型示例如下: 
    set m 6666
    object encoding m
2. 短字符串示例如下: 
    #小于等于39个字节的字符串: embstr
    set m "hello"
    object encoding m
3. 长字符串示例如下: 
    #大于39个字节的字符串: raw
    set m "Redis is an open source (BSD licensed)..."
    object encoding m
    strlen m

**结构和命令**

value 的值可是字符串, 可以是数字, 可以是 0, 1 的二进制位, 上限是 512MB, 建议 100k 以内, 适用于缓存, 计数器, 分布式锁等等

| **命令** | **描述**                                                     | **用法**                                              | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ----------------------------------------------------- | :--------: |
| SET      | 1. 将字符串值 Value 关联到 Key<br/>2. Key 已关联则覆盖, 无视类型<br/>3. 原本 Key 带有生存时间 TTL, 那么 TTL 被清除 | set key value [EX seconds] [PX milliseconds] [NX\|XX] |    O(1)    |
| SETEX    | 1. 将 Value 关联到 Key<br/>2. 设置 Key 生存时间为 seconds, 单位为秒<br/>3. 如果 Key 对应的 Value 已经存在, 则覆盖旧值<br/>4. SET 同时也可以设置失效时间, 是一个原子操作, 即关联值与设置生存时间同一时间完成 | set key value ex seconds                              |    O(1)    |
| SETNX    | 1. 将 Key 的值设置为Value, **当且仅当 Key 不存在**<br/>2. 若给定的 Key 已经存在 SEXNX 不做任何动作 | set key value nx                                      |    O(1)    |
| setxx    | 1. 将 Key 的值设置为 Value, **当且仅当 Key 存在**<br/>2. 若给定的 Key 不存在 SEXXX 不做任何动作 | set key value xx                                      |    O(1)    |
| GET      | 1. 返回 key 关联的字符串值<br/>2. Key 不存在返回 nil<br/>3. Key 存储的不是字符串, 返回错误, 因为 GET 只用于处理字符串 | GET key                                               |    O(1)    |
| MSET     | 1. 同时设置一个或多个 Key-Value 键值对<br/>2. 某个给定 Key 已经存在, 那么 MSET 新值会覆盖旧值<br/>3. 如果上面的覆盖不是希望的, 那么使用 MSETNX 命令, **所有 Key 都不存在才会进行覆盖**<br/>4.**MSET 是一个原子性操作**, 所有 Key 都会在同一时间被设置, 不会存在有些更新有些没更新的情况 | MSET key1 value1 [key1 value1 ...]                    |    O(n)    |
| MGET     | 1. 返回一个或多个给定 Key 对应的 Value<br/>2. 某个 Key 不存在那么这个 Key 返回 nil | MGET key1 [key2 ...]                                  |    O(n)    |
| INCR     | 1. Key 中存储的数字值 +1, 返回增加之后的值<br/>2. Key 不存在, 那么 Key 的值被初始化为 0 再执行 INCR<br/>3. 如果值包含错误类型或者字符串不能被表示为数字, 那么返回错误<br/>4. 值限制在64位有符号数字表示之内, 即-9223372036854775808~9223372036854775807 | INCR key                                              |    O(1)    |
| DECR     | 1. Key 中存储的数字值 -1<br/>2. 其余同 INCR                  | DECR key                                              |    O(1)    |
| INCRBY   | 1. 将 key 所存储的值加上增量返回增加之后的值<br/>2. 其余同 INCR | INCRBY key increment                                  |    O(1)    |
| DECRBY   | 1. 将 key 所存储的值减去减量 decrement<br/>2. 其余同 INCR    | DECRBY key decrement                                  |    O(1)    |
| APPEND   | 1. 给指定 key 的 value 追加字符串, 并返回新字符串的长度      | append key value                                      |    O(1)    |
| GETSET   | 1. 设置 key 的值, 并返回 key 旧的值                          | getset key newvalue                                   |    O(1)    |
| STRLEN   | 1. 取指定 key 的 value 的长度(注意中文)                      | strlen key                                            |    O(1)    |
| KEEPTTL  | 保留生存时间                                                 | set k1 v1 keepttl                                     |            |

**快速实战**

记录网站每个用户个人主页的访问量

```bash
incr userid:pageview(单线程,  无竞争)
```

缓存视频的基本信息(数据源在 MySQL 中), 伪代码

```java
public VideoInfo get(long id) {
    String redisKey = redisPrefix + id;
    VideoInfo videInfo = redis.get(redisKey);
    if (videoInfo == null) {
        videoInfo = mysql.get(id);
        if (videoInfo != null) {
            // 序列化
            redis.set(redisKey, serialize(videoInfo));
        }
    }
    return videoInfo;
}
```

分布式 id 生成器, 不同的应用获取一个自增的 id, 因为 redis 单线程的, 所以不同的服务肯定获得不同的值

```bash
incr counter
```

### 哈希类型, 可以对 key 进行分类(Hash)

**结构和命令**

Hash 是一个 String 类型的 field 和 value 之间的映射表, 即 redis 的 Hash 数据类型的 key(hash 表名称)对应的 value 实际的内部存储结构为一个 HashMap, 因此 Hash 特别适合存储对象. 相对于把一个对象的每个属性存储为 String 类型, 将整个对象存储在 Hash 类型中会占用更少内存.

当前 HashMap 的实现有两种方式: 当 HashMap 的成员比较少时 Redis 为了节省内存会采用类似一维数组的方式来紧凑存储, 而不会采用真正的 HashMap 结构, 这时对应的 value 的 redisObject 的 encoding 为 ziplist, 当成员数量增大时会自动转成真正的 HashMap, 此时 encoding 为 hashtable.

ziplist(压缩列表): 当哈希类型元素个数小于 hash-max-ziplist-entries 配置(默认512个)、同时所有值都小于 hash-max-ziplist-value 配置(默认64字节)时,redis会使用ziplist作为哈希的内部实现, ziplist 使用更加紧凑的结构实现多个元素的连续存储,所以在节省内存方面比hashtable更加优秀。
hashtable(哈希表): 当哈希类型无法满足 ziplist 的条件时, redis 会使用 hashtable 作为哈希的内部实现, 因此此时 ziplist 的读写效率会下降, 而 hashtable 的读写时间复杂度为O(1)

1. 当 field 个数比较少且没有大的 value 时,内部编码为 ziplist
    hmset m f1 v1 f2 v2
    object encoding m
2. 当有 value 大于 64 字节,内部编码会由 ziplist 变为 hashtable:
     hset m f3 "Redis is an open source (BSD licensed), in-memory data structure store, used as a database..."
     object encoding m
3. 当 field 个数超过 512,内部编码也会由 ziplist 变为 hashtable:
    hmset m f1 .....f513
    object encoding m

用一个对象来存储用户信息, 商品信息, 订单信息等等.

<img src="https://miaomiaoqi.github.io/images/redis/redis_2.png" alt="https://miaomiaoqi.github.io/images/redis/redis_2.png" style="zoom:50%;" />

| **命令** | **描述**                                                     | **用法**                                    | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ------------------------------------------- | ---------- |
| HSET     | 1. 将哈希表 Key 中的域 field 的值设为 value<br/>2. key 不存在, 一个新的 Hash 表被创建<br/>3. field 已经存在, 旧的值被覆盖 | HSET key field value                        | O(1)       |
| HSETNX   | 1. 设置 key 对应的 HashMap 中的 field 的 value, 如果 field 已经存在, 则失败 | hsetnx key field value                      | O(1)       |
| HGET     | 1. 返回哈希表 key 中给定域 field 的值                        | HGET key field                              | O(1)       |
| HDEL     | 1. 删除哈希表 key 中的一个或多个指定域<br/>2. 不存在的域将被忽略 | HDEL key filed1 [field2 ...]                | O(1)       |
| HEXISTS  | 1. 查看哈希表 key 中, 给定 field 是否存在, 存在返回 1, 不存在返回 0 | HEXISTS key field                           | O(1)       |
| HGETALL  | 1. 返回哈希表 key 中, 所有的域和值                           | HGETALL key                                 | O(n)       |
| HINCRBY  | 1. 为哈希表 key 中的域 field 加上增量 increment<br/>2. 其余同 INCR 命令 | HINCRYBY key filed increment                | O(1)       |
| HLEN     | 1. 返回哈希表 key 中 field 的数量                            | HLEN key                                    | O(1)       |
| HMGET    | 1. 返回哈希表 key 中, 一个或多个给定域的值<br/>2. 如果给定的域不存在于哈希表, 那么返回一个 nil 值 | HMGET key field1 [field2 ...]               | O(n)       |
| HMSET    | 1. 同时将多个 field-value 对设置到哈希表 key 中<br/>2. 会覆盖哈希表中已存在的域<br/>3. key 不存在, 那么一个空哈希表会被创建并执行 HMSET 操作 | HMSET key field1 value1 [field2 value2 ...] | O(n)       |
| HKEYS    | 1. 返回哈希表 key 中的所有域                                 | HKEYS key                                   | O(n)       |
| HVALS    | 1. 返回哈希表 key 中所有的值                                 | HVALS key                                   | O(n)       |

**快速实战**

记录网站每个用户个人主页的访问量, 每次自增 1

```
hincrby user:1:info pageview 1
```

缓存视频的基本信息(数据源在 mysql 中)伪代码

```java
public VideoInfo get(long id) {
    String redisKey = redisPrefix + id;
    Map<String, String> hashMap = redis.hgetAll(redisKey);
    VideoInfo videoInfo = transferMapToVideo(hashMap);
    if (videoInfo == null) {
        videoInfo = mysql.get(id);
        if (videoInfo != null) {
            redis.hmset(redisKey, transferVideoToMap(videoInfo));
        }
    }
}
```



### 列表类型, 元素有序可重复(List)

Redis 的 List 类型其实就是每一个元素都是 String 类型的**双向链表**.我们可以从链表的头部和尾部添加或者删除元素.这样的 List 既可以作为栈, 也可以作为队列使用.

ziplist(压缩列表):当列表的元素个数小于 list-max-ziplist-entries 配置(512个),同时列表中每个元素的值都小于 list-max-ziplist-value 配置(64个),redis 会选用ziplist 来作为列表的内部实现来减少内存的使用.
linkedlist(链表):当列表类型无法满足 ziplist 的条件时,redis 会使用 linkedlist 作为列表的内部实现。

1. 当元素个数较少且没有大元素时,内部编码为 ziplist: 
    rpush m a1 a2 a3
    object encoding m
2. 当元素个数超过 512 个,内部编码变为 linkedlist:
    rpush m a1...a513
    object encoding m
3. 或者当某个元素超过64 字节,内部编码也会变为linkedlist:
    rpush m "Redis is an open source (BSD licensed), in-memory data structure store, used as a database..."
    object encoding m

注: Redis3.2 版本提供了 quicklist 内部编码, 简单地说它是以一个 ziplist 为节点的 linkedlist, 它结合了 ziplist 和 linkedlist 两者的优势, 为列表类型提供了一种更为优秀的内部编码实现, 它的设计原理可以参考 Redis 的另一个作者 Matt Stancliff 的博客: https://matt.sh/redis-quicklist。

如好友列表, 粉丝列表, 消息队列, 最新消息排行等.另外还有一个就是, 可以利用lrange命令, 做**基于 redis 的分页功能**, 性能极佳, 用户体验好.

<img src="https://miaomiaoqi.github.io/images/redis/redis_3.png" alt="https://miaomiaoqi.github.io/images/redis/redis_3.png" style="zoom:67%;" />

**结构和命令**

| **命令**  | **描述**                                                     | **用法**                              | 时间复杂度 |
| --------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| LPUSH     | 1. 将一个或多个值 value 插入到列表 key 的表头<br/>2. 如果有多个 value 值, 那么各个 value 值按从左到右的顺序依次插入表头<br/>3. key 不存在, 一个空列表会被创建并执行 LPUSH 操作<br/>4. key 存在但不是列表类型, 返回错误 | LPUSH key value1 [value2 ...]         | O(1~n)     |
| LPUSHX    | 1. 将值 value 插入到列表 key 的表头, 当且 key 存在且为一个列表<br/>2. key 不存在时, LPUSHX 命令什么都不做 | LPUSHX key value1 [value2...]         | O(1~n)     |
| LPOP      | 1. 移除并返回列表 key 的头元素                               | LPOP key                              | O(1)       |
| LRANGE    | 1. 返回列表 key 中指定区间内的元素, 区间以偏移量start和end指定<br/>2. start 和 end 都以 0 为底<br/>3. 可使用负数下标, -1 表示列表最后一个元素, -2 表示列表倒数第二个元素, 以此类推<br/>4. start 大于列表最大下标, 返回空列表<br/>5. stop 大于列表最大下标, stop = 列表最大下标 | LRANGE key start end(包含 end)        | O(n)       |
| LREM      | 1. 根据 count 的值, 移除列表中与 value 相等的元素<br/>2. count > 0 表示从头到尾搜索, 移除与 value 相等的元素, 数量为 count<br/>3. count < 0 表示从从尾到头搜索, 移除与 value 相等的元素, 数量为 count<br/>4. count = 0 表示移除表中所有与 value 相等的元素 | LREM key count value                  | O(n)       |
| LSET      | 1. 将列表 key 下标为 index 的元素值设为 value<br/>2. index 参数超出范围, 或对一个空列表进行 LSET 时, 返回错误 | LSET key index value                  | O(n)       |
| LINDEX    | 1. 返回列表 key 中, 下标为 index 的元素                      | LINDEX key index                      | O(n)       |
| LINSERT   | 1. 将值 value 插入列表 key 中, 位于 pivot 前面或者后面插入 value 元素<br/>2. pivot 不存在于列表 key 时, 不执行任何操作<br/>3. key 不存在, 不执行任何操作 | LINSERT key BEFORE\|AFTER pivot value | O(n)       |
| LLEN      | 1. 返回列表 key 的长度<br/>2. key 不存在, 返回 0             | LLEN key                              | O(1)       |
| LTRIM     | 1. 对一个列表进行修剪, 让列表只返回指定区间内的元素, **不存在指定区间内的都将被移除** | LTRIM key start end                   | O(n)       |
| RPOP      | 1. 移除并返回列表 key 的尾元素                               | RPOP key                              | O(1)       |
| RPOPLPUSH | 在一个原子时间内, 执行两个动作: <br/>1. 将列表 source 中最后一个元素弹出并返回给客户端<br/>2. 将 source 弹出的元素插入到列表 desination, 作为 destination 列表的头元素 | RPOPLPUSH source destination          |            |
| RPUSH     | 1. 将一个或多个值 value 插入到列表 key 的表尾                | RPUSH key value1 [value2 ...]         | O(1~n)     |
| RPUSHX    | 1. 将 value 插入到列表 key 的表尾, 当且仅当 key 存在并且是一个列表<br/>2. key 不存在, RPUSHX 什么都不做 | RPUSHX key value                      |            |

**快速实战**

根据时间轴展示微博内容, 当有用户更新微博时, 将用户的 id 使用 rpush 存入 list 中, 每次 lrange 获取 id, 并根据 id 找到对应的微博内容

### 集合类型, 元素是无序的, 元素不能重复. 并集, 交集, 差集(Set)

因为set堆放的是一堆不重复值的集合.所以可以做**全局去重**的功能.为什么不用JVM自带的Set进行去重? 因为我们的系统一般都是集群部署, 使用JVM自带的Set, 比较麻烦, 难道为了一个做一个全局去重, 再起一个公共服务, 太麻烦了.
另外, 就是利用交集, 并集, 差集等操作, 可以计算**共同喜好, 全部的喜好, 自己独有的喜好等功能**

Redis 集合(Set类型)是一个无序的 String 类型数据的集合, 类似 List 的一个列表, 与 List 不同的是 Set 不能有重复的数据.实际上, Set 的内部是用 HashMap 实现的, Set 只用了 HashMap 的 key 列来存储对象

intset(整数集合): 当集合中的元素都是整数且元素个数小于 set-max-ziplist-entries 配置(512)时, redis 会选用 intset 来作为集合的内部实现, 从而减少内存的使用
hashtable(哈希表): 当集合类型无法满足 intset 的条件时, redis 会使用 hashtable 作为集合的内部实现

1. 当元素个数较少且都为整数时, 内部编码为 intset
sadd m 1 2 3 4
object encoding m
2. 当元素的个数超过 512 个, 内部编码变为 hashtable
    sadd m 1...513
    scard setkey
    object encoding m
3. 当某个元素不为整数时, 内部编码也会变为 hashtable
    sadd m a
    object encoding m


**集合有取交集, 并集, 差集等操作, 因此可以求共同好友, 共同兴趣, 分类标签等**

**结构和命令**

| **命令**    | **描述**                                                     | **用法**                              | 时间复杂度 |
| ----------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| SADD        | 1. 将一个或多个 member 元素加入到 key 中, 已存在在集合的 member 将被忽略<br/>2. 假如 key 不存在, 则只创建一个只包含 member 元素做成员的集合<br/>3. 当 key 不是集合类型时, 将返回一个错误 | SADD key member1 [member2 ...]        | O(1)       |
| SCARD       | 1. 返回 key 对应的集合中的元素数量                           | SCARD key                             | O(1)       |
| SDIFF       | 1. 返回一个集合的全部成员, 该集合是第一个 Key 对应的集合和后面 key 对应的集合的差集 | SDIFF key [key ...]                   |            |
| SDIFFSTORE  | 1. 和 SDIFF 类似, 但结果保存到 destination 集合而不是简单返回结果集<br/>2.  destination 如果已存在, 则覆盖 | SDIFFSTORE destionation key [key ...] |            |
| SINTER      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的交集<br/>2. 不存在的key被视为空集 | SINTER key [key ...]                  |            |
| SINTERSTORE | 1. 和 SINTER 类似, 但结果保存早 destination 集合而不是简单返回结果集<br/>2. 如果 destination 已存在, 则覆盖<br/>3. destination 可以是 key 本身 | SINTERSTORE destination key [key ...] |            |
| SUNION      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的并集<br/>2. 不存在的 key 被视为空集 | SUNION key [key ...]                  |            |
| SUNIONSTORE | 1. 类似 SUNION, 但结果保存到 destination 集合而不是简单返回结果集<br/>2. destination 已存在, 覆盖旧值<br/>3. destination 可以是key本身 | SUNION destination key [key ...]      |            |
| SISMEMBER   | 1. 判断 member 元素是否 key 的成员, 0 表示不是, 1 表示是     | SISMEMBER key member                  |            |
| SMEMBERS    | 1. 返回集合 key 中的所有成员<br/>2. 不存在的 key 被视为空集  | SMEMBERS key                          |            |
| SMOVE       | 1. 原子性地将 member 元素从 source 集合移动到 destination 集合<br/>2. source 集合中不包含 membe r元素, SMOVE 命令不执行任何操作, 仅返回 0<br/>3. destination 中已包含 member 元素, SMOVE 命令只是简单做 source 集合的 member 元素移除 | SMOVE source desination member        |            |
| SPOP        | 1.**移除**并返回集合中的一个随机元素, 如果 count 不指定那么随机返回一个随机元素<br/>2. count 为正数且小于集合元素数量, 那么返回一个 count 个元素的数组且数组中的**元素各不相同**<br/>3. count 为正数且大于等于集合元素数量, 那么返回整个集合<br/>4. count 为负数那么命令返回一个数组, 数组中的**元素可能重复多次**, 数量为 count 的绝对值 | SPOP key [count]                      |            |
| SRANDMEMBER | 1. 如果 count 不指定, 那么返回集合中的一个随机元素<br/>2. count 同上<br />3. 不会破坏集合元素 | SRANDMEMBER key [count]               |            |
| SREM        | 1. 移除集合 key 中的一个或多个 member 元素, 不存在的 member 将被忽略 | SREM key member1 [member2 ...]        | O(1)       |

**快速实战**

打标签(tag), 可以方便查看标签下的用户, 也可以做交集并集查看共同标签

```bash
sadd user:1:tags tag1 tag2 tag5
sadd user:2:tags tag2 tag3 tag5
...
sadd user:k:tags tar1 tag2 tar4

sadd tag1:users user1 user3
sadd tag2:users user1 user2 user3
...
sadd tagk:users user1 user2
```



### 有序集合类型, 有序的 set, 元素不能重复但有序(SortedSet)

SortSet 顾名思义, 是一个排好序的 Set, 它在 Set 的基础上增加了一个顺序属性 score, 这个属性在添加修改元素时可以指定, 每次指定后, SortSet 会自动重新按新的值排序.

SortSet 的内部使用 HashMap 和跳跃表(SkipList)来保证数据的存储和有序, HashMap 里放的是成员到 score 的映射, 而跳跃表里存放的是所有的成员, 排序依据是 HashMap 里存的 score. 

ziplist(压缩列表): 当有序集合的元素个数小于 zset-max-ziplist-entries 配置(默认128个),同时每个元素的值都小于 zset-max-ziplist-value 配置(64个)时,
redis 会用 ziplist 来作为有序集合的内部实现, ziplist 可以有效的减少内存的使用.
skiplist(跳跃表): 当 ziplist 条件不满足时,有序集合会使用 skiplist 作为内部的实现, 因为此时 ziplist 的读写效率会下降.

1. 当元素个数较少且每个元素较小时,内部编码为 skiplist
    zadd m 50 a1 60 a2 30 a3
    object encoding m

2. 当元素个数超过128个, 内部编码变为 ziplist
    zadd m 50 a1 60 a2 84 a129
    object encoding m

3. 当某个元素大于64字节时,内部编码也会变为 hashtable
    zadd m  20 "Redis is an open source (BSD licensed), in-memory data structure store, used as a database..."
    object encoding m 

**可以做排行榜应用, 取 TOP N 操作.可以用来做延时任务.最后一个应用就是可以做范围查找.**

**结构和命令**

| **命令**         | **描述**                                                     | **用法**                                                     | 时间复杂度  |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| ZADD             | 1. 将一个或多个 member 元素及其 score 值加入有序集 key 中<br/>2. 如果 member 已经是有序集的成员, 那么更新 member 对应的 score 并重新插入 member 保证 member 在正确的位置上<br/>3. score 可以是整数值或双精度浮点数 | ZADD key score1 member1 [[score2 member2] [score3 member3] ...] | O(logN)     |
| ZCARD            | 1. 返回有序集 key 的元素个数                                 | ZCARD key                                                    | O(1)        |
| ZCOUNT           | 1. 返回有序集 key 中, score 值 >= minScore 且 <= maxScore 的成员的数量 | ZCOUNT key minScore maxScore                                 | O(logN + m) |
| ZSCORE           | 1. 返回元素的分数                                            | ZSCORE key member                                            | O(1)        |
| ZRANGE           | 1. 返回有序集 key 中指定区间内的成员, 成员位置按 score 从小到大排序<br/>2. 具有相同 score 值的成员按字典序排列<br/>3. 需要成员按 score 从大到小排列, 使用 ZREVRANGE 命令<br/>4. 下标参数 start 和 end 都以 0 为底, 也可以用负数, -1 表示最后一个成员, -2 表示倒数第二个成员<br/>5. 可通过 WITHSCORES 选项让成员和它的 score 值一并返回 | ZRANGE key start end [WITHSCORES]                            | O(logN + m) |
| ZREVRANGE        | 1. 返回有序集 key 中, 指定区间内的成员.其中成员的位置按 score 值递减(从大到小)来排列 | ZREVRANGE key start end                                      | O(logN + m) |
| ZRANGEBYSCORE    | 1. 返回有序集 key 中, 指定分数范围的元素列表                 | ZRANGEBYSCORE key minScore maxScore [WITHSCORES]             | O(logN + m) |
| ZRANK            | 1. 返回有序集 key 中成员 member 的排名, 有序集成员按 score 值从小到大排列<br/>2. 排名以 0 为底, 即 score 最小的成员排名为 0<br/>3. ZREVRANK 命令可将成员按 score 值从大到小排名 | ZRANK key member                                             |             |
| ZREVRANK         | 1. 得成员按 score 值递减(从大到小)排列的排名                 |                                                              |             |
| ZREM             | 1. 移除有序集 key 中的一个或多个成员, 不存在的成员将被忽略<br/>2. 当 key 存在但不是有序集时, 返回错误 | ZREM key member1 [member2 ...]                               |             |
| ZREMRANGEBYRANK  | 1. 移除有序集 key 中指定排名区间内的所有成员                 | ZREMRANGEBYRANK key start end                                | O(logN + m) |
| ZREMRANGEBYSCORE | 1. 移除有序集 key 中, 所有 score 值 >= minScore 且 <=maxScore 之间的成员 | ZREMRANGEBYSCORE key minScore maxScore                       | O(logN + m) |
| ZINCRBY          | 1. 如果 key 对应的 zset 中已经存在元素 member, 则对 member 的score 属性加指定的值 | ZINCRBY key score member                                     | O(1)        |



### 位图 Bitmap

Redis 可以直接操作数据的位数据, 由 0 和 1 状态表现的二进制位的 bit 数组

| **命令**                    | **描述**                                            | **用法**           |
| --------------------------- | --------------------------------------------------- | ------------------ |
| setbit key offset val       | 给指定 key 的第 offset 位赋值 val                   | setbit k1 1 1      |
| getbit key offset           | 获取指定 key 的第 offset 位                         | getbit k1 1        |
| strlen                      | 统计字节数占用了多少字节,超过 8 位按 1 个字节算     | strlen k1          |
| bitcount key []start end]   | 返回指定 key 中 [start,end] 中为 1 的数量           | bitcount k1        |
| bitop operation destkey key | 对不同的二进制存储数据进行位运算(AND, OR, NOT, XOR) | bitop and k3 k2 k1 |

连续签到

### 位域 Bitfield

### 基数统计 HyperLogLog



### 地理空间 GEO(Geospatial)

### 流 Stream

redis 版本的 mq 中间件



## Jedis 客户端

Jedis 是基于 Java 语言的 Redis 客户端

### Jedis 直连

生成一个 Jedis 对象, 这个对象负责和指定 Redis 节点通信

```java
Jedis jedis = new Jedis("127.0.0.1",  6379);
```

jedis 执行 set 操作

```java
jedis.set("hello",  "world");
```

jedis 执行 get 操作, value="world"

```java
String value = jedis.get("hello");
```

Jedis(String host, int port, int connectionTimeout, int soTimeout) 构造函数参数意义

host: Redis 节点的所在机器的 ip

port: Redis 节点的端口

connectionTimeout: 客户端连接超时

soTimeout: 客户端读写超时

### Jedis 连接池配置

初始化 Jedis 连接池, 通常来讲 JedisPool 是单例的

```java
GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
JedisPool jedisPool = new JedisPool(poolConfig, "127.0.0.1", 6379);
```

**资源数配置**

| 参数名     | 含义                          | 默认值 | 使用建议 |
| ---------- | ----------------------------- | ------ | -------- |
| maxTotal   | 资源池最大连接数              | 8      |          |
| maxIdle    | 资源池允许最大空闲连接数      | 8      |          |
| minIdle    | 资源池确保最少空闲连接数      | 0      |          |
| jmxEnabled | 是否开启 jmx 监控, 可用于监控 | true   | 建议开启 |

* maxTotal

    这是一个比较难确定的参数值, 举个例子

    1. 命令平均执行时间 0.1ms = 0.001s
    2. 业务需要 50000QPS
    3. maxTotal 理论值 = 0.001 * 50000 = 50 个, 实际要偏大一些

    **业务希望 Redis 并发量**

    **客户端执行命令时间**

    **Redis 资源: 例如 nodes(应用个数) * maxTotal 是不能超过 redis 的最大连接数(config get maxclients)**

    **资源开销, 例如虽然希望控制空闲连接, 但是不希望因为连接池的频繁释放创建连接造成不必要开销**

* 适合的 maxIdle 和 minIdle

    建议 maxIdle = maxTotal, 假如 maxTotal 是 100, maxIdle 是 50, 当有第 51 个连接时, 就会使用 new Jedis 创建新的连接, 这个过程也是耗费资源的

    建议预热 minIdle, 减少第一次启动后的新连接开销



**借还参数**

| 参数名             | 含义                                                         | 默认值           | 使用建议         |
| ------------------ | ------------------------------------------------------------ | ---------------- | ---------------- |
| blockWhenExhausted | 当资源池用尽后, 调用者是否要等待. 只有当为 true 时, 下面的 maxWaitMillis 才会生效 | true             | 建议使用默认值   |
| maxWaitMillis      | 当资源池连接用尽后, 调用者的最大等待时间(单位为毫秒)         | -1: 表示永不超时 | 不建议使用默认值 |
| testOnBorrow       | 向资源池借用连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |
| testOnReturn       | 向资源池归还连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |



## 瑞士军刀 Redis

### 慢查询

#### 生命周期

1. 客户端发送命令
2. 排队
3. 执行命令
4. 返回结果

慢查询一般发生在第 3 阶段

客户端超时不一定慢查询, 但慢查询是客户端超时的一个因素

#### 两个配置

**慢查询是一个先进先出的队列, 队列是固定长度的, 满了之后会出队一个元素, 保存在内存中, 不会持久化**

**slowlog-max-len:** 设置队列长度

**slowlog-log-slower-than:** 慢查询阈值(单位: 微妙), 该值等于 0 记录所有命令, 小于 0 不记录任何命令, 1毫秒等于 1000 微妙

#### 配置方法

1.**默认值**

    config get slowlog-max-len=128
    
    config get slowlog-log-slower-than=10000

2. 修改配置文件重启(不推荐)

3. 动态配置

    config set slowlog-max-len 1000

    config set slowlog-log-slower-than 1000

#### 三个命令

slowlog get [n]: 获取 n 条慢查询队列

slowlog len: 获取慢查询队列长度

slowlog reset: 清空慢查询队列

#### 运维经验

slowlog-max-len 不要设置过小, 通常设置 1000 左右

slowlog-log-slower-than 不要设置过大, 默认 10ms, 通常设置 1ms = 1000 微秒, 根据业务 qps 来决定

理解命令生命周期, 更容易定位慢在哪里

定期持久化慢查询

### 管道 (pipeline)

如果我们发送 n 条命令, 那么就是 n 次网络时间 + n 次命令时间, 如果使用流水线(pipeline), 会将 n 条命令打包发送给服务端, 服务端会将 n 条结果一次返回, 消耗是 1 次网络时间 + n 次命令时间, 这就是流水线的作用, 减少网络开销

| 命令   | N 个命令操作        | 1 次 pipeline(N 个命令) |
| ------ | ------------------- | ----------------------- |
| 时间   | n 次网络 + n 次命令 | 1 次网络 + n 次命令     |
| 数据量 | 1 条命令            | n 条命令                |

#### 使用 JedisPipeline

没有 pipeline 设置 10000 个 key, 1W hset 花费 50s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for (int i = 0; i < 10000; i++) {
    jedis.hset("hashKey" + i, "field" + i, "value" + i);
}
```

**使用 pipeline 操作**, 拆分 10000 条命令, 执行 100 次, 每次执行 100 条命令, 花费 0.7s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for (int i = 0; i < 10000; i++) {
    Pipeline pipeline = jedis.pipelined();
    for (int j = i * 100; j < (i + 1) * 100; j++) {
        pipeline.hset("hashKey" + j, "field" + j, "value" + j);
    }
    pipeline.syncAndReturnAll();
}
```

#### 使用建议

注意每次 pipeline 携带数据量

pipeline 每次只能作用在一个 Redis 节点上

**注意原子性问题, 与 M 命令相比, pipeline 会将命令拆分执行, 不是原子的, 而 M 命令是原子的**



### 发布订阅



### Redis 事务

可以一次执行多个命令, 本质是一组命令的集合, 一个事务中的所有命令都会被序列化, 按顺序的串行化执行而不会被其他命令插入, 不许加塞, 一个队列中, 一次性, 顺序性, 排他性的执行一系列命令

| 1 单独的隔离操作     | Redis的事务仅仅是保证事务里的操作会被连续独占的执行，redis命令执行是单线程架构，在执行完事务内所有指令前是不可能再去同时执行其他客户端的请求的 |
| -------------------- | ------------------------------------------------------------ |
| 2 没有隔离级别的概念 | 因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这种问题了 |
| 3不保证原子性        | Redis的事务不保证原子性，也就是不保证所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，没有执行到一半进行回滚的能力 |
| 4 排它性             | Redis会保证一个事务内的命令依次执行，而不会被其它命令插入    |



1 开启：以MULTI开始一个事务

2 入队：将多个命令入队到事务中，接到这些命令并不会立即执行， 而是放到等待执行的事务队列里面

3 执行：由EXEC命令触发事务





## Redis 常见应用

### 使用 Redis 实现分布式锁

和 Memcached 的方式类似, 利用 Redis 的 setnx 命令.此命令同样是原子性操作, 只有在 key 不存在的情况下, 才能 set 成功.(setnx 命令并不完善, 后续会介绍替代方案)

1. 加锁

    最简单的方法是使用 setnx 命令, key 是锁的唯一标识, 按业务来决定命名.比如想要给一种商品的秒杀活动加锁, 可以给 key 命名为 “lock_sale_商品ID”, 而 value 设置成什么呢? 我们可以姑且设置成 1.加锁的伪代码如下:     

    ```shell
    setnx(key, 1)
    ```

    当一个线程执行 setnx 返回 1, 说明 key 原本不存在, 该线程成功得到了锁; 当一个线程执行 setnx 返回 0, 说明 key 已经存在, 该线程抢锁失败.

2. 解锁

    有加锁就得有解锁. 当得到锁的线程执行完任务, 需要释放锁, 以便其他线程可以进入.释放锁的最简单方式是执行 del 指令, 伪代码如下: 

        del(key)

    释放锁之后, 其他线程就可以继续执行setnx命令来获得锁

3. 锁超时

    锁超时是什么意思呢? 如果一个得到锁的线程在执行任务的过程中挂掉, 来不及显式地释放锁, 这块资源将会永远被锁住, 别的线程再也别想进来.所以, setnx的key必须设置一个超时时间, 以保证即使没有被显式释放, 这把锁也要在一定时间后自动释放.setnx不支持超时参数, 所以需要额外的指令, 伪代码如下: 

        expire(key, 30)

    综合起来, 我们分布式锁实现的第一版伪代码如下: 

    ```java
    if(setnx(key,  1) == 1){
        expire(key,  30)
        try {
            do something ......
        } finally {
            del(key)
        }
    }
    ```

4. 第一版存在的问题

    *   setnx 和 expire 的非原子性, 当 A 线程得到了锁, 还未来得及设置超时时间就挂掉了, 会导致锁没有超时时间, 在Redis2.6.12 以上版本增加了 set(key, 1, 30, NX) 取代了 setnx

    *   del 导致误删, 假如 A 线程得到了锁, 并且设置 30 秒超时, 如果某些原因导致了 A 超过了 30 秒, 自动释放锁, B 线程获得了锁, 当 A 运行完成后, 删除了锁, 直接删除的是 B 线程的锁, 可以再 del 之前判断一下这个锁是不是自己的, 即将 value 设置成线程 id, 每次删除前判断一下是不是自己的锁, 这样实际上有并发问题

    *   还是刚才第二点所描述的场景, 虽然我们避免了线程 A 误删掉 key 的情况, 但是同一时间有 A, B 两个线程在访问代码块, 仍然是不完美的.怎么办呢? 我们可以让获得锁的线程开启一个守护线程, 用来给快要过期的锁“续航”.这样就避免了 A 线程执行时间过长, 导致锁自动释放的问题, 假设锁是 30 秒, 让守护线程 29 秒时给锁续命 20 秒, 当 A 线程销毁时, 守护线程也就销毁了 

### 基于 Redis 的分布式布隆过滤器

#### 引出布隆过滤器

现有 50 亿个电话号码, 现有 10 万个电话号码, 要**快速准备**判断这些电话号码是否已经存在

1. 通过数据库查询: 实现**快速**有点难
2. 数据预放在集合中: 50 亿 * 8 字节 ~ 40GB(内存浪费或不够)
3. hyperloglog:**准确**有点难

类似的还有垃圾邮件过滤, 文字处理软件的错误单词检测, 网络爬虫重复 url 检测, Hbase行过滤

#### 布隆过滤器原理

1970年伯顿.布隆提出, 用很小的空间解决上述问题

实现原理: 一个很长的二进制向量和若干个哈希函数

参数: m 个二进制向量, n 个预备数据, k 个 hash 函数

构建布隆过滤器: n 个预备数据走一遍上面过程

判断元素存在: 走一边上面过程: 如果都是 1, 则表明存在, 反之不存在

#### 布隆过滤器的误差率

肯定存在误差: 恰好都命中了

直观因素: m/n 的比率, hash 函数的个数

#### 本地布隆过滤器

现有库: Guava

本地布隆过滤器的问题

1. 容量受限制
2. 多个应用存在多个布隆过滤器, 多个布隆过滤器之间的同步问题

#### Redis 单机布隆过滤器

基于 Redis 的位图实现

定义布隆过滤器构造函数: m, n, k, 误差概率

定义布隆过滤器操作函数: add 和 contain

封装 Redis 位图操作

开发测试样例

#### Redis 分布式布隆过滤器

多个布隆过滤器: 二次路由, 解决容量受限的问题



## Redis 开发规范

### Key 设计

可读性和可管理型: 以业务名(或数据库名)为前缀(防止 key 冲突), 用冒号分割, 比如业务名:表名:id, 如 ugc:video:1

简洁性: 保证语义的前提下, 控制 key 的长度, 当 key 较多时, 内存占用也不容忽略, 如 `user:{uid}:friends:messages:{mid}` 简化为 `u:{uid}:fr:m:{mid}`

**不要包含特殊字符: 反例, 包含空格, 换行, 单双引号以及其他转义字符**

**Redis3 embstr 测试**

| key-value 个数 | 39 字节 | 40 字节 |
| -------------- | ------- | ------- |
| 10 万          | 15.69M  | 18.75M  |
| 100 万         | 146.29M | 176.81M |
| 1000 万        | 1.47G   | 1.77G   |
| 1 亿           | 14.6G   | 17.7G   |

### Value 设计

#### 拒绝 bigkey

string 类型控制在 10KB 以内, 10240 个英文, 3413 个中文

hash, list, set, zset 元素个数不要超过 5000

redis-cli \-\-bigkeys 查看 bigkey

#### 选择合适的数据结构

实体类型(要合理控制和使用数据结构内存编码优化配置, 例如ziplist, 但也要注意节省内存和性能之间的平衡)

#### 过期设计

控制 key 的生命周期, redis不是垃圾桶

object idle time 可以找到垃圾 key-value

过期时间不宜集中: 缓存穿透和雪崩等问题

### 命令使用技巧

O(N)以上命令关注 N 的数量: hgetall, lrange, smembers, zrang, sinter 等并非不能使用, 但是需要明确 N 的值. 有遍历的需求可以使用 hscan, sscan, zscan 代替

禁用命令: 线上禁用 keys, flushall, flushdb 等, 通过 redis 的 rename 机制禁掉命令, 或者使用 scan 的方式渐进式处理

合理使用 select: redis 的多数据库较弱, 使用数字进行区分, 很多客户端支持较差, 同时多业务用多数据库实际还是单线程处理

Redis 事务功能较弱, 不建议使用: Redis 的事务功能较弱, 不支持回滚 

Redis 集群版在使用 Lua 上有特殊要求

必要情况下使用 monitor 命令时, 要注意不要长时间使用



### Java 客户端优化

避免多个应用使用一个Redis实例: 不相干的业务拆分, 公共数据做服务化.

使用带有连接池的数据库, 可以有效控制连接, 同时提高效率

高并发下建议客户端添加熔断功能(例如netflix hystrix)

设置合理的密码, 如有必要可以使用SSL加密访问

根据自身业务类型, 选好 maxmemory-policy(最大内存淘汰策略), 设置好过期时间.

默认策略是 volatile-lru, 即超过最大内存后, 在过期键中使用 lru 算法进行 key 的剔除, 保证不过期数据不被删除, 但是可能会出现 OOM 问题.

### 连接池参数优化

#### 空闲连接参数

| 序号 | 参数名                        | 含义                                                         | 默认值               | 使用建议                                                     |
| ---- | ----------------------------- | ------------------------------------------------------------ | -------------------- | ------------------------------------------------------------ |
| 1    | testWhileIdle                 | 是否开启空闲资源监测                                         | false                | true                                                         |
| 2    | timeBetweenEvictionRunsMillis | 空闲资源的监测周期(单位为毫秒)                               | -1: 不检测           | 建议设置, 周期自行选择, 也可以默认也可以使用下面 JedisPoolConfig 中的配置 |
| 3    | minEvictableIdleTimeMillis    | 资源池中资源最小空闲时间(单位为毫秒), 达到此值后空闲资源将被移除 | 1000 60 30 = 30 分钟 | 可以根据自身业务决定, 大部分默认即可, 也可以考虑使用下面 JedisPoolConfig 中的配置 |
| 4    | numTestsPerEvicationRun       | 做空闲资源监测时, 每次的采样数                               | 3                    | 可以根据自身应用连接数进行微调, 如设置-1, 就是对所有连接做控线检测 |

#### 如何预估最大连接池

maxIdle 接近 maxTotal 即可

maxTotal 考虑业务希望 Redis 并发量, 客户端执行命令时间, node(应用个数) * maxTotal 不能超过 Redis 最大连接数



### 删除 bigkey

**非字符串的 bigkey, 不要使用 del 删除, 使用 hscan, sscan, zscan 方式渐进式删除, 同时要注意防止 bigkey 过期时间自动删除问题(例如一个 200 万的 zset 设置 1 小时过期, 会触发 del 操作, 造成阻塞, 而且该操作不会出现在慢查询中(latency可查)), 查找方法和删除方法**

Hash 删除: hscan + hdel

```java
public void delBigHash(String host,  int port,  String password,  String bigHashKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Entry<String,  String>> scanResult = jedis.hscan(bigHashKey,  cursor,  scanParams);
        List<Entry<String,  String>> entryList = scanResult.getResult();
        if (entryList != null && !entryList.isEmpty()) {
            for (Entry<String,  String> entry : entryList) {
                jedis.hdel(bigHashKey,  entry.getKey());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigHashKey);
}
```

List 删除: ltrim

```java
public void delBigList(String host,  int port,  String password,  String bigListKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    long llen = jedis.llen(bigListKey);
    int counter = 0;
    int left = 100;
    while (counter < llen) {
        //每次从左侧截掉100个
        jedis.ltrim(bigListKey,  left,  llen);
        counter += left;
    }
    //最终删除key
    jedis.del(bigListKey);
}
```

Set 删除: sscan + srem

```java
public void delBigSet(String host,  int port,  String password,  String bigSetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<String> scanResult = jedis.sscan(bigSetKey,  cursor,  scanParams);
        List<String> memberList = scanResult.getResult();
        if (memberList != null && !memberList.isEmpty()) {
            for (String member : memberList) {
                jedis.srem(bigSetKey,  member);
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigSetKey);
}
```

SortedSet 删除: zscan + zrem

```java
public void delBigZset(String host,  int port,  String password,  String bigZsetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey,  cursor,  scanParams);
        List<Tuple> tupleList = scanResult.getResult();
        if (tupleList != null && !tupleList.isEmpty()) {
            for (Tuple tuple : tupleList) {
                jedis.zrem(bigZsetKey,  tuple.getElement());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigZsetKey);
}
```

- hash key: 通过 hscan 命令, 每次获取 500 个字段, 再用 hdel 命令; 
- set key: 使用 sscan 命令, 每次扫描集合中 500 个元素, 再用srem命令每次删除一个元素; 
- list key: 删除大的 List 键, 未使用 scan 命令; 通过ltrim命令每次删除少量元素. 
- sorted set key: 删除大的有序集合键, 和List类似, 使用sortedset自带的zremrangebyrank命令,每次删除top 100个元素



## Redis 内存优化

### 内存消耗

#### 内存使用统计

| 属性名                  | 属性说明                                               |
| ----------------------- | ------------------------------------------------------ |
| used_memory             | Redis 分配器分配的内存量, 也就是实际存储数据的内存总量 |
| used_memory_human       | 以可读格式返回 Redis 使用的内存总量                    |
| used_memory_rss         | 从操作系统的角度, Redis 进程只用的总物理内存           |
| used_memory_peak        | 内存分配器分配的最大内存, 代表 used_memory 的历史峰值  |
| used_memory_peak_human  | 以可读的格式显示内存消耗峰值                           |
| used_memory_lua         | Lua 引擎所消耗的内存                                   |
| mem_fragmentation_ratio | used_memory_rss/used_memory 比值, 表示内存碎片率       |
| mem_allocator           | Redis 所使用的内存分配器, 默认 jemalloc                |

#### 内存消耗划分

used_memory: 自身内存, 对象内存, 缓冲内存, Lua 内存

used_memory_rss-used_memory: 内存碎片

<img src="https://miaomiaoqi.github.io/images/redis/redis_73.png" alt="https://miaomiaoqi.github.io/images/redis/redis_73.png" style="zoom: 33%;" />

输入缓冲区: 客户端发送命令, 会将命令放到输入缓冲区, 最大 1GB, 超过后会强制断开连接, 不可动态设置

输出缓冲区: 对应的配置骨子额是 `client-output-buffer-limie <class> <hard limit> <soft limit> <soft seconds>`

* \<class\>: 客户端类型, 分为三种(a)normal: 普通客户端 (b)slave: 从节点用于复制, 伪装成客户端 (c)pubsub: 发布订阅客户端

* \<hard limit\>: 如果客户端使用的输出缓冲区大于\<hard limit\>, 客户端会被立即关闭
* \<soft limit\>和\<soft seconds\>: 如果客户端使用的输出缓冲区超过了\<soft limit\>并且持续了\<soft limit\>秒, 客户端会被立即关闭

普通客户端缓冲区: `client-output-buffer-limit normal 0 0 0`, 没有限制客户端缓冲, 防止大的命令或者 monitor

slave 客户端缓冲区: `client-output-buffer-limit slave 256mb 64mb 60`, 主从延迟较高, 或者从节点过多, 建议设置较大, 从节点不要超过 2 个

pubsub 客户端: `client-output-buffer-limit pubsub 32mb 8mb 60`, 不是一个主流的使用方法

缓冲内存: 此部分内存独享, 考虑不分肤质, 默认 1MB, 可以设置更大

AOF 缓冲区: AOF 的缓冲区, 没有容量限制

### 内存管理

#### 设置内存上线

定义实例最大内存, 便于管理机器内存, 一般要预留 30%, config set maxmemory 6GB

#### 内存回收策略

删除过期键值

* 惰性删除: 访问 key -> expired ditc -> del key
* 定时删除: 每秒运行 10 次, 采样删除

超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制

* noeviction: 默认策略, 不会删除任何数据, 拒绝写入操作并返回客户端错误信息
* volatile-lru: 根据 lru 算法删除设置了超时属性(expire)的键, 直到腾出足够空间为止, 如果没有可删除的键对象, 回退到 noeviction 策略

* volatile-random: 随机删除过期键, 直到腾出足够空间为止
* volatile-ttl: 根据键值对象的 ttl 属性, 删除最近将要过期数据, 如果没有, 回退到 noeviction 策略

* allkeys-lru: 根据 lru 算法删除键, 不管数据有没有设置超时属性, 直到腾出足够空间为止
* allkeys-random: 随机删除所有键, 直到腾出足够空间为止





## Redis 的过期策略

### Redis 的 Key 过期策略

我们都知道, Redis 是 key-value 数据库, 我们可以设置 Redis 中缓存的 key 的过期时间. Redis 的过期策略就是指当 Redis 中缓存的 key 过期了, Redis 如何处理.

过期策略通常有以下三种: 

- 定时过期: 每个设置过期时间的 key 都需要创建一个定时器, 到过期时间就会立即清除.该策略可以立即清除过期的数据, 对内存很友好; **但是会占用大量的CPU 资源去处理过期的数据, 从而影响缓存的响应时间和吞吐量.**
- 惰性过期: 只有当访问一个 key 时, 才会判断该 key 是否已过期, 过期则清除.该策略可以最大化地节省 CPU 资源, 却对内存非常不友好. 极端情况可能出现大量的过期 key 没有再次被访问, 从而不会被清除, 占用大量内存.
- 定期过期: **Redis 默认每隔 100ms** 会随机抽取进行检查一定数量的数据库的 expires 字典中的 key, 并清除其中已过期的 key.该策略是前两者的一个折中方案.通过调整定时扫描的时间间隔和每次扫描的限定耗时, 可以在不同情况下使得 CPU 和内存资源达到最优的平衡效果.(expires 字典会保存所有设置了过期时间的 key 的过期时间数据, 其中 key 是指向键空间中的某个键的指针, value 是该键的毫秒精度的 UNIX 时间戳表示的过期时间. 键空间是指该 Redis 集群中保存的所有键)
    1. Redis配置项hz定义了serverCron任务的执行周期, 默认为10, 即CPU空闲时每秒执行10次
    2. 每次过期key清理的时间不超过CPU时间的25%, 即若hz=1, 则一次清理时间最大为250ms, 若hz=10, 则一次清理时间最大为25ms
    3. 清理时依次遍历所有的db
    4. 从db中随机取20个key, 判断是否过期, 若过期, 则逐出
    5. 若有5个以上key过期, 则重复步骤4, 否则遍历下一个db
    6. 在清理过程中, 若达到了25%CPU时间, 退出清理过程

**Redis 采用的是定期删除+惰性删除策略**

* 如果定期删除没删除key. 然后你也没即时去请求key, 也就是说惰性删除也没生效.这样, redis 的内存会越来越高.那么就应该采用内存淘汰机制.

    在 redis.conf 中有一行配置

    ```yaml
    # maxmemory-policy volatile-lru
    ```

    该配置就是配内存淘汰策略的

### Redis 的内存淘汰策略

Redis 的内存淘汰策略是指在Redis的用于缓存的内存不足时, 怎么处理需要新写入且需要申请额外空间的数据. 超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制.

- noeviction(默认): 当内存不足以容纳新写入数据时, 新写入操作会报错, 读和删除可继续. **应该没人用吧**
- allkeys-lru: 当内存不足以容纳新写入数据时, 在键空间中, 移除最近最少使用的 key. **推荐使用, 目前项目在用这种**
- allkeys-random: 当内存不足以容纳新写入数据时, 在键空间中, 随机移除某个 key. **你不删最少使用 Key, 去随机删**
- volatile-lru: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 移除最近最少使用的 key. **这种情况一般是把 redis 既当缓存, 又做持久化存储的时候才用**
- volatile-random: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 随机移除某个 key. **依然不推荐**
- volatile-ttl: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 有更早过期时间的 key 优先移除. **不推荐**

**如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致.**

#### Redis LRU 近似算法

Redis 使用的是一种近似 LRU 算法: 

1. key 增加最近访问时间戳字段

2. 选取一定数量的 key(默认5, server.maxmemory_samples进行配置), 比较最近访问时间.按照 LRU 算法淘汰 key.

当 Redis 执行写操作时, 发现内存超出 maxmemory, 就会执行一次 LRU 淘汰算法.

注意: maxmemory_samples 的值越大, Redis 的近似 LRU 算法就越接近于严格 LRU 算法(队列结构重排, 批量非热点数据缓存垃圾), 但是相应消耗也变高, 对性能有一定影响, 样本值默认为 5.



## Redis 中使用密码

Redis 默认配置是不需要密码认证的, 也就是说只要连接的Redis服务器的host和port正确, 就可以连接使用.这在安全性上会有一定的问题, 所以需要启用Redis的认证密码, 增加Redis服务器的安全性.

1. 修改配置文件

    Redis的配置文件默认在/etc/redis.conf, 找到如下行: 

    \#requirepass foobared

    去掉前面的注释, 并修改为所需要的密码: 

    requirepass myPassword (其中myPassword就是要设置的密码)

2. 启动redis服务

3. 登录验证

    设置Redis认证密码后, 客户端登录时需要使用-a参数输入认证密码, 不添加该参数虽然也可以登录成功, 但是没有任何操作权限.如下: 

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379
    127.0.0.1:6379> keys *
    (error) NOAUTH Authentication required.
    ```

    使用密码认证登录, 并验证操作权限

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379 -a myPassword
    127.0.0.1:6379> config get requirepass
    1) "requirepass"
    2) "myPassword"
    ```

4. 在Redis集群中使用认证密码

    如果Redis服务器, 使用了集群.除了在master中配置密码外, 也需要在slave中进行相应配置.在slave的配置文件中找到如下行, 去掉注释并修改与master相同的密码即可: 

    ```bash
    # masterauth master-password    
    ```



## Redis 选型

### **复杂数据结构, 选择 redis 更合适**

value是哈希, 列表, 集合, 有序集合这类复杂的数据结构时, 会选择redis, 因为mc无法满足这些需求.

最典型的场景, 用户订单列表, 用户消息, 帖子评论列表等.



### **持久化, 选择 redis 更合适**

mc无法满足持久化的需求, 只得选择redis.

但是, 这里要提醒的是, **真的使用对了redis的持久化功能么? **

千万不要把redis当作数据库用: 

* redis 的定期快照不能保证数据不丢失; 

* redis 的 AOF 会降低效率, 并且不能支持太大的数据量; 

不要期望 redis 做固化存储会比 mysql 做得好, 不同的工具做各自擅长的事情, 把 redis 当作数据库用, 这样的设计八成是错误的.



**缓存场景, 开启固化功能, 有什么利弊? **

如果只是缓存场景, 数据存放在数据库, 缓存在 redis, 此时如果开启固化功能: 

**优点是**, redis 挂了再重启, 内存里能够快速恢复热数据, 不会瞬时将压力压到数据库上, 没有一个cache预热的过程.

**缺点是**, 在 redis 挂了的过程中, 如果数据库中有数据的修改, 可能导致redis重启后, 数据库与redis的数据不一致.

因此, 只读场景, 或者允许一些不一致的业务场景, 可以尝试开启redis的固化功能.

### **高可用, 选择 redis 更合适**

redis 天然支持集群功能, 可以实现主动复制, 读写分离.

redis 官方也提供了 sentinel 集群管理工具, 能够实现主从服务监控, 故障自动转移, 这一切, 对于客户端都是透明的, 无需程序改动, 也无需人工介入.

***画外音: memcache, 要想要实现高可用, 需要进行二次开发, 例如客户端的双读双写, 或者服务端的集群同步.***

但是, 这里要提醒的是, **大部分业务场景, 缓存真的需要高可用么? **

* 缓存场景, 很多时候, 是允许cache miss

* 缓存挂了, 很多时候可以通过DB读取数据

所以, 需要认真剖析业务场景, 高可用, 是否真的是对缓存的主要需求? 

***画外音: 即时通讯业务中, 用户的在线状态, 就有高可用需求.***

 

### 存储的内容比较大, 选择 redis 更合适

memcache 的 value 存储, 最大为 1 M, 如果存储的 value 很大, 只能使用 redis.

当然, redis 与 memcache 相比, 由于底层实现机制的差异, **也有一些“劣势”的情况.**



**情况一: 由于内存分配机制的差异, redis 可能导致内存碎片**

memcache 使用预分配内存池的方式管理内存, 能够省去内存分配时间.

redis 则是临时申请空间, 可能导致碎片.

从这一点上, mc 会更快一些.

 

**情况二: 由于虚拟内存使用的差异, redis 可能会刷盘影响性能**

memcache 把所有的数据存储在物理内存里.

redis 有自己的 VM 机制, 理论上能够存储比物理内存更多的数据, 当数据超量时, 会引发 swap, 把冷数据刷到磁盘上.

从这一点上, 数据量大时, mc 会更快一些.

***画外音: 新版本 redis 已经优化.***

 

**情况三: 由于网络模型的差异, redis 可能会因为 CPU 计算影响 IO 调度**

memcache 使用非阻塞 IO 复用模型, redis 也是使用非阻塞 IO 复用模型.

但由于 redis 还提供一些非 KV 存储之外的排序, 聚合功能, 在执行这些功能时, 复杂的 CPU 计算, 会阻塞整个 IO 调度.

从这一点上, 由于 redis 提供的功能较多, mc 会更快一些.

 

**情况四: 由于线程模型的差异, redis 难以利用多核特效提升性能**

memcache 使用多线程, 主线程监听, worker 子线程接受请求, 执行读写, 这个过程中, 可能存在锁冲突.

redis 使用单线程, 虽无锁冲突, 但难以利用多核的特性提升整体吞吐量.

从这一点上, mc 会快一些.



**情况五: 由于缺乏 auto-sharding, redis 只能手动水平扩展**

不管是 redis 还是 memcache, 服务端集群没有天然支持水平扩展, 需要在客户端进行分片, 这其实对调用方并不友好.如果能服务端集群能够支持水平扩展, 会更完美一些.



## 面试

### 什么是 Redis

基于内存, KV 存储结构

KV: redis 通常是用来做缓存的, 只缓存一部分数据, 数据是不完整的, 所以不适合关系型

单线程: worker 单线程, iothreads 多线程

连接很多: 并发高

<img src="https://miaomiaoqi.github.io/images/redis/redis_80.png" alt="https://miaomiaoqi.github.io/images/redis/redis_80.png" style="zoom: 50%;" />

### 本地方法: 计算向数据移动, IO 优化

在 memcached 中, 只能将列表全部取出然后在应用内获取对应下标的值, 增加了网络 io 的开销, 而使用 redis, 可以在 redis 中计算出想要的数据, 极大地减少了网络 io 的开销

<img src="https://miaomiaoqi.github.io/images/redis/redis_77.png" alt="https://miaomiaoqi.github.io/images/redis/redis_77.png" style="zoom: 33%;" />

### 串行化/原子, 并行 VS 串行

Redis 是单线程的, 串行化, 执行命令需要 3 个步骤, 1: epoll 通知有 event 的到来, 2: 读取事件内容, 3: 本地计算结果

<img src="https://miaomiaoqi.github.io/images/redis/redis_76.png" alt="https://miaomiaoqi.github.io/images/redis/redis_76.png" style="zoom: 33%;" />

如果在多核 CPU 情况下, 此处有个小弊端, 因为 Redis 是单线程的, 所以 CPU 的利用率并不高, redis 的计算和 io 实际上是独立的, c1 的 io 要等到 c2 结束后才进行, 实际上是一种资源浪费, c1 的 io 与 c2 的 io 和计算完全可以并行进行, 所以在 Redis6.x 以后进行了 iothreads 多线程优化, 需要配置开启, 不是默认行为

<img src="https://miaomiaoqi.github.io/images/redis/redis_79.png" alt="https://miaomiaoqi.github.io/images/redis/redis_79.png" style="zoom: 33%;" />

在高并发交易场景下, 并发可能是 100, 但并行度是 2, 最终落到 db 时要保证是串行化, 如果使用传统 db 加锁性能低下, 如果使用 redis, 天然的单线程内存模型效率会大大提高

<img src="https://miaomiaoqi.github.io/images/redis/redis_78.png" alt="https://miaomiaoqi.github.io/images/redis/redis_78.png" style="zoom: 33%;" />



## 其他链接

[https://mp.weixin.qq.com/s/aXaMRAUD3IBVOk_HvSfSWg](https://mp.weixin.qq.com/s/aXaMRAUD3IBVOk_HvSfSWg)