---
layout: post
title: "Redis 基础"
categories: [NoSql]
description:
keywords:
---

* content
{:toc}




## Redis 初识

### Redis 的特性

#### 速度快

官方称 Redis 可以达到 10W OPS, 虽然实际上不会 100% 达到 10W OPS 但是几万 OPS 还是有的, 原因有如下 3 点

* 数据存储在内存中, 内存相较于寄存器来说便宜, 相较于硬盘来说速度又快许多, 足够满足日常需求

    <img src="http://www.milky.show/images/redis/redis_58.png" alt="http://www.milky.show/images/redis/redis_58.png" style="zoom: 33%;" />

    | 类型   | 每秒读写次数 | 随机读写延迟 | 访问带宽   |
    | ------ | ------------ | ------------ | ---------- |
    | 内存   | 千万级       | 80ns         | 5GB        |
    | SSD 盘 | 35000        | 0.1-0.2ms    | 100~300MB  |
    | 机械盘 | 100 左右     | 10ms         | 100MB 左右 |

* 使用 C 语言编写

* 单线程模型

#### 持久化

Redis 所有的数据保持在内存中, 对数据的更新将异步地保存到磁盘上

#### 多种数据结构

Redis 支持 5 种经典数据结构

<img src="http://www.milky.show/images/redis/redis_59.png" alt="http://www.milky.show/images/redis/redis_59.png" style="zoom: 33%;" />

还支持其他的数据结构

* BitMaps: 位图
* HyperLogLog: 超小内存唯一值计数
* GEO: 地理信息定位

#### 支持多种编辑语言

Java, PHP, Python, Ruby, Lua, Nodejs

#### 功能丰富

发布订阅, Lua 脚本实现自定义功能, 事务, pipeline

#### 简单

最初的版本只有 23000 行代码, 源码易读, 不依赖外部, 单线程模型

#### 主从复制, 高可用, 分布式

从 Redis2.8 开始支持 Redis-Sentinel 高可用

从 Redis3.0 开始支持 Redis-Cluster 分布式



#### Redis 默认 16 个数据库

Redis是一个字典结构的存储服务器, 一个Redis实例提供了多个用来存储数据的字典, 客户端可以指定将数据存储在哪个字典中. 这与在一个关系数据库实例中可以创建多个数据库类似（如下图所示）, 所以可以将其中的每个字典都理解成一个独立的数据库. 

Redis默认支持16个数据库, 可以通过调整Redis的配置文件redis/redis.conf中的databases来修改这一个值, 设置完毕后重启Redis便完成配置. 

客户端与Redis建立连接后会默认选择0号数据库, 不过可以随时使用SELECT命令更换数据库. 

由于Redis不支持自定义数据库的名字, 所以每个数据库都以编号命名. 开发者则需要自己记录存储的数据与数据库的对应关系. 另外Redis也不支持为每个数据库设置不同的访问密码, 所以一个客户端要么可以访问全部数据库, 要么全部数据库都没有权限访问. 但是, 要正确地理解Redis的“数据库”概念这里不得不提到一个命令:

`flushall`

该命令可以清空实例下的所有数据库数据, 这与我们所熟知的关系型数据库所不同. 关系型数据库多个库常用于存储不同应用程序的数据 , 且没有方式可以同时清空实例下的所有库数据. 所以对于Redis来说这些db更像是一种命名空间, 且不适宜存储不同应用程序的数据. 比如可以使用0号数据库存储某个应用生产环境中的数据, 使用1号数据库存储测试环境中的数据, 但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据, 不同的应用应该使用不同的Redis实例存储数据. Redis非常轻量级, 一个空Redis实例占用的内在只有1M左右, 所以不用担心多个Redis实例会额外占用很多内存. 

要注意以上所说的都是基于单体Redis的情况. 而在集群的情况下不支持使用select命令来切换db, 因为Redis集群模式下只有一个db0. 再扩展一些集群与单机Reids的区别, 感兴趣的朋友可以去查阅相关的资料深入理解, 这里就不做讨论了. 

- key批量操作支持有限:例如mget, mset必须在一个slot
- Key事务和Lua支持有限:操作的key必须在一个节点
- key是数据分区的最小粒度:不支持bigkey分区
- 不支持多个数据库:集群模式下只有一个db0
- 复制只支持一层:不支持树形复制结构



### 单线程 Redis 为什么这么快?

纯内存操作

单线程操作, 避免了频繁的上下文切换

基本对象使用多种底层数据结构, 且灵活变化是redis高性能的另一个原因

**采用了非阻塞I/O多路复用机制**

我们现在要仔细的说一说I/O多路复用机制, 因为这个说法实在是太通俗了, 通俗到一般人都不懂是什么意思.博主打一个比方: 小曲在S城开了一家快递店, 负责同城快送服务.小曲因为资金限制, 雇佣了一批快递员, 然后小曲发现资金不够了, 只够买一辆车送快递.

* 经营方式一

    客户每送来一份快递, 小曲就让一个快递员盯着, 然后快递员开车去送快递.慢慢的小曲就发现了这种经营方式存在下述问题

    几十个快递员基本上时间都花在了抢车上了, 大部分快递员都处在闲置状态, 谁抢到了车, 谁就能去送快递

    随着快递的增多, 快递员也越来越多, 小曲发现快递店里越来越挤, 没办法雇佣新的快递员了

    快递员之间的协调很花时间

    综合上述缺点, 小曲痛定思痛, 提出了下面的经营方式

* 经营方式二

    小曲只雇佣一个快递员.然后呢, 客户送来的快递, 小曲按送达地点标注好, 然后依次放在一个地方.最后, 那个快递员依次的去取快递, 一次拿一个, 然后开着车去送快递, 送好了就回来拿下一个快递.

    对比上述两种经营方式对比, 是不是明显觉得第二种, 效率更高, 更好呢.在上述比喻中:

每个快递员------------------>每个线程

每个快递-------------------->每个socket(I/O流)

快递的送达地点-------------->socket的不同状态

客户送快递请求-------------->来自客户端的请求

小曲的经营方式-------------->服务端运行的代码

一辆车---------------------->CPU的核数

1. 于是我们有如下结论:

    * 经营方式一就是传统的并发模型, 每个I/O流(快递)都有一个新的线程(快递员)管理.

    * 经营方式二就是I/O多路复用.只有单个线程(一个快递员), 通过跟踪每个I/O流的状态(每个快递的送达地点), 来管理多个I/O流.

    下面类比到真实的redis线程模型, 如图所示

    <img src="http://www.milky.show/images/redis/redis_1.png" alt="http://www.milky.show/images/redis/redis_1.png" style="zoom:50%;" />

### Redis 典型使用场景

缓存系统, 计数器功能, 消息队列系统, 排行榜, 社交网络, 实时系统

### Redis 单机安装

到官网下载, tar 解压缩, make&make install 安装

#### 可执行文件说明

redis-server: Redis 服务器

redis-cli: Redis 命令行客户端

redis-benchmark: Redis 性能测试工具

redis-check-aof: AOF 文件修复工具

redis-check-dump: RDB 文件检查工具

redis-sentinel: Sentinel 服务器(2.8 之后)

#### 三种启动方式

最简启动: redis-server 使用默认参数

动态参数启动: redis-server \-\-port 6380

配置文件启动: redis-server configPath

#### Redis 常用配置

daemonize: 是否是守护进程启动 no|yes

port: Redis 对外端口号, 默认 6379, 对应意大利女歌手的名字 Merz

logfile: Redis 系统日志

dir: Redis 工作目录

去除空格和注释输出 redis 配置并重定向到新的文件 `cat redis-6381.conf|grep -v "#"|grep -v "^$" > redis-6382.com`

## API 的理解和使用

### 通用命令

| **命令**        | **描述**                                                     | **用法**                                                     |      |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
| DEL             | 1. 删除给定的一个或多个key<br/>2. 不存在的Key将被忽略        | DEL key1 [key2 ...]                                          | O(1) |
| EXISTS          | 1. 检查给定 key 是否存在<br />2. 存在返回 1, 不存在返回 0, 线上可用 | EXISTS key                                                   | O(1) |
| EXPIRE          | 1. 为给定key设置生存时间, key 过期时它会被自动删除<br/>2. 对一个已经指定生存时间的 key 设置执行expire, 新的值会代替旧的值 | EXPIRE key seconds                                           | O(1) |
| EXPIREAT        | 1. 同EXPIRE, 但此命令指定的是UNIX时间戳, 单位为秒            | EXPIRE key timestamp                                         | O(1) |
| KEYS            | 1. 查找所有符合给定模式 pattern 的 key, 下面举一下例子<br/>2. KEYS \*匹配所有key<br/>3. KEYS h?llo匹配hello, hallo, hxllo等<br/>4. KEYS h*llo匹配hllo, heeeeello等<br/>5. KEYS h[ae]llo匹配hello和hallo<br/>6. 特殊符号想当做查找内容经的使用\ <br />**7. 线上禁用该命令** | KEYS pattern                                                 | O(n) |
| DBSIZE          | 计算 key 的总数, 生产可用, 内部维护了计数器                  | DBSIZE                                                       | O(1) |
| MIGRATE         | 1. 原子性地将key从当前实例传送到目标实例指定的数据库上<br/>2. 原数据库Key删除, 新数据库Key增加<br/>3. 阻塞进行迁移的两个实例, 直到迁移成功, 迁移失败, 等待超时三个之一发生 | MIGRATE host port key destination-db timeout [COPY] [REPLACE] |      |
| MOVE            | 1. 将当前数据库的key移动到给定数据库的db中<br/>2. 执行成功的条件为当前数据库有key, 给定数据库没有key | MOVE key db                                                  |      |
| PERSIST         | 1. 移除给定key的生存时间, 将key变为持久的                    | PERSIST key                                                  |      |
| RANDOMKEY       | 1. 从当前数据库随机返回且不删除一个key,                      | RANDOMKEY                                                    |      |
| RENAME          | 1. 将key改名为newkey<br/>2. 当key和newkey相同或key不存在, 报错<br/>3. newkey已存在, RENAME将覆盖旧值 | RENAME key newkey                                            |      |
| TTL             | 1. 以秒为单位, 返回给定的key剩余生存时间                     | TTL key                                                      |      |
| PTTL            | 1. 以毫秒为单位, 返回给定的key剩余生存时间                   | PTTL key                                                     |      |
| TYPE            | 1. 返回key锁存储的值的类型, string, hash, list, set, zset, none | TYPE key                                                     | O(1) |
| OBJECT ENCODING | 1. 显示数据类型的底层数据结构                                | OBJECT ENCODING key                                          |      |
| INFO MEMORY     | 1. 查看内存使用情况                                          | INFO MEMORY                                                  |      |

### 数据结构和内部编码

Redis 是基于内存的数据库, 内存相对来说还是比较贵的, 如果我们在使用数据结构时, 以时间换取空间, 可以使用一些压缩的结构比如 ziplist, 如果元素个数比较小的时候, 就可以用空间来换时间, 这就是内部编码的作用, 可以使我们的 redis 有一个更好的使用率, 我们在使用时不用关心具体内部编码的实现, 直接使用数据结构的 api 即可, 是一种面向接口编程的思想

<img src="http://www.milky.show/images/redis/redis_62.png" alt="http://www.milky.show/images/redis/redis_62.png" style="zoom: 33%;" />

### redisObject 结构体

<img src="http://www.milky.show/images/redis/redis_63.png" alt="http://www.milky.show/images/redis/redis_63.png" style="zoom: 25%;" />

### 单线程

**单线程为什么这么快**

* 纯内存
* 非阻塞 IO
* 避免线程切换和竞态消耗

**单线程要注意什么**

* 一次只运行一条命令

* 拒绝长(慢)命令, keys, flushall, flushdb, slow lua script, multi/exec, operate big value(collection)

* 其实不是单线程

    fysnc file descriptor

    close file descriptor





### 系统相关命令

| **命令**         | **描述**                                                     | **用法**                   |
| ---------------- | ------------------------------------------------------------ | -------------------------- |
| BGREWRITEAOF     | 1. 手动触发AOF重写操作, 用于减小AOF文件体积                  | BGREWRITEAOF               |
| BGSAVE           | 1. 后台异步保存当前数据库的数据到磁盘                        | BGSAVE                     |
| CLIENT KILL      | 1. 关闭地址为ip:port的客户端<br/>2. 由于Redis为单线程设计, 因此当当前命令执行完之后才会关闭客户端 | CLIENT KILL ip:port        |
| CLIENT LIST      | 1. 以可读的格式, 返回所有连接到服务器的客户端信息和统计数据  | CLIENT LIST                |
| CONFIG GET       | 1. 取得运行中的Redis服务器配置参数<br/>2. 支持*              | CONFIG GET parameter       |
| CONFIG RESETSTAT | 1. 重置INFO命令中的某些统计数据, 例如Keyspace hits, Keyspace misses等 | CONFIG RESETSTAT           |
| CONFIG REWRITE   | 1. 对**启动Redis时指定的redis.conf文件进行改写**             | CONFIG REWRITE             |
| CONFIG SET       | 1. 动态调整Redis服务器的配置而无需重启<br/>2. 修改后的配置**立即生效** | CONFIG SET parameter value |
| SELECT           | 1. 切换到指定数据库, 数据库索引index用数字指定, 以0作为起始索引值<br/>2. 默认使用0号数据库 | SELECT index               |
| DBSIZE           | 1. 返回当前数据库的Key的数量                                 | DBSIZE                     |
| DEBUG OBJECT     | 1. 这是一个调试命令, 不应当被客户端使用<br/>2. key存在时返回有关信息, key不存在时返回错误 | DEBUG OBJECT key           |
| FLUSHALL         | 1. 清空整个Redis服务器的数据<br />2. 线上禁用                | FLUSHALL                   |
| FLUSHDB          | 1. 清空当前数据库中的所有数据                                | FLUSHDB                    |
| INFO             | 1. 以一种易于解释且易于阅读的格式, 返回Redis服务器的各种信息和统计数值2. 通过给定可选参数section, 可以让命令只返回某一部分信息 | INFO [section]             |
| LASTSAVE         | 1. 返回最近一次Redis成功将数据保存到磁盘上的时间, 以UNIX时间戳格式表示 | LASTSAVE                   |
| MONITOR          | 1. 实时打印出Redis服务器接收到的命令, 调试用                 | MONITOR                    |
| SHUTDOWN         | 1. 停止所有客户端<br/>2. 如果至少有一个保存点在等待, 执行SAVE命令<br/>3. 如果AOF选项被打开, 更新AOF文件<br/>4. 关闭Redis服务器 | SHUTDOWN [SAVE\|NOSAVE]    |





### 字符串类型

实际上type=string代表value存储的是一个普通字符串, 那么对应的encoding可以是raw或者是int, 如果是int则代表实际redis内部是按数值型类存储和表示这个字符串的, 当然前提是这个字符串本身可以用数值表示, **比如"20"这样的字符串, 当遇到incr, decr等操作时会转成数值型进行计算, 此时redisObject的encoding字段为int**.如果你试图对name进行incr操作则报错.

#### 结构和命令

value 的值可是字符串, 可以是数字, 可以是 0, 1 的二进制位, 上限是 512MB, 建议 100k 以内, 适用于缓存, 计数器, 分布式锁等等

| **命令** | **描述**                                                     | **用法**                                              | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ----------------------------------------------------- | :--------: |
| SET      | 1. 将字符串值 Value 关联到 Key<br/>2. Key 已关联则覆盖, 无视类型<br/>3. 原本 Key 带有生存时间 TTL, 那么 TTL 被清除 | set key value [EX seconds] [PX milliseconds] [NX\|XX] |    O(1)    |
| SETEX    | 1. 将 Value 关联到 Key<br/>2. 设置 Key 生存时间为 seconds, 单位为秒<br/>3. 如果 Key 对应的 Value 已经存在, 则覆盖旧值<br/>4. SET 同时也可以设置失效时间, 是一个原子操作, 即关联值与设置生存时间同一时间完成 | setex key seconds value                               |    O(1)    |
| SETNX    | 1. 将 Key 的值设置为Value, **当且仅当 Key 不存在**<br/>2. 若给定的 Key 已经存在 SEXNX 不做任何动作 | setnx key value                                       |    O(1)    |
| setxx    | 1. 将 Key 的值设置为 Value, **当且仅当 Key 存在**<br/>2. 若给定的 Key 不存在 SEXXX 不做任何动作 | set key value xx                                      |    O(1)    |
| GET      | 1. 返回 key 关联的字符串值<br/>2. Key 不存在返回 nil<br/>3. Key 存储的不是字符串, 返回错误, 因为 GET 只用于处理字符串 | GET key                                               |    O(1)    |
| MSET     | 1. 同时设置一个或多个 Key-Value 键值对<br/>2. 某个给定 Key 已经存在, 那么 MSET 新值会覆盖旧值<br/>3. 如果上面的覆盖不是希望的, 那么使用 MSETNX 命令, **所有 Key 都不存在才会进行覆盖**<br/>4. **MSET 是一个原子性操作**, 所有 Key 都会在同一时间被设置, 不会存在有些更新有些没更新的情况 | MSET key1 value1 [key1 value1 ...]                    |    O(n)    |
| MGET     | 1. 返回一个或多个给定 Key 对应的 Value<br/>2. 某个 Key 不存在那么这个 Key 返回 nil | MGET key1 [key2 ...]                                  |    O(n)    |
| INCR     | 1. Key 中存储的数字值 +1, 返回增加之后的值<br/>2. Key 不存在, 那么 Key 的值被初始化为 0 再执行 INCR<br/>3. 如果值包含错误类型或者字符串不能被表示为数字, 那么返回错误<br/>4. 值限制在64位有符号数字表示之内, 即-9223372036854775808~9223372036854775807 | INCR key                                              |    O(1)    |
| DECR     | 1. Key 中存储的数字值 -1<br/>2. 其余同 INCR                  | DECR key                                              |    O(1)    |
| INCRBY   | 1. 将 key 所存储的值加上增量返回增加之后的值<br/>2. 其余同 INCR | INCRBY key increment                                  |    O(1)    |
| DECRBY   | 1. 将 key 所存储的值减去减量 decrement<br/>2. 其余同 INCR    | DECRBY key decrement                                  |    O(1)    |
| APPEND   | 1. 给指定 key 的 value 追加字符串, 并返回新字符串的长度      | append key value                                      |    O(1)    |
| GETSET   | 1. 设置 key 的值, 并返回 key 旧的值                          | getset key newvalue                                   |    O(1)    |
| STRLEN   | 1. 取指定 key 的 value 的长度(注意中文)                      | strlen key                                            |    O(1)    |

#### 快速实战

记录网站每个用户个人主页的访问量

```bash
incr userid:pageview(单线程,  无竞争)
```

缓存视频的基本信息(数据源在 MySQL 中), 伪代码

```java
public VideoInfo get(long id) {
    String redisKey = redisPrefix + id;
    VideoInfo videInfo = redis.get(redisKey);
    if (videoInfo == null) {
        videoInfo = mysql.get(id);
        if (videoInfo != null) {
            // 序列化
            redis.set(redisKey, serialize(videoInfo));
        }
    }
    return videoInfo;
}
```

分布式 id 生成器, 不同的应用获取一个自增的 id, 因为 redis 单线程的, 所以不同的服务肯定获得不同的值

```bash
incr counter
```

### 哈希类型, 可以对 key 进行分类

#### 结构和命令

Hash是一个String类型的field和value之间的映射表, 即redis的Hash数据类型的key(hash表名称)对应的value实际的内部存储结构为一个HashMap, 因此Hash特别适合存储对象.相对于把一个对象的每个属性存储为String类型, 将整个对象存储在Hash类型中会占用更少内存.

当前HashMap的实现有两种方式: 当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储, 而不会采用真正的HashMap结构, 这时对应的value的redisObject的encoding为zipmap, 当成员数量增大时会自动转成真正的HashMap, 此时encoding为ht.

用一个对象来存储用户信息, 商品信息, 订单信息等等.

<img src="http://www.milky.show/images/redis/redis_2.png" alt="http://www.milky.show/images/redis/redis_2.png" style="zoom:50%;" />

| **命令** | **描述**                                                     | **用法**                                    | 时间复杂度 |
| -------- | ------------------------------------------------------------ | ------------------------------------------- | ---------- |
| HSET     | 1. 将哈希表Key中的域field的值设为value<br/>2. key不存在, 一个新的Hash表被创建<br/>3. field已经存在, 旧的值被覆盖 | HSET key field value                        | O(1)       |
| HSETNX   | 1. 设置key对应的HashMap中的field的value, 如果 field 已经存在, 则失败 | hsetnx key field value                      | O(1)       |
| HGET     | 1. 返回哈希表key中给定域field的值                            | HGET key field                              | O(1)       |
| HDEL     | 1. 删除哈希表key中的一个或多个指定域<br/>2. 不存在的域将被忽略 | HDEL key filed1 [field2 ...]                | O(1)       |
| HEXISTS  | 1. 查看哈希表key中, 给定 field 是否存在, 存在返回1, 不存在返回0 | HEXISTS key field                           | O(1)       |
| HGETALL  | 1. 返回哈希表key中, 所有的域和值                             | HGETALL key                                 | O(n)       |
| HINCRBY  | 1. 为哈希表key中的域field加上增量increment<br/>2. 其余同INCR命令 | HINCRYBY key filed increment                | O(1)       |
| HLEN     | 1. 返回哈希表key中 field 的数量                              | HLEN key                                    | O(1)       |
| HMGET    | 1. 返回哈希表key中, 一个或多个给定域的值<br/>2. 如果给定的域不存在于哈希表, 那么返回一个nil值 | HMGET key field1 [field2 ...]               | O(n)       |
| HMSET    | 1. 同时将多个field-value对设置到哈希表key中<br/>2. 会覆盖哈希表中已存在的域<br/>3. key不存在, 那么一个空哈希表会被创建并执行HMSET操作 | HMSET key field1 value1 [field2 value2 ...] | O(n)       |
| HKEYS    | 1. 返回哈希表key中的所有域                                   | HKEYS key                                   | O(n)       |
| HVALS    | 1. 返回哈希表key中所有的值                                   | HVALS key                                   | O(n)       |

#### 快速实战

记录网站每个用户个人主页的访问量, 每次自增 1

```
hincrby user:1:info pageview 1
```

缓存视频的基本信息(数据源在 mysql 中)伪代码

```java
public VideoInfo get(long id) {
    String redisKey = redisPrefix + id;
    Map<String, String> hashMap = redis.hgetAll(redisKey);
    VideoInfo videoInfo = transferMapToVideo(hashMap);
    if (videoInfo == null) {
        videoInfo = mysql.get(id);
        if (videoInfo != null) {
            redis.hmset(redisKey, transferVideoToMap(videoInfo));
        }
    }
}
```



### 列表类型, 元素有序可重复

Redis的List类型其实就是每一个元素都是String类型的**双向链表**.我们可以从链表的头部和尾部添加或者删除元素.这样的List既可以作为栈, 也可以作为队列使用.

如好友列表, 粉丝列表, 消息队列, 最新消息排行等.另外还有一个就是, 可以利用lrange命令, 做**基于redis的分页功能**, 性能极佳, 用户体验好.

![http://www.milky.show/images/redis/redis_3.png](http://www.milky.show/images/redis/redis_3.png)

#### 结构和命令

| **命令**  | **描述**                                                     | **用法**                              | 时间复杂度 |
| --------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| LPUSH     | 1. 将一个或多个值value插入到列表key的表头<br/>2. 如果有多个value值, 那么各个value值按从左到右的顺序依次插入表头<br/>3. key不存在, 一个空列表会被创建并执行LPUSH操作<br/>4. key存在但不是列表类型, 返回错误 | LPUSH key value1 [value2 ...]         | O(1~n)     |
| LPUSHX    | 1. 将值value插入到列表key的表头, 当且key存在且为一个列表<br/>2. key不存在时, LPUSHX命令什么都不做 | LPUSHX key value1 [value2...]         | O(1~n)     |
| LPOP      | 1. 移除并返回列表key的头元素                                 | LPOP key                              | O(1)       |
| LRANGE    | 1. 返回列表key中指定区间内的元素, 区间以偏移量start和end指定<br/>2. start和end都以0位底<br/>3. 可使用负数下标, -1表示列表最后一个元素, -2表示列表倒数第二个元素, 以此类推<br/>4. start大于列表最大下标, 返回空列表<br/>5. stop大于列表最大下标, stop=列表最大下标 | LRANGE key start end(包含 end)        | O(n)       |
| LREM      | 1. 根据count的值, 移除列表中与value相等的元素<br/>2. count>0表示从头到尾搜索, 移除与value相等的元素, 数量为count<br/>3. count<0表示从从尾到头搜索, 移除与value相等的元素, 数量为count<br/>4. count=0表示移除表中所有与value相等的元素 | LREM key count value                  | O(n)       |
| LSET      | 1. 将列表key下标为index的元素值设为value<br/>2. index参数超出范围, 或对一个空列表进行LSET时, 返回错误 | LSET key index value                  | O(n)       |
| LINDEX    | 1. 返回列表key中, 下标为index的元素                          | LINDEX key index                      | O(n)       |
| LINSERT   | 1. 将值value插入列表key中, 位于pivot前面或者后面插入 value 元素<br/>2. pivot不存在于列表key时, 不执行任何操作<br/>3. key不存在, 不执行任何操作 | LINSERT key BEFORE\|AFTER pivot value | O(n)       |
| LLEN      | 1. 返回列表key的长度<br/>2. key不存在, 返回0                 | LLEN key                              | O(1)       |
| LTRIM     | 1. 对一个列表进行修剪, 让列表只返回指定区间内的元素, **不存在指定区间内的都将被移除** | LTRIM key start end                   | O(n)       |
| RPOP      | 1. 移除并返回列表key的尾元素                                 | RPOP key                              | O(1)       |
| RPOPLPUSH | 在一个原子时间内, 执行两个动作: <br/>1. 将列表source中最后一个元素弹出并返回给客户端<br/>2. 将source弹出的元素插入到列表desination, 作为destination列表的头元素 | RPOPLPUSH source destination          |            |
| RPUSH     | 1. 将一个或多个值value插入到列表key的表尾                    | RPUSH key value1 [value2 ...]         | O(1~n)     |
| RPUSHX    | 1. 将value插入到列表key的表尾, 当且仅当key存在并且是一个列表<br/>2. key不存在, RPUSHX什么都不做 | RPUSHX key value                      |            |

#### 快速实战

根据时间轴展示微博内容, 当有用户更新微博时, 将用户的 id 使用 rpush 存入 list 中, 每次 lrange 获取 id, 并根据 id 找到对应的微博内容

### 集合类型, 元素是无序的, 元素不能重复. 并集, 交集, 差集

因为set堆放的是一堆不重复值的集合.所以可以做**全局去重**的功能.为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署, 使用JVM自带的Set, 比较麻烦, 难道为了一个做一个全局去重, 再起一个公共服务, 太麻烦了.
另外, 就是利用交集, 并集, 差集等操作, 可以计算**共同喜好, 全部的喜好, 自己独有的喜好等功能**

Redis 集合(Set类型)是一个无序的String类型数据的集合, 类似List的一个列表, 与List不同的是Set不能有重复的数据.实际上, Set的内部是用HashMap实现的, Set只用了HashMap的key列来存储对象

**集合有取交集, 并集, 差集等操作, 因此可以求共同好友, 共同兴趣, 分类标签等**

#### 结构和命令

| **命令**    | **描述**                                                     | **用法**                              | 时间复杂度 |
| ----------- | ------------------------------------------------------------ | ------------------------------------- | ---------- |
| SADD        | 1. 将一个或多个member元素加入到key中, 已存在在集合的member将被忽略<br/>2. 假如key不存在, 则只创建一个只包含member元素做成员的集合<br/>3. 当key不是集合类型时, 将返回一个错误 | SADD key member1 [member2 ...]        | O(1)       |
| SCARD       | 1. 返回key对应的集合中的元素数量                             | SCARD key                             | O(1)       |
| SDIFF       | 1. 返回一个集合的全部成员, 该集合是第一个Key对应的集合和后面key对应的集合的差集 | SDIFF key [key ...]                   |            |
| SDIFFSTORE  | 1. 和SDIFF类似, 但结果保存到destination集合而不是简单返回结果集<br/>2.  destination如果已存在, 则覆盖 | SDIFFSTORE destionation key [key ...] |            |
| SINTER      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的交集<br/>2. 不存在的key被视为空集 | SINTER key [key ...]                  |            |
| SINTERSTORE | 1. 和SINTER类似, 但结果保存早destination集合而不是简单返回结果集<br/>2. 如果destination已存在, 则覆盖<br/>3. destination可以是key本身 | SINTERSTORE destination key [key ...] |            |
| SUNION      | 1. 返回一个集合的全部成员, 该集合是所有给定集合的并集<br/>2. 不存在的key被视为空集 | SUNION key [key ...]                  |            |
| SUNIONSTORE | 1. 类似SUNION, 但结果保存到destination集合而不是简单返回结果集<br/>2. destination已存在, 覆盖旧值<br/>3. destination可以是key本身 | SUNION destination key [key ...]      |            |
| SISMEMBER   | 1. 判断member元素是否key的成员, 0表示不是, 1表示是           | SISMEMBER key member                  |            |
| SMEMBERS    | 1. 返回集合key中的所有成员<br/>2. 不存在的key被视为空集      | SMEMBERS key                          |            |
| SMOVE       | 1. 原子性地将member元素从source集合移动到destination集合<br/>2. source集合中不包含member元素, SMOVE命令不执行任何操作, 仅返回0<br/>3. destination中已包含member元素, SMOVE命令只是简单做source集合的member元素移除 | SMOVE source desination member        |            |
| SPOP        | 1. **移除**并返回集合中的一个随机元素, 如果count不指定那么随机返回一个随机元素<br/>2. count为正数且小于集合元素数量, 那么返回一个count个元素的数组且数组中的**元素各不相同**<br/>3. count为正数且大于等于集合元素数量, 那么返回整个集合<br/>4. count为负数那么命令返回一个数组, 数组中的**元素可能重复多次**, 数量为count的绝对值 | SPOP key [count]                      |            |
| SRANDMEMBER | 1. 如果count不指定, 那么返回集合中的一个随机元素<br/>2. count同上<br />3. 不会破坏集合元素 | SRANDMEMBER key [count]               |            |
| SREM        | 1. 移除集合key中的一个或多个member元素, 不存在的member将被忽略 | SREM key member1 [member2 ...]        | O(1)       |

#### 快速实战

打标签(tag), 可以方便查看标签下的用户, 也可以做交集并集查看共同标签

```bash
sadd user:1:tags tag1 tag2 tag5
sadd user:2:tags tag2 tag3 tag5
...
sadd user:k:tags tar1 tag2 tar4

sadd tag1:users user1 user3
sadd tag2:users user1 user2 user3
...
sadd tagk:users user1 user2
```



### 有序集合类型, 有序的set, 元素不能重复但有序

SortSet 顾名思义, 是一个排好序的Set, 它在Set的基础上增加了一个顺序属性score, 这个属性在添加修改元素时可以指定, 每次指定后, SortSet会自动重新按新的值排序.

SortSet 的内部使用 HashMap 和跳跃表(SkipList)来保证数据的存储和有序, HashMap 里放的是成员到 score 的映射, 而跳跃表里存放的是所有的成员, 排序依据是 HashMap 里存的 score. 

**可以做排行榜应用, 取 TOP N 操作.可以用来做延时任务.最后一个应用就是可以做范围查找.**

#### 结构和命令

| **命令**         | **描述**                                                     | **用法**                                                     | 时间复杂度  |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| ZADD             | 1. 将一个或多个member元素及其score值加入有序集key中<br/>2. 如果member已经是有序集的成员, 那么更新member对应的score并重新插入member保证member在正确的位置上<br/>3. score可以是整数值或双精度浮点数 | ZADD key score1 member1 [[score2 member2] [score3 member3] ...] | O(logN)     |
| ZCARD            | 1. 返回有序集key的元素个数                                   | ZCARD key                                                    | O(1)        |
| ZCOUNT           | 1.  返回有序集key中, score值>=minScore且<=maxScore的成员的数量 | ZCOUNT key minScore maxScore                                 | O(logN + m) |
| ZSCORE           | 1.  返回元素的分数                                           | ZSCORE key member                                            | O(1)        |
| ZRANGE           | 1. 返回有序集key中指定区间内的成员, 成员位置按score从小到大排序<br/>2. 具有相同score值的成员按字典序排列<br/>3. 需要成员按score从大到小排列, 使用ZREVRANGE命令<br/>4. 下标参数start和end都以0为底, 也可以用负数, -1表示最后一个成员, -2表示倒数第二个成员<br/>5. 可通过WITHSCORES选项让成员和它的score值一并返回 | ZRANGE key start end [WITHSCORES]                            | O(logN + m) |
| ZREVRANGE        | 1. 返回有序集key中, 指定区间内的成员.其中成员的位置按score值递减(从大到小)来排列 | ZREVRANGE key start end                                      | O(logN + m) |
| ZRANGEBYSCORE    | 1. 返回有序集key中, 指定分数范围的元素列表                   | ZRANGEBYSCORE key minScore maxScore [WITHSCORES]             | O(logN + m) |
| ZRANK            | 1. 返回有序集key中成员member的排名, 有序集成员按score值从小到大排列<br/>2. 排名以0为底, 即score最小的成员排名为0<br/>3. ZREVRANK命令可将成员按score值从大到小排名 | ZRANK key member                                             |             |
| ZREVRANK         | 1. 得成员按score值递减(从大到小)排列的排名                   |                                                              |             |
| ZREM             | 1. 移除有序集key中的一个或多个成员, 不存在的成员将被忽略<br/>2. 当key存在但不是有序集时, 返回错误 | ZREM key member1 [member2 ...]                               |             |
| ZREMRANGEBYRANK  | 1. 移除有序集key中指定排名区间内的所有成员                   | ZREMRANGEBYRANK key start end                                | O(logN + m) |
| ZREMRANGEBYSCORE | 1. 移除有序集key中, 所有score值>=minScore且<=maxScore之间的成员 | ZREMRANGEBYSCORE key minScore maxScore                       | O(logN + m) |
| ZINCRBY          | 1. 如果key对应的zset中已经存在元素member, 则对member的score属性加指定的值 | ZINCRBY key score member                                     | O(1)        |



## Jedis 客户端

Jedis 是基于 Java 语言的 Redis 客户端

### Jedis 直连

生成一个 Jedis 对象, 这个对象负责和指定 Redis 节点通信

```java
Jedis jedis = new Jedis("127.0.0.1",  6379);
```

jedis 执行 set 操作

```java
jedis.set("hello",  "world");
```

jedis 执行 get 操作, value="world"

```java
String value = jedis.get("hello");
```

Jedis(String host, int port, int connectionTimeout, int soTimeout) 构造函数参数意义

host: Redis 节点的所在机器的 ip

port: Redis 节点的端口

connectionTimeout: 客户端连接超时

soTimeout: 客户端读写超时

### Jedis 连接池配置

初始化 Jedis 连接池, 通常来讲 JedisPool 是单例的

```java
GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
JedisPool jedisPool = new JedisPool(poolConfig, "127.0.0.1", 6379);
```

**资源数配置**

| 参数名     | 含义                          | 默认值 | 使用建议 |
| ---------- | ----------------------------- | ------ | -------- |
| maxTotal   | 资源池最大连接数              | 8      |          |
| maxIdle    | 资源池允许最大空闲连接数      | 8      |          |
| minIdle    | 资源池确保最少空闲连接数      | 0      |          |
| jmxEnabled | 是否开启 jmx 监控, 可用于监控 | true   | 建议开启 |

* maxTotal

    这是一个比较难确定的参数值, 举个例子

    1. 命令平均执行时间 0.1ms = 0.001s
    2. 业务需要 50000QPS
    3. maxTotal 理论值 = 0.001 * 50000 = 50 个, 实际要偏大一些

    **业务希望 Redis 并发量**

    **客户端执行命令时间**

    **Redis 资源: 例如 nodes(应用个数) * maxTotal 是不能超过 redis 的最大连接数(config get maxclients)**

    **资源开销, 例如虽然希望控制空闲连接, 但是不希望因为连接池的频繁释放创建连接造成不必要开销**

* 适合的 maxIdle 和 minIdle

    建议 maxIdle = maxTotal, 假如 maxTotal 是 100, maxIdle 是 50, 当有第 51 个连接时, 就会使用 new Jedis 创建新的连接, 这个过程也是耗费资源的

    建议预热 minIdle, 减少第一次启动后的新连接开销



**借还参数**

| 参数名             | 含义                                                         | 默认值           | 使用建议         |
| ------------------ | ------------------------------------------------------------ | ---------------- | ---------------- |
| blockWhenExhausted | 当资源池用尽后, 调用者是否要等待. 只有当为 true 时, 下面的 maxWaitMillis 才会生效 | true             | 建议使用默认值   |
| maxWaitMillis      | 当资源池连接用尽后, 调用者的最大等待时间(单位为毫秒)         | -1: 表示永不超时 | 不建议使用默认值 |
| testOnBorrow       | 向资源池借用连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |
| testOnReturn       | 向资源池归还连接时是否做连接有效性检测(ping), 无效连接会被移除 | false            | 建议 false       |



## 瑞士军刀 Redis

### 慢查询

#### 生命周期

1. 客户端发送命令
2. 排队
3. 执行命令
4. 返回结果

慢查询一般发生在第 3 阶段

客户端超时不一定慢查询, 但慢查询是客户端超时的一个因素

#### 两个配置

**慢查询是一个先进先出的队列, 队列是固定长度的, 满了之后会出队一个元素, 保存在内存中, 不会持久化**

**slowlog-max-len:** 设置队列长度

**slowlog-log-slower-than:** 慢查询阈值(单位: 微妙), 该值等于 0 记录所有命令, 小于 0 不记录任何命令, 1毫秒等于 1000 微妙

#### 配置方法

1. **默认值**

    config get slowlog-max-len=128

    config get slowlog-log-slower-than=10000

2. 修改配置文件重启(不推荐)

3. 动态配置

    config set slowlog-max-len 1000

    config set slowlog-log-slower-than 1000

#### 三个命令

slowlog get [n]: 获取 n 条慢查询队列

slowlog len: 获取慢查询队列长度

slowlog reset: 清空慢查询队列

#### 运维经验

slowlog-max-len 不要设置过小, 通常设置 1000 左右

slowlog-log-slower-than 不要设置过大, 默认 10ms, 通常设置 1ms = 1000 微秒, 根据业务 qps 来决定

理解命令生命周期, 更容易定位慢在哪里

定期持久化慢查询

### pipeline

如果我们发送 n 条命令, 那么就是 n 次网络时间 + n 次命令时间, 如果使用流水线(pipeline), 会将 n 条命令打包发送给服务端, 服务端会将 n 条结果一次返回, 消耗是 1 次网络时间 + n 次命令时间, 这就是流水线的作用, 减少网络开销

| 命令   | N 个命令操作        | 1 次 pipeline(N 个命令) |
| ------ | ------------------- | ----------------------- |
| 时间   | n 次网络 + n 次命令 | 1 次网络 + n 次命令     |
| 数据量 | 1 条命令            | n 条命令                |

#### 使用 JedisPipeline

没有 pipeline 设置 10000 个 key, 1W hset 花费 50s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for (int i = 0; i < 10000; i++) {
    jedis.hset("hashKey" + i, "field" + i, "value" + i);
}
```

**使用 pipeline 操作**, 拆分 10000 条命令, 执行 100 次, 每次执行 100 条命令, 花费 0.7s

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
for (int i = 0; i < 10000; i++) {
    Pipeline pipeline = jedis.pipelined();
    for (int j = i * 100; j < (i + 1) * 100; j++) {
        pipeline.hset("hashKey" + j, "field" + j, "value" + j);
    }
    pipeline.syncAndReturnAll();
}
```

#### 使用建议

注意每次 pipeline 携带数据量

pipeline 每次只能作用在一个 Redis 节点上

**注意原子性问题, 与 M 命令相比, pipeline 会将命令拆分执行, 不是原子的, 而 M 命令是原子的**

### 发布订阅

### Bitmap

Redis 可以直接操作数据的位数据

### HyperLogLog

### GEO

## Redis 开发运维常见问题

### fork 操作

fork 操作是一个同步操作, 与内存量息息相关, 内存越大, 耗时越长, rdb 和 aof 的异步备份都需要 fork 一份子进程, 这个 fork 的过程就有可能阻塞住 redis 的主线程, 影响 qps

info 命令中有一个 latest_fork_usec 选项可以查看 fork 耗时的微秒数

如何改善 fork

* 优先使用物理机或者高效支持 fork 操作的虚拟化技术
* 控制 Redis 实例最大可用内存: maxmemory, 减少内存可以加快 fork
* 合理配置 Linux 内存分配策略: vm.overcommit_memory=1
* 降低 fork 频率: 例如放宽 AOF 重写自动触发时机, 不必要的全量复制

### 子进程开销和优化

CPU: RDB 和 AOF 文件生成, 属于 CPU 密集型, 我们部署 Redis 时, 不做 CPU 绑定, 不和 CPU 密集型的服务部署在一起

内存: fork 内存开销, copy-on-write 时会占用两份内存, 尽量不要大量写入

硬盘: AOF 和 RDB 文件写入, 可以结合 iostat, iotop 分析, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 no-appendfsync-on-rewrite=yes, 根据写入量使用 SSD 磁盘

### AOF 追加阻塞

主线程会向 AOF 缓冲区写入, 同时 AOF 会开启一个同步线程进行 AOF 同步, 主线程继续向下执行, 对比上次 fsync 的时间, 如果大于 2 秒, 阻塞主线程, 小于 2 秒, 正常执行

<img src="http://www.milky.show/images/redis/redis_64.png" alt="http://www.milky.show/images/redis/redis_64.png" style="zoom:50%;" />

如果发现 Redis 阻塞情况发生, 可以通过 Redis 日志查看是否有 AOF 阻塞: `Asynchronous AOF fsync is takine too long(disk in busy?)`, 也可以通过 top 命令查看 linux 系统的 IO 情况

这种情况一般都是磁盘 IO 太忙导致, 尽量将 Redis 单独部署一台服务器, 不要混用磁盘, 开启 `no-appendfsync-on-rewrite=yes`, 根据写入量使用 SSD 磁盘





## Redis 常见问题

### 无底洞问题

2010 年, Facebook 有了 3000 个 Memcache 节点, 但是发现了一个问题, 加了一个机器后, 性能没能提升, 反而下降了, 因为在集群模式下, 批量操作会随着机器节点数的增加, 时间复杂度而增加, 批量操作的 key 会分散到不同的机器上去执行, 那么这条命令的性能就要等到最慢的那台机器返回才是真正执行完成

**如何优化**

* 命令本身优化: 例如慢查询 keys, hgetall bigkey

* 减少网络通信次数
* 降低接入成本: 例如客户端长连接/连接池, NIO 等

### 缓存穿透

什么是缓存穿透, 它就是指当用户在查询一条数据的时候, 而此时数据库和缓存却没有关于这条数据的任何记录, 而这条数据在缓存中没找到就会向数据库请求获取数据. 它拿不到数据时, 是会一直查询数据库, 这样会对数据库的访问造成很大的压力. 

如:用户查询一个 id = -1 的商品信息, 一般数据库 id 值都是从 1 开始自增, 很明显这条信息是不在数据库中, 当没有信息返回时, 会一直向数据库查询, 给当前数据库的造成很大的访问压力. 

这时候我们要想一想, 该如何解决这个问题呢？o(╥﹏╥)o

一般我们可以想到从缓存开始出发, 想如果我们给缓存设置一个如果当前数据库不存在的信息, 把它缓存成一个空对象, 返回给用户. 

这是一个解决方案, 也就是我们常说的缓存空对象(代码维护简单, 但是效果不是很好). 

Redis 也为我们提供了一种解决方案, 那就是布隆过滤器(代码维护比较复杂, 效果挺好的). 

在流量大时, 可能DB就挂掉了, 要是有人利用不存在的key频繁攻击我们的应用, 这就是漏洞. 

#### 造成缓存穿透的原因

业务自身代码或者数据出现问题

一些恶意攻击, 爬虫等造成大量空命中

#### 如何发现

监控业务的响应时间, 如果业务的响应时间突然变慢, 那么有可能是大量请求打到了存储层

业务本身逻辑问题

相关指标: 总调用数, 缓存层命中数, 存储层命中数

#### 解决方法

##### 缓存空对象

空值做缓存, 再次接收到同样的查询请求时, 若命中缓存并且值为空, 就会直接返回, 不会透传到数据库, 避免缓存击穿, **即缓存层中存了更多的键, 这就需要更多的内存空间, 可以对其设置一个较短的过期时间, 让其自动清除**, 优点是实时性高, 代码维护简单. 当然, 有时恶意袭击者可以猜到我们使用了这种方案, 每次都会使用不同的参数来查询, 这就需要我们对输入的参数进行过滤, 例如, 如果我们使用ID进行查询, 则可以对ID的格式进行分析, 如果不符合产生ID的规则, 就直接拒绝, 或者在ID上放入时间信息, 根据时间信息判断ID是否合法, 或者是否是我们曾经生成的ID, 这样可以拦截一定的无效请求.

<img src="http://www.milky.show/images/redis/redis_81.png" alt="http://www.milky.show/images/redis/redis_81.png" style="zoom: 67%;" />

如果大量不存在的请求过来, 那么这时候缓存岂不是会缓存许多空对象了吗~~~

没错哦！这也是使用缓存空对象会导致的一个问题:如果时间一长这样会导致缓存中存在大量空对象, 这样不仅会占用许多的内存空间, 还会浪费许多资源呀！. 那这有没有什么可以解决的方法呢？我们来想一想:我们可以将这些对象在一段时间之后清理下不久可以了吗 ~

嗯嗯, 没错！在想想 Redis 里是不是给我们提供了有关过期时间的命令呀(*^▽^*), 这样我们可以在设置空对象的时间, 顺便设置一个过期时间, 就可以解决个问题了呀！

```bash
setex key seconds valule:设置键值对的同时指定过期时间(s)
```

在Java 中直接调用 API 操作即可:

```java
redisCache.put(Integer.toString(id), null, 60) //过期时间为 60s
```



##### 布隆过滤器拦截

如果布隆过滤器认为某个键不存在, 那么就不会访问存储层, 适用于数据命中不高, 数据相对固定实时性低(通常是数据集较大)的应用场景, 代码维护较为复杂, 但是缓存空间占用少

我们也可以简单理解为是一个不怎么精确的 set 结构(set 具有去重的效果). 但是有个小问题是:当你使用它的 contains 方法去判断某个对象是否存在时, 它可能会误判. 也就是说布隆过滤器不是特别不精确, 但是只要参数设置的合理, 它的精确度可以控制的相对足够精确, 只会有小小的误判概率(这是可以接受的呀 ~). 当布隆过滤器说某个值存在时, 这个值可能不存在；当它说不存在时, 那就肯定不存在. 

布隆过滤器的特点

1.  一个非常大的二进制位数组(数组中只存在 0 和 1)
2.  拥有若干个哈希函数(Hash Function)
3.  在空间效率和查询效率都非常高
4.  布隆过滤器不会提供删除方法, 在代码维护上比较困难. 

每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数. 所谓无偏就是能够把元素的 hash 值算得比较均匀. 

<img src="http://www.milky.show/images/redis/redis_82.png" alt="http://www.milky.show/images/redis/redis_82.png" style="zoom: 67%;" />

向布隆过滤器中添加 key 时, 会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置, 每个 hash 函数都会算得一个不同的位置. 再把位数组的这几个位置都置为 1 就完成了 add 操作. ( 每一个 key 都通过若干的hash函数映射到一个巨大位数组上, 映射成功后, 会在把位数组上对应的位置改为1. )

**那为什么布隆过滤器会存在误判率呢？**

误判吗？人生哪有不摔跤, 只要锄头挥得好, 照样能挖到. (咳咳咳, 说偏了...)

其实它会误判是如下这个情况:

<img src="http://www.milky.show/images/redis/redis_83.png" alt="http://www.milky.show/images/redis/redis_83.png" style="zoom: 67%;" />

当 key1 和 key2 映射到位数组上的位置为 1 时, 假设这时候来了个 key3, 要查询是不是在里面, 恰好 key3 对应位置也映射到了这之间, 那么布隆过滤器会认为它是存在的, 这时候就会产生误判(因为明明 key3 是不在的). 

O(∩_∩)O哈哈~, 这时候你会问了:如何提高布隆过滤器的准确率呢？

**要提高布隆过滤器的准确率, 就要说到影响它的三个重要因素:**

1.  哈希函数的好坏
2.  存储空间大小
3.  哈希函数个数

hash函数的设计也是一个十分重要的问题, 对于好的hash函数能大大降低布隆过滤器的误判率. 

(这就好比优秀的配件之所以能够运行这么顺畅就在于其内部设计的得当)

同时, 对于一个布隆过滤器来说, 如果其位数组越大的话, 那么每个key通过hash函数映射的位置会变得稀疏许多, 不会那么紧凑, 有利于提高布隆过滤器的准确率. 同时, 对于一个布隆过滤器来说, 如果key通过许多hash函数映射, 那么在位数组上就会有许多位置有标志, 这样当用户查询的时候, 在通过布隆过滤器来找的时候, 误判率也会相应降低. 

#### 如何选择

针对于一些恶意攻击, 攻击带过来的大量 key 是不存在的, 那么我们采用第一种方案就会缓存大量不存在 key 的数据.此时我们采用第一种方案就不合适了, 我们完全可以先对使用第二种方案进行过滤掉这些 key.针对这种 key 异常多, 请求重复率比较低的数据, 我们就没有必要进行缓存, 使用第二种方案直接过滤掉.而对于空数据的 key 有限的, 重复率比较高的, 我们则可以采用第一种方式进行缓存.



### 缓存击穿

缓存击穿是指有某个key经常被查询, 经常被用户特殊关怀, 用户非常 love 它 (*^▽^*), 也就类比“熟客” 或者 一个key经常不被访问. 但是这时候, 如果这个key在缓存的过期时间失效的时候或者这是个冷门key时, 这时候突然有大量有关这个key的访问请求, 这样会导致大并发请求直接穿透缓存, 请求数据库, 瞬间对数据库的访问压力增大, 这个和缓存雪崩的区别在于这里针对某一key缓存, 前者则是很多key. 

**归纳起来:造成缓存击穿的原因有两个. **

(1)一个“冷门”key, 突然被大量用户请求访问. 

(2)一个“热门”key, 在缓存中时间恰好过期, 这时有大量用户来进行访问. 

<img src="http://www.milky.show/images/redis/redis_84.png" alt="http://www.milky.show/images/redis/redis_84.png" style="zoom: 67%;" />

对于缓存击穿的问题:我们常用的解决方案是加锁. 对于key过期的时候, 当key要查询数据库的时候加上一把锁, 这时只能让第一个请求进行查询数据库, 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

如果我们是在单机环境下:直接使用常用的锁即可(如:Lock, Synchronized等), 在分布式环境下我们可以使用分布式锁, 如:基于数据库, 基于Redis或者zookeeper 的分布式锁. 

<img src="http://www.milky.show/images/redis/redis_85.png" alt="http://www.milky.show/images/redis/redis_85.png" style="zoom: 67%;" />



#### 解决方法

**永久缓存**

可以将爆款的缓存失效时间设置为永久. 

**互斥锁**

利用互斥锁, 缓存失效的时候, 先去获得锁, 得到锁了, 再去请求数据库. 没得到锁, 则休眠一段时间重试. 然后把从数据库中查询到的值存储到缓存中, 对于剩下的相同的key, 可以直接从缓存中获取即可. 

### 缓存雪崩

缓存雪崩是指在某一个时间段内, 缓存集中过期失效, 如果这个时间段内有大量请求, 而查询数据量巨大, 所有的请求都会达到存储层, 存储层的调用量会暴增, 请求全部转发到DB, DB瞬时压力过重雪崩. 

1.  Redis突然宕机
2.  大部分数据失效

#### 解决方法

**redis高可用**

redis有可能挂掉, 多增加几台redis实例, (一主多从或者多主多从), 这样一台挂掉之后其他的还可以继续工作, 其实就是搭建的集群. 

**限流降级**

在缓存失效后, 通过加锁或者队列来控制读数据库写缓存的线程数量, 对某个key只允许一个线程查询数据和写缓存, 其他线程等待. 

**数据预热**

数据加热的含义就是在正式部署之前, 我先把可能的数据先预先访问一遍, 这样部分可能大量访问的数据就会加载到缓存中. 在即将发生大并发访问前手动触发加载缓存不同的key. 

##### 设置不同的失效时间

对不同的数据使用不同的失效时间, 甚至对相同的数据, 不同的请求使用不同的失效时间, 例如, 我们要缓存 user 数据, 会对每个用户的数据设置不同的缓存过期时间, 可以定义一个基础时间, 假设10秒, 然后加上一个两秒以内的随机数, 过期时间为10～12秒, 就会避免缓存雪崩. 避免同一时间缓存全部失效

**双缓存**

缓存A和B, 比如A的失效时间是20分钟, B不失效. 比如从A中没读到, 就去B中读, 然后异步起一个线程同步到A. 



### Redis, MySQL 双写一致性问题

最经典的缓存+数据库读写的模式, 就是 Cache Aside Pattern.读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.更新的时候, 先更新数据库, 然后再删除缓存.

**为什么是删除缓存, 而不是更新缓存？**

原因很简单, 很多时候, 在复杂点的缓存场景, 缓存不单单是数据库中直接取出来的值.比如可能更新了某个表的一个字段, 然后其对应的缓存, 是需要查询另外两个表的数据并进行运算, 才能计算出缓存最新的值的.

另外更新缓存的代价有时候是很高的. 是不是说, 每次修改数据库的时候, 都一定要将其对应的缓存更新一份？也许有的场景是这样, 但是对于比较复杂的缓存数据计算的场景, 就不是这样了.

如果你频繁修改一个缓存涉及的多个表, 缓存也频繁更新.但是问题在于, 这个缓存到底会不会被频繁访问到？

举个栗子, 一个缓存涉及的表的字段, 在 1 分钟内就修改了 20 次, 或者是 100 次, 那么缓存更新 20 次, 100 次; 但是这个缓存在 1 分钟内只被读取了 1 次, 有大量的冷数据.实际上, 如果你只是删除缓存的话, 那么在 1 分钟内, 这个缓存不过就重新计算一次而已, 开销大幅度降低, 用到缓存才去算缓存.

其实删除缓存, 而不是更新缓存, 就是一个 lazy 计算的思想, 不要每次都重新做复杂的计算, 不管它会不会用到, 而是让它到需要被使用的时候再重新计算.

像 mybatis, hibernate 都有懒加载思想.查询一个部门, 部门带了一个员工的 list, 没有必要说每次查询部门, 都把里面的 1000 个员工的数据也同时查出来.80% 的情况, 查这个部门, 就只是要访问这个部门的信息就可以了.先查部门, 同时要访问里面的员工, 那么这个时候只有在你要访问里面的员工的时候, 才会去数据库里面查询 1000 个员工.

#### 先更新数据库, 后更新缓存

<img src="http://www.milky.show/images/redis/redis_74.png" alt="http://www.milky.show/images/redis/redis_74.png" style="zoom: 67%;" />

由上面流程图可知道, **请求 A 更新缓存应该比请求 B 更新缓存早才对, 但是因为网络等原因, B 却比 A 更早更新了缓存.**

这就导致了**脏数据**, 因此不考虑 先更新数据库, 后更新缓存 这个更新策略.



#### 先删除缓存, 在更新数据库

<img src="http://www.milky.show/images/redis/redis_75.png" alt="http://www.milky.show/images/redis/redis_75.png" style="zoom:67%;" />

如果同时有一个**请求 A 进行更新操作, 另一个请求 B 进行查询操作**.

**就会导致不一致的情形出现**.而且, 如果不采用给缓存设置过期时间策略, 该数据永远都是脏数据.



#### 先更新数据库, 在删除缓存

因为可能存在删除缓存失败的问题, 提供一个补偿措施即可, 例如利用消息队列.

FaceBook 也是采用这种方式.

当然, 这种方式也会产生数据不一致问题.

1.  缓存刚好失效

2.  请求A查询数据库, 得一个旧值

3.  请求B将新值写入数据库

4.  请求B删除缓存

5.  请求A将查到的旧值写入缓存



#### 小结

一致性问题是分布式常见问题, 还可以再分为最终一致性和强一致性.数据库和缓存双写, 就必然会存在不一致的问题.答这个问题, 先明白一个前提.就是如果对数据有强一致性要求, 不能放缓存.我们所做的一切, 只能保证最终一致性.另外, 我们所做的方案其实从根本上来说, 只能说降低不一致发生的概率, 无法完全避免.**因此, 有强一致性要求的数据, 不能放缓存.**





### 热点 key 重建优化

#### 三个目标

减少重建缓存的次数

数据尽可能一致

减少潜在危险

#### 两个解决方法

**互斥锁(mutex key)**

```java
String get(String key) {
	String value = redis.get(key);
    if(value == null) {
        String mutexKey = "mutexKey:" + key;
        if(redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            value = db.get(key);
            redis.set(key,  value);
            redis.delete(mutexKey);
        } else {
            // 其他线程休息 50 毫秒后重试
            Thread.sleep(50);
            get(key);
        }
    }
    return value;
}
```

**永不过期**

* 缓存层面: 没有设置过期使用(没有使用 expire)
* 功能层面: 为每个 value 添加逻辑过期时间, 但发现超过逻辑过期时间后, 会使用单独的线程去构建缓存

```java
String get(final String key) {
    V v = redis.get(key);
    String value = v.getValue();
    long logicTimeout = v.getValue();
    if (logicTimeout >= System.currentTimeMillis) {
        String mutexKey = "mutexKey:" + key;
        if (redis.set(mutexKey,  "1",  "ex 180",  "nx")) {
            // 异步更新后台执行
            threadPool.execute(new Runnable(){
                public void run() {
                    String dbValue = db.get(key);
                    redis.set(key,  (dbValue,  newLoginTimeout));
                    redis.delete(keyMutex);
                }
            });
        }
    }
    return value;
}
```

|   方案   |           优点            |                       缺点                       |
| :------: | :-----------------------: | :----------------------------------------------: |
|  互斥锁  |   思路简单, 保持一致性    |          代码复杂度增加, 存在死锁的风险          |
| 永不过期 | 基本杜绝热点 key 重建问题 | 不保证一致性, 逻辑过期时间增加维护成本和内存成本 |



## Redis 常见应用

### 使用 Redis 实现分布式锁

和 Memcached 的方式类似, 利用 Redis 的 setnx 命令.此命令同样是原子性操作, 只有在 key 不存在的情况下, 才能 set 成功.(setnx 命令并不完善, 后续会介绍替代方案)

1. 加锁

    最简单的方法是使用 setnx 命令, key 是锁的唯一标识, 按业务来决定命名.比如想要给一种商品的秒杀活动加锁, 可以给 key 命名为 “lock_sale_商品ID”, 而 value 设置成什么呢？我们可以姑且设置成 1.加锁的伪代码如下:     

    ```shell
    setnx(key, 1)
    ```

    当一个线程执行 setnx 返回 1, 说明 key 原本不存在, 该线程成功得到了锁; 当一个线程执行 setnx 返回 0, 说明 key 已经存在, 该线程抢锁失败.

2. 解锁

    有加锁就得有解锁. 当得到锁的线程执行完任务, 需要释放锁, 以便其他线程可以进入.释放锁的最简单方式是执行 del 指令, 伪代码如下: 

        del(key)

    释放锁之后, 其他线程就可以继续执行setnx命令来获得锁

3. 锁超时

    锁超时是什么意思呢？如果一个得到锁的线程在执行任务的过程中挂掉, 来不及显式地释放锁, 这块资源将会永远被锁住, 别的线程再也别想进来.所以, setnx的key必须设置一个超时时间, 以保证即使没有被显式释放, 这把锁也要在一定时间后自动释放.setnx不支持超时参数, 所以需要额外的指令, 伪代码如下: 

        expire(key, 30)

    综合起来, 我们分布式锁实现的第一版伪代码如下: 

    ```java
    if(setnx(key,  1) == 1){
        expire(key,  30)
        try {
            do something ......
        } finally {
            del(key)
        }
    }
    ```

4. 第一版存在的问题

    *   setnx 和 expire 的非原子性, 当 A 线程得到了锁, 还未来得及设置超时时间就挂掉了, 会导致锁没有超时时间, 在Redis2.6.12 以上版本增加了 set(key, 1, 30, NX) 取代了 setnx

    *   del 导致误删, 假如 A 线程得到了锁, 并且设置 30 秒超时, 如果某些原因导致了 A 超过了 30 秒, 自动释放锁, B 线程获得了锁, 当 A 运行完成后, 删除了锁, 直接删除的是 B 线程的锁, 可以再 del 之前判断一下这个锁是不是自己的, 即将 value 设置成线程 id, 每次删除前判断一下是不是自己的锁, 这样实际上有并发问题

    *   还是刚才第二点所描述的场景, 虽然我们避免了线程 A 误删掉 key 的情况, 但是同一时间有 A, B 两个线程在访问代码块, 仍然是不完美的.怎么办呢？我们可以让获得锁的线程开启一个守护线程, 用来给快要过期的锁“续航”.这样就避免了 A 线程执行时间过长, 导致锁自动释放的问题, 假设锁是 30 秒, 让守护线程 29 秒时给锁续命 20 秒, 当 A 线程销毁时, 守护线程也就销毁了 

### 基于 Redis 的分布式布隆过滤器

#### 引出布隆过滤器

现有 50 亿个电话号码, 现有 10 万个电话号码, 要**快速准备**判断这些电话号码是否已经存在

1. 通过数据库查询: 实现**快速**有点难
2. 数据预放在集合中: 50 亿 * 8 字节 ~ 40GB(内存浪费或不够)
3. hyperloglog: **准确**有点难

类似的还有垃圾邮件过滤, 文字处理软件的错误单词检测, 网络爬虫重复 url 检测, Hbase行过滤

#### 布隆过滤器原理

1970年伯顿.布隆提出, 用很小的空间解决上述问题

实现原理: 一个很长的二进制向量和若干个哈希函数

参数: m 个二进制向量, n 个预备数据, k 个 hash 函数

构建布隆过滤器: n 个预备数据走一遍上面过程

判断元素存在: 走一边上面过程: 如果都是 1, 则表明存在, 反之不存在

#### 布隆过滤器的误差率

肯定存在误差: 恰好都命中了

直观因素: m/n 的比率, hash 函数的个数

#### 本地布隆过滤器

现有库: Guava

本地布隆过滤器的问题

1. 容量受限制
2. 多个应用存在多个布隆过滤器, 多个布隆过滤器之间的同步问题

#### Redis 单机布隆过滤器

基于 Redis 的位图实现

定义布隆过滤器构造函数: m, n, k, 误差概率

定义布隆过滤器操作函数: add 和 contain

封装 Redis 位图操作

开发测试样例

#### Redis 分布式布隆过滤器

多个布隆过滤器: 二次路由, 解决容量受限的问题



## Redis 开发规范

### Key 设计

可读性和可管理型: 以业务名(或数据库名)为前缀(防止 key 冲突), 用冒号分割, 比如业务名:表名:id, 如 ugc:video:1

简洁性: 保证语义的前提下, 控制 key 的长度, 当 key 较多时, 内存占用也不容忽略, 如 `user:{uid}:friends:messages:{mid}` 简化为 `u:{uid}:fr:m:{mid}`

**不要包含特殊字符: 反例, 包含空格, 换行, 单双引号以及其他转义字符**

**Redis3 embstr 测试**

| key-value 个数 | 39 字节 | 40 字节 |
| -------------- | ------- | ------- |
| 10 万          | 15.69M  | 18.75M  |
| 100 万         | 146.29M | 176.81M |
| 1000 万        | 1.47G   | 1.77G   |
| 1 亿           | 14.6G   | 17.7G   |

### Value 设计

#### 拒绝 bigkey

string 类型控制在 10KB 以内, 10240 个英文, 3413 个中文

hash, list, set, zset 元素个数不要超过 5000

redis-cli \-\-bigkeys 查看 bigkey

#### 选择合适的数据结构

实体类型(要合理控制和使用数据结构内存编码优化配置, 例如ziplist, 但也要注意节省内存和性能之间的平衡)

#### 过期设计

控制 key 的生命周期, redis不是垃圾桶

object idle time 可以找到垃圾 key-value

过期时间不宜集中: 缓存穿透和雪崩等问题

### 命令使用技巧

O(N)以上命令关注 N 的数量: hgetall, lrange, smembers, zrang, sinter 等并非不能使用, 但是需要明确 N 的值. 有遍历的需求可以使用 hscan, sscan, zscan 代替

禁用命令: 线上禁用 keys, flushall, flushdb 等, 通过 redis 的 rename 机制禁掉命令, 或者使用 scan 的方式渐进式处理

合理使用 select: redis 的多数据库较弱, 使用数字进行区分, 很多客户端支持较差, 同时多业务用多数据库实际还是单线程处理

Redis 事务功能较弱, 不建议使用: Redis 的事务功能较弱, 不支持回滚 

Redis 集群版在使用 Lua 上有特殊要求

必要情况下使用 monitor 命令时, 要注意不要长时间使用



### Java 客户端优化

避免多个应用使用一个Redis实例: 不相干的业务拆分, 公共数据做服务化.

使用带有连接池的数据库, 可以有效控制连接, 同时提高效率

高并发下建议客户端添加熔断功能(例如netflix hystrix)

设置合理的密码, 如有必要可以使用SSL加密访问

根据自身业务类型, 选好maxmemory-policy(最大内存淘汰策略), 设置好过期时间.

默认策略是volatile-lru, 即超过最大内存后, 在过期键中使用lru算法进行key的剔除, 保证不过期数据不被删除, 但是可能会出现OOM问题.

### 连接池参数优化

#### 空闲连接参数

| 序号 | 参数名                        | 含义                                                         | 默认值               | 使用建议                                                     |
| ---- | ----------------------------- | ------------------------------------------------------------ | -------------------- | ------------------------------------------------------------ |
| 1    | testWhileIdle                 | 是否开启空闲资源监测                                         | false                | true                                                         |
| 2    | timeBetweenEvictionRunsMillis | 空闲资源的监测周期(单位为毫秒)                               | -1: 不检测           | 建议设置, 周期自行选择, 也可以默认也可以使用下面 JedisPoolConfig 中的配置 |
| 3    | minEvictableIdleTimeMillis    | 资源池中资源最小空闲时间(单位为毫秒), 达到此值后空闲资源将被移除 | 1000 60 30 = 30 分钟 | 可以根据自身业务决定, 大部分默认即可, 也可以考虑使用下面 JedisPoolConfig 中的配置 |
| 4    | numTestsPerEvicationRun       | 做空闲资源监测时, 每次的采样数                               | 3                    | 可以根据自身应用连接数进行微调, 如设置-1, 就是对所有连接做控线检测 |

#### 如何预估最大连接池

maxIdle 接近 maxTotal 即可

maxTotal 考虑业务希望 Redis 并发量, 客户端执行命令时间, node(应用个数) * maxTotal 不能超过 Redis 最大连接数



### 删除bigkey

**非字符串的 bigkey, 不要使用 del 删除, 使用 hscan, sscan, zscan 方式渐进式删除, 同时要注意防止 bigkey 过期时间自动删除问题(例如一个 200 万的 zset 设置 1 小时过期, 会触发 del 操作, 造成阻塞, 而且该操作不会出现在慢查询中(latency可查)), 查找方法和删除方法**

Hash 删除: hscan + hdel

```java
public void delBigHash(String host,  int port,  String password,  String bigHashKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Entry<String,  String>> scanResult = jedis.hscan(bigHashKey,  cursor,  scanParams);
        List<Entry<String,  String>> entryList = scanResult.getResult();
        if (entryList != null && !entryList.isEmpty()) {
            for (Entry<String,  String> entry : entryList) {
                jedis.hdel(bigHashKey,  entry.getKey());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigHashKey);
}
```

List 删除: ltrim

```java
public void delBigList(String host,  int port,  String password,  String bigListKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    long llen = jedis.llen(bigListKey);
    int counter = 0;
    int left = 100;
    while (counter < llen) {
        //每次从左侧截掉100个
        jedis.ltrim(bigListKey,  left,  llen);
        counter += left;
    }
    //最终删除key
    jedis.del(bigListKey);
}
```

Set 删除: sscan + srem

```java
public void delBigSet(String host,  int port,  String password,  String bigSetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<String> scanResult = jedis.sscan(bigSetKey,  cursor,  scanParams);
        List<String> memberList = scanResult.getResult();
        if (memberList != null && !memberList.isEmpty()) {
            for (String member : memberList) {
                jedis.srem(bigSetKey,  member);
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigSetKey);
}
```

SortedSet 删除: zscan + zrem

```java
public void delBigZset(String host,  int port,  String password,  String bigZsetKey) {
    Jedis jedis = new Jedis(host,  port);
    if (password != null && !"".equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = "0";
    do {
        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey,  cursor,  scanParams);
        List<Tuple> tupleList = scanResult.getResult();
        if (tupleList != null && !tupleList.isEmpty()) {
            for (Tuple tuple : tupleList) {
                jedis.zrem(bigZsetKey,  tuple.getElement());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!"0".equals(cursor));

    //删除bigkey
    jedis.del(bigZsetKey);
}
```



## Redis 内存优化

### 内存消耗

#### 内存使用统计

| 属性名                  | 属性说明                                               |
| ----------------------- | ------------------------------------------------------ |
| used_memory             | Redis 分配器分配的内存量, 也就是实际存储数据的内存总量 |
| used_memory_human       | 以可读格式返回 Redis 使用的内存总量                    |
| used_memory_rss         | 从操作系统的角度, Redis 进程只用的总物理内存           |
| used_memory_peak        | 内存分配器分配的最大内存, 代表 used_memory 的历史峰值  |
| used_memory_peak_human  | 以可读的格式显示内存消耗峰值                           |
| used_memory_lua         | Lua 引擎所消耗的内存                                   |
| mem_fragmentation_ratio | used_memory_rss/used_memory 比值, 表示内存碎片率       |
| mem_allocator           | Redis 所使用的内存分配器, 默认 jemalloc                |

#### 内存消耗划分

used_memory: 自身内存, 对象内存, 缓冲内存, Lua 内存

used_memory_rss-used_memory: 内存碎片

<img src="http://www.milky.show/images/redis/redis_73.png" alt="http://www.milky.show/images/redis/redis_73.png" style="zoom: 33%;" />

输入缓冲区: 客户端发送命令, 会将命令放到输入缓冲区, 最大 1GB, 超过后会强制断开连接, 不可动态设置

输出缓冲区: 对应的配置骨子额是 `client-output-buffer-limie <class> <hard limit> <soft limit> <soft seconds>`

* \<class\>: 客户端类型, 分为三种(a)normal: 普通客户端 (b)slave: 从节点用于复制, 伪装成客户端 (c)pubsub: 发布订阅客户端

* \<hard limit\>: 如果客户端使用的输出缓冲区大于\<hard limit\>, 客户端会被立即关闭
* \<soft limit\>和\<soft seconds\>: 如果客户端使用的输出缓冲区超过了\<soft limit\>并且持续了\<soft limit\>秒, 客户端会被立即关闭

普通客户端缓冲区: `client-output-buffer-limit normal 0 0 0`, 没有限制客户端缓冲, 防止大的命令或者 monitor

slave 客户端缓冲区: `client-output-buffer-limit slave 256mb 64mb 60`, 主从延迟较高, 或者从节点过多, 建议设置较大, 从节点不要超过 2 个

pubsub 客户端: `client-output-buffer-limit pubsub 32mb 8mb 60`, 不是一个主流的使用方法

缓冲内存: 此部分内存独享, 考虑不分肤质, 默认 1MB, 可以设置更大

AOF 缓冲区: AOF 的缓冲区, 没有容量限制

### 内存管理

#### 设置内存上线

定义实例最大内存, 便于管理机器内存, 一般要预留 30%, config set maxmemory 6GB

#### 内存回收策略

删除过期键值

* 惰性删除: 访问 key -> expired ditc -> del key
* 定时删除: 每秒运行 10 次, 采样删除

超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制

* noeviction: 默认策略, 不会删除任何数据, 拒绝写入操作并返回客户端错误信息
* volatile-lru: 根据 lru 算法删除设置了超时属性(expire)的键, 直到腾出足够空间为止, 如果没有可删除的键对象, 回退到 noeviction 策略

* volatile-random: 随机删除过期键, 直到腾出足够空间为止
* volatile-ttl: 根据键值对象的 ttl 属性, 删除最近将要过期数据, 如果没有, 回退到 noeviction 策略

* allkeys-lru: 根据 lru 算法删除键, 不管数据有没有设置超时属性, 直到腾出足够空间为止
* allkeys-random: 随机删除所有键, 直到腾出足够空间为止





## Redis 的过期策略

### Redis 的 Key 过期策略

我们都知道, Redis 是 key-value 数据库, 我们可以设置 Redis 中缓存的 key 的过期时间. Redis 的过期策略就是指当 Redis 中缓存的key 过期了, Redis 如何处理.

过期策略通常有以下三种: 

- 定时过期: 每个设置过期时间的 key 都需要创建一个定时器, 到过期时间就会立即清除.该策略可以立即清除过期的数据, 对内存很友好; **但是会占用大量的CPU资源去处理过期的数据, 从而影响缓存的响应时间和吞吐量.**
- 惰性过期: 只有当访问一个 key 时, 才会判断该 key 是否已过期, 过期则清除.该策略可以最大化地节省 CPU 资源, 却对内存非常不友好. 极端情况可能出现大量的过期 key 没有再次被访问, 从而不会被清除, 占用大量内存.
- 定期过期: **Redis 默认每隔 100ms** 会随机抽取进行检查一定数量的数据库的 expires 字典中的 key, 并清除其中已过期的 key.该策略是前两者的一个折中方案.通过调整定时扫描的时间间隔和每次扫描的限定耗时, 可以在不同情况下使得 CPU 和内存资源达到最优的平衡效果.(expires 字典会保存所有设置了过期时间的 key 的过期时间数据, 其中 key 是指向键空间中的某个键的指针, value 是该键的毫秒精度的 UNIX 时间戳表示的过期时间. 键空间是指该 Redis 集群中保存的所有键)
    1. Redis配置项hz定义了serverCron任务的执行周期, 默认为10, 即CPU空闲时每秒执行10次
    2. 每次过期key清理的时间不超过CPU时间的25%, 即若hz=1, 则一次清理时间最大为250ms, 若hz=10, 则一次清理时间最大为25ms
    3. 清理时依次遍历所有的db
    4. 从db中随机取20个key, 判断是否过期, 若过期, 则逐出
    5. 若有5个以上key过期, 则重复步骤4, 否则遍历下一个db
    6. 在清理过程中, 若达到了25%CPU时间, 退出清理过程

**Redis采用的是定期删除+惰性删除策略**

* 如果定期删除没删除key.然后你也没即时去请求key, 也就是说惰性删除也没生效.这样, redis的内存会越来越高.那么就应该采用内存淘汰机制.

    在redis.conf中有一行配置

    ```yaml
    # maxmemory-policy volatile-lru
    ```

    该配置就是配内存淘汰策略的

### Redis 的内存淘汰策略

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时, 怎么处理需要新写入且需要申请额外空间的数据. 超过 maxmemory 后触发响应策略, 由 maxmemory-policy 控制.

- noeviction(默认): 当内存不足以容纳新写入数据时, 新写入操作会报错, 读和删除可继续. **应该没人用吧**
- allkeys-lru: 当内存不足以容纳新写入数据时, 在键空间中, 移除最近最少使用的 key. **推荐使用, 目前项目在用这种**
- allkeys-random: 当内存不足以容纳新写入数据时, 在键空间中, 随机移除某个 key. **你不删最少使用 Key, 去随机删**
- volatile-lru: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 移除最近最少使用的key. **这种情况一般是把redis既当缓存, 又做持久化存储的时候才用**
- volatile-random: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 随机移除某个key. **依然不推荐**
- volatile-ttl: 当内存不足以容纳新写入数据时, 在设置了过期时间的键空间中, 有更早过期时间的key优先移除. **不推荐**

**如果没有设置 expire 的 key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致.**

#### Redis LRU 近似算法

Redis 使用的是一种近似 LRU 算法: 

1. key增加最近访问时间戳字段

2. 选取一定数量的key(默认5, server.maxmemory_samples进行配置), 比较最近访问时间.按照LRU算法淘汰key.

当 Redis 执行写操作时, 发现内存超出 maxmemory, 就会执行一次 LRU 淘汰算法.

注意: maxmemory_samples的值越大, Redis的近似LRU算法就越接近于严格LRU算法(队列结构重排, 批量非热点数据缓存垃圾), 但是相应消耗也变高, 对性能有一定影响, 样本值默认为5.



## Redis 中使用密码

Redis默认配置是不需要密码认证的, 也就是说只要连接的Redis服务器的host和port正确, 就可以连接使用.这在安全性上会有一定的问题, 所以需要启用Redis的认证密码, 增加Redis服务器的安全性.

1. 修改配置文件

    Redis的配置文件默认在/etc/redis.conf, 找到如下行: 

    \#requirepass foobared

    去掉前面的注释, 并修改为所需要的密码: 

    requirepass myPassword (其中myPassword就是要设置的密码)

2. 启动redis服务

3. 登录验证

    设置Redis认证密码后, 客户端登录时需要使用-a参数输入认证密码, 不添加该参数虽然也可以登录成功, 但是没有任何操作权限.如下: 

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379
    127.0.0.1:6379> keys *
    (error) NOAUTH Authentication required.
    ```

    使用密码认证登录, 并验证操作权限

    ```bash
    $ ./redis-cli -h 127.0.0.1 -p 6379 -a myPassword
    127.0.0.1:6379> config get requirepass
    1) "requirepass"
    2) "myPassword"
    ```

4. 在Redis集群中使用认证密码

    如果Redis服务器, 使用了集群.除了在master中配置密码外, 也需要在slave中进行相应配置.在slave的配置文件中找到如下行, 去掉注释并修改与master相同的密码即可: 

    ```
    # masterauth master-password    
    ```



## Redis 选型

### **复杂数据结构, 选择redis更合适**

value是哈希, 列表, 集合, 有序集合这类复杂的数据结构时, 会选择redis, 因为mc无法满足这些需求.

最典型的场景, 用户订单列表, 用户消息, 帖子评论列表等.



### **持久化, 选择redis更合适**

mc无法满足持久化的需求, 只得选择redis.

但是, 这里要提醒的是, **真的使用对了redis的持久化功能么？**

千万不要把redis当作数据库用: 

* redis 的定期快照不能保证数据不丢失; 

* redis 的 AOF 会降低效率, 并且不能支持太大的数据量; 

不要期望 redis 做固化存储会比 mysql 做得好, 不同的工具做各自擅长的事情, 把 redis 当作数据库用, 这样的设计八成是错误的.



**缓存场景, 开启固化功能, 有什么利弊？**

如果只是缓存场景, 数据存放在数据库, 缓存在 redis, 此时如果开启固化功能: 

**优点是**, redis 挂了再重启, 内存里能够快速恢复热数据, 不会瞬时将压力压到数据库上, 没有一个cache预热的过程.

**缺点是**, 在 redis 挂了的过程中, 如果数据库中有数据的修改, 可能导致redis重启后, 数据库与redis的数据不一致.

因此, 只读场景, 或者允许一些不一致的业务场景, 可以尝试开启redis的固化功能.

### **高可用, 选择redis更合适**

redis 天然支持集群功能, 可以实现主动复制, 读写分离.

redis 官方也提供了 sentinel 集群管理工具, 能够实现主从服务监控, 故障自动转移, 这一切, 对于客户端都是透明的, 无需程序改动, 也无需人工介入.

***画外音: memcache, 要想要实现高可用, 需要进行二次开发, 例如客户端的双读双写, 或者服务端的集群同步.***

但是, 这里要提醒的是, **大部分业务场景, 缓存真的需要高可用么？**

* 缓存场景, 很多时候, 是允许cache miss

* 缓存挂了, 很多时候可以通过DB读取数据

所以, 需要认真剖析业务场景, 高可用, 是否真的是对缓存的主要需求？

***画外音: 即时通讯业务中, 用户的在线状态, 就有高可用需求.***

 

### 存储的内容比较大, 选择 redis 更合适

memcache 的 value 存储, 最大为 1 M, 如果存储的 value 很大, 只能使用 redis.

当然, redis 与 memcache 相比, 由于底层实现机制的差异, **也有一些“劣势”的情况.**



**情况一: 由于内存分配机制的差异, redis 可能导致内存碎片**

memcache 使用预分配内存池的方式管理内存, 能够省去内存分配时间.

redis 则是临时申请空间, 可能导致碎片.

从这一点上, mc 会更快一些.

 

**情况二: 由于虚拟内存使用的差异, redis 可能会刷盘影响性能**

memcache 把所有的数据存储在物理内存里.

redis 有自己的 VM 机制, 理论上能够存储比物理内存更多的数据, 当数据超量时, 会引发 swap, 把冷数据刷到磁盘上.

从这一点上, 数据量大时, mc 会更快一些.

***画外音: 新版本 redis 已经优化.***

 

**情况三: 由于网络模型的差异, redis 可能会因为 CPU 计算影响 IO 调度**

memcache 使用非阻塞 IO 复用模型, redis 也是使用非阻塞 IO 复用模型.

但由于 redis 还提供一些非 KV 存储之外的排序, 聚合功能, 在执行这些功能时, 复杂的 CPU 计算, 会阻塞整个 IO 调度.

从这一点上, 由于 redis 提供的功能较多, mc 会更快一些.

 

**情况四: 由于线程模型的差异, redis 难以利用多核特效提升性能**

memcache 使用多线程, 主线程监听, worker 子线程接受请求, 执行读写, 这个过程中, 可能存在锁冲突.

redis 使用单线程, 虽无锁冲突, 但难以利用多核的特性提升整体吞吐量.

从这一点上, mc 会快一些.



**情况五: 由于缺乏 auto-sharding, redis 只能手动水平扩展**

不管是 redis 还是 memcache, 服务端集群没有天然支持水平扩展, 需要在客户端进行分片, 这其实对调用方并不友好.如果能服务端集群能够支持水平扩展, 会更完美一些.



## SCAN 命令

**SCAN [key] cursor [MATCH pattern] [COUNT count]**

SCAN 命令及其相关的 SSCAN 命令,  HSCAN 命令和 ZSCAN 命令都用于增量地迭代(incrementally iterate)一集元素(a collection of elements):

* SCAN 命令用于迭代当前数据库中的所有数据库键.

* SSCAN 命令用于迭代集合键中的元素.

* HSCAN 命令用于迭代哈希键中的键值对.

* ZSCAN 命令用于迭代有序集合中的元素(包括元素成员和元素分值).

以上列出的四个命令都支持增量式迭代, 它们每次执行都只会返回少量元素, 所以这些命令可以用于生产环境, 而不会出现像 KEYS 命令,  SMEMBERS 命令带来的问题 —— 当 KEYS 命令被用于处理一个大的数据库时, 又或者 SMEMBERS 命令被用于处理一个大的集合键时, 它们可能会阻塞服务器达数秒之久.

不过, 增量式迭代命令也不是没有缺点的:  举个例子, 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素, 但是对于 SCAN 这类增量式迭代命令来说, 因为在对键进行增量式迭代的过程中, 键可能会被修改, 所以增量式迭代命令只能对被返回的元素提供有限的保证 (offer limited guarantees about the returned elements).

**需要注意的是:**

* SSCAN 命令,  HSCAN 命令和 ZSCAN 命令的第一个参数总是一个数据库键.

* 而 SCAN 命令则不需要在第一个参数提供任何数据库键, 因为它迭代的是当前数据库中的所有数据库键.

### SCAN 命令基本用法

SCAN 命令是一个基于游标的迭代器(cursor based iterator):  SCAN 命令每次被调用之后, 都会向用户返回一个新的游标, 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数, 以此来延续之前的迭代过程.

当 SCAN 命令的游标参数被设置为 0 时, 服务器将开始一次新的迭代, 而当服务器向用户返回值为 0 的游标时, 表示迭代已结束.

首先使用 `keys *` 可以看到数据库中一共有19条数据, key* 共14条, akey\* 共5条

```bash
127.0.0.1:6379> keys *
 1) "key13"
 2) "key7"
 3) "akey5"
 4) "key11"
 5) "key12"
 6) "key14"
 7) "key6"
 8) "key2"
 9) "akey3"
10) "key3"
11) "key9"
12) "key10"
13) "key1"
14) "akey4"
15) "key5"
16) "akey2"
17) "akey1"
18) "key4"
19) "key8"
```

使用 `scan` 命令迭代过程如下:

```bash
127.0.0.1:6379> scan 0
1) "30"
2)  1) "key13"
    2) "key3"
    3) "key4"
    4) "key11"
    5) "key12"
    6) "akey1"
    7) "akey5"
    8) "key1"
    9) "key2"
   10) "akey3"
127.0.0.1:6379> scan 30
1) "0"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
   6) "key14"
   7) "akey4"
   8) "key5"
   9) "akey2"
127.0.0.1:6379>
```

在上面这个例子中, 第一次迭代使用 0 作为游标, 表示开始一次新的迭代.

第二次迭代使用的是第一次迭代时返回的游标, 也即是命令回复第一个元素的值 —— 30 .

从上面的示例可以看到, SCAN 命令的回复是一个包含两个元素的数组, 第一个数组元素是用于进行下一次迭代的新游标, 而第二个数组元素则是一个数组, 这个数组中包含了所有被迭代的元素.

在第二次调用 SCAN 命令时, 命令返回了游标 0 , 这表示迭代已经结束, 整个数据集(collection)已经被完整遍历过了.

以 0 作为游标开始一次新的迭代, 一直调用 SCAN 命令, 直到命令返回游标 0 , 我们称这个过程为一次**完整遍历**(full iteration).

### SCAN 命令的保证(guarantees)

SCAN 命令, 以及其他增量式迭代命令, 在进行完整遍历的情况下可以为用户带来以下保证:  从完整遍历开始直到完整遍历结束期间, 一直存在于数据集内的所有元素都会被完整遍历返回;  这意味着, 如果有一个元素, 它从遍历开始直到遍历结束期间都存在于被遍历的数据集当中, 那么 SCAN 命令总会在某次迭代中将这个元素返回给用户.

然而因为增量式命令仅仅使用游标来记录迭代状态, 所以这些命令带有以下缺点: 

* 同一个元素可能会被返回多次. 处理重复元素的工作交由应用程序负责, 比如说, 可以考虑将迭代返回的元素仅仅用于可以安全地重复执行多次的操作上.
* 如果一个元素是在迭代过程中被添加到数据集的, 又或者是在迭代过程中从数据集中被删除的, 那么这个元素可能会被返回, 也可能不会, 这是未定义的(undefined).

### SCAN 命令每次执行返回的元素数量

增量式迭代命令并不保证每次执行都返回某个给定数量的元素.

增量式命令甚至可能会返回零个元素, 但只要命令返回的游标不是 `0` , 应用程序就不应该将迭代视作结束.

不过命令返回的元素数量总是符合一定规则的, 在实际中: 

- 对于一个大数据集来说, 增量式迭代命令每次最多可能会返回数十个元素; 
- 而对于一个足够小的数据集来说, 如果这个数据集的底层表示为编码数据结构(encoded data structure, 适用于是小集合键, 小哈希键和小有序集合键), 那么增量迭代命令将在一次调用中返回数据集中的所有元素.

最后, 用户可以通过增量式迭代命令提供的 `COUNT` 选项来指定每次迭代返回元素的最大值.

### COUNT 选项

虽然增量式迭代命令不保证每次迭代所返回的元素数量, 但我们可以使用 `COUNT` 选项, 对命令的行为进行一定程度上的调整.

基本上, `COUNT` 选项的作用就是让用户告知迭代命令, 在每次迭代中应该从数据集里返回多少元素.

虽然 `COUNT` 选项**只是对增量式迭代命令的一种提示**(hint), 但是在大多数情况下, 这种提示都是有效的.

- `COUNT` 参数的默认值为 `10` .
- 在迭代一个足够大的, 由哈希表实现的数据库, 集合键, 哈希键或者有序集合键时, 如果用户没有使用 `MATCH` 选项, 那么命令返回的元素数量通常和 `COUNT` 选项指定的一样, 或者比 `COUNT` 选项指定的数量稍多一些.
- 在迭代一个编码为整数集合(intset, 一个只由整数值构成的小集合),  或者编码为压缩列表(ziplist, 由不同值构成的一个小哈希或者一个小有序集合)时, 增量式迭代命令通常会无视 `COUNT` 选项指定的值, 在第一次迭代就将数据集包含的所有元素都返回给用户.

### MATCH 选项

和 [*KEYS*](http://doc.redisfans.com/key/keys.html#keys) 命令一样, 增量式迭代命令也可以通过提供一个 glob 风格的模式参数, 让命令只返回和给定模式相匹配的元素, 这一点可以通过在执行增量式迭代命令时, 通过给定 `MATCH <pattern>` 参数来实现.

以下是一个使用 `MATCH` 选项进行迭代的示例:

```bash
127.0.0.1:6379> SCAN 0 match key* count 5
1) "26"
2) 1) "key13"
   2) "key3"
   3) "key4"
   4) "key11"
   5) "key12"
127.0.0.1:6379> SCAN 26 match key* count 5
1) "30"
2) 1) "key1"
   2) "key2"
127.0.0.1:6379> SCAN 30 match key* count 5
1) "3"
2) 1) "key9"
   2) "key10"
   3) "key7"
   4) "key6"
   5) "key8"
127.0.0.1:6379> SCAN 3 match key* count 5
1) "0"
2) 1) "key14"
   2) "key5"
```

### 并发执行多个迭代

在同一时间, 可以有任意多个客户端对同一数据集进行迭代, 客户端每次执行迭代都需要传入一个游标, 并在迭代执行之后获得一个新的游标, 而这个游标就包含了迭代的所有状态, 因此, 服务器无须为迭代记录任何状态.

### 中途停止迭代

因为迭代的所有状态都保存在游标里面, 而服务器无须为迭代保存任何状态, 所以客户端可以在中途停止一个迭代, 而无须对服务器进行任何通知.

即使有任意数量的迭代在中途停止, 也不会产生任何问题.

### 使用错误的游标进行增量式迭代

使用间断的(broken), 负数, 超出范围或者其他非正常的游标来执行增量式迭代并不会造成服务器崩溃, 但可能会让命令产生未定义的行为.

未定义行为指的是, 增量式命令对返回值所做的保证可能会不再为真.

只有两种游标是合法的: 

1. 在开始一个新的迭代时, 游标必须为 `0` .
2. 增量式迭代命令在执行之后返回的, 用于延续(continue)迭代过程的游标.

### 迭代终结的保证

增量式迭代命令所使用的算法只保证在数据集的大小有界(bounded)的情况下, 迭代才会停止, 换句话说, 如果被迭代数据集的大小不断地增长的话, 增量式迭代命令可能永远也无法完成一次完整迭代.

从直觉上可以看出, 当一个数据集不断地变大时, 想要访问这个数据集中的所有元素就需要做越来越多的工作, 能否结束一个迭代取决于用户执行迭代的速度是否比数据集增长的速度更快.







## 面试

### 什么是 Redis

基于内存, KV 存储结构

KV: redis 通常是用来做缓存的, 只缓存一部分数据, 数据是不完整的, 所以不适合关系型

单线程: worker 单线程, iothreads 多线程

连接很多: 并发高

<img src="http://www.milky.show/images/redis/redis_80.png" alt="http://www.milky.show/images/redis/redis_80.png" style="zoom: 67%;" />

### 本地方法: 计算向数据移动, IO 优化

在 memcached 中, 只能将列表全部取出然后在应用内获取对应下标的值, 增加了网络 io 的开销, 而使用 redis, 可以在 redis 中计算出想要的数据, 极大地减少了网络 io 的开销

<img src="http://www.milky.show/images/redis/redis_77.png" alt="http://www.milky.show/images/redis/redis_77.png" style="zoom: 33%;" />

### 串行化/原子, 并行 VS 串行

Redis 是单线程的, 串行化, 执行命令需要 3 个步骤, 1: epoll 通知有 event 的到来, 2: 读取事件内容, 3: 本地计算结果

<img src="http://www.milky.show/images/redis/redis_76.png" alt="http://www.milky.show/images/redis/redis_76.png" style="zoom: 33%;" />

如果在多核 CPU 情况下, 此处有个小弊端, 因为 Redis 是单线程的, 所以 CPU 的利用率并不高, redis 的计算和 io 实际上是独立的, c1 的 io 要等到 c2 结束后才进行, 实际上是一种资源浪费, c1 的 io 与 c2 的 io 和计算完全可以并行进行, 所以在 Redis6.x 以后进行了 iothreads 多线程优化, 需要配置开启, 不是默认行为

<img src="http://www.milky.show/images/redis/redis_79.png" alt="http://www.milky.show/images/redis/redis_79.png" style="zoom: 33%;" />

在高并发交易场景下, 并发可能是 100, 但并行度是 2, 最终落到 db 时要保证是串行化, 如果使用传统 db 加锁性能低下, 如果使用 redis, 天然的单线程内存模型效率会大大提高

<img src="http://www.milky.show/images/redis/redis_78.png" alt="http://www.milky.show/images/redis/redis_78.png" style="zoom: 33%;" />





## 其他链接

[https://mp.weixin.qq.com/s/aXaMRAUD3IBVOk_HvSfSWg](https://mp.weixin.qq.com/s/aXaMRAUD3IBVOk_HvSfSWg)